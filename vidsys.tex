\label{vidsys}

\begin{informative*}
\subsection{Colour models}
All current video systems use a $Y, C1, C2$ form of coding for RGB source 
values. Although $Y, C_B, C_R$ is widely used, Dirac can support other colour
systems such as $Y, C_O, C_G$ as defined by ITU-T H.264 AVC annex E. For this
reason the non-luma components are generalized to the terms C1 and C2.

The R, G and B are tristimulus values (e.g. candelas/$m^2$). Their
relationship to CIE XYZ tristimulus values can be derived from the set
of primaries and white point defined in the colour primaries part of the
colour specification below using the method described in SMPTE RP
177-1993. In this document the RGB values are normalised to the range
[0,1], so that RGB=[1,1,1] represents the peak white of the display device
and RGB=0,0,0 represents black.

The $E_R$, $E_G$ and $E_B$ values are related to the linear RGB 
values by non-linear transfer functions. 
Normally, $E_R$, $E_G$ and $E_B$ also fall in the range $[0,1]$, but in the
case of extended gamut systems (such as ITU-R BT1361), negative values can also
occur. The non-linear transfer function is typically performed in the camera and
is specified in the transfer characteristic part of the appropriate colour 
specification. For aesthetic and psychovisual reasons
the encoding transfer function is not always the inverse of
the decoding transfer function. In fact the combined effect of the
encoding and decoding transfer functions is such that the rendering intent or 
end-to-end gamma of the system can vary between about 1.1 and 1.6 depending on
 viewing conditions. The rationale for this is given in “Digital Video and
HDTV” by Charles Poynton, (2003, Morgan Kaufmann Publishers, ISBN 1-55860-792-7).

The non-linear $E_R$, $E_G$ and $E_B$ values are subject to a matrix operation
(known as `non-constant luminance coding'), which transforms
them into luma ($E_Y$) and colour difference (normally $E_{Cb}$ and $E_{Cr}$) values. 
$E_Y$ is normally limited to the range $[0,1]$ and the colour difference
values to the range $[-0.5, 0.5]$. In this specification, the color difference
components are referred to as `chroma’ components and are not to be confused 
with the chroma signals used by composite television systems where the colour 
difference signals are significantly reduced in both resolution and signal
amplitude. The chroma components used in this specification can be sub-sampled,
 either horizontally, vertically or both horizontally and vertically.

\subsubsection{$YC_BC_R$ coding}

The $E_Y$, $E_{Cb}$ and $E_{Cr}$ values are
mapped to a range of integers denoted $Y$, $C_B$ and $C_R$, typically $[0,255]$.  In order to display video, the inverse to the above
operations must be performed to convert this data to $E_Y$, $E_{Cb}$, $E_Cr$, 
then to $E_R$, $E_G$, $E_B$ and thence to R, G and B.  

\subsubsection{$YC_OC_G$ coding}

In the case of YCoCg coding, the $E_R$, $E_G$ and $E_B$ values are directly
linearly scaled to integer ranges before a lossless 
direct integer transform is applied to convert this data to $Y$, $C_O$ and 
$C_G$) data.

\subsubsection{Signal range}
\label{signalranges}

The output of the Dirac decoder consists of unsigned integer values. For $YC_BC_R$ coding, the offset and excursion values are used to linearly scale these 
values into intermediate  vlues  $E_Y$, $E_{Cb}$, and $E_{Cr}$.
$E_Y$ is normally clipped to the range $[0,1]$ and $E_{Cb}$, $E_{Cr}$
to the range $[-0.5,0.5]$. The effect is to clip integer $Y$ values output by
the decoder to the interval
\[ \SLumaOffset, \SLumaOffset+\SLumaExcursion] \]
and $C1$, $C2$ values to
\[ [\SChromaOffset-\SChromaExcursion/2,\SChromaOffset+\SChromaExcursion/2] \]

However, maintaining an extended RGB gamut can mean that either such
clipping is not done, or non-standard offset and excursion values are
used to extract the extended gamut from the non-negative $Y$, $C1$,
and $C2$ values.

In the case of $YCoCg$ coding, $E_Y$, $E_{CO}$, and $E_{CG}$ should not be
 calculated. Instead, direct integer conversion to RGB should be done 
(note: excursion values will be ignored in this integer conversion.)

\subsubsection{Primaries}
\label{primaries}
The colour primaries allow device dependent linear RGB colour
co-ordinates to be mapped to device independent linear CIE XYZ space.
The primaries specified are the CIE (1931) XYZ chromaticity
co-ordinates of the primaries and the white point of the device. 

The color primary specification therefore allows exact color reproduction of
 decoded RGB values on different displays
with different display primaries.

\subsubsection{Colour matrix}
\label{matrix}
\paragraph{$YC_BC_R$ coding}
$\ $\newline
Unit-scale luma and chroma values $E_Y$, $E_{Cb}$ and $E_{Cr}$ should be
derived from decoded $Y$, $C1$ and $C2$ values using the signal range parameters
as per Section \ref{signalranges}. Given these values, $E_R$, $E_G$ and $E_B$ are
determined as follows:
\begin{eqnarray*}
E_R & = & E_Y + 2*(1-K_R)*E_{Cr} \\
E_G & = & E_Y - \dfrac{2*K_R*(1-K_R)*E_{Cr}}{K_G}-\dfrac{2*K_B*(1-K_B)*E_{Cb}}{K_G} \\
E_B & = & E_Y + 2*(1-K_R)*E_{Cb} 
\end{eqnarray*}
where $K_G=1-K_R-K_B$.
This follows by inverting the equations 
\begin{eqnarray*}
K_R+K_G+K_B & = & 1 \\
E_Y & = & K_R*E_R+K_G*E_G+K_B*E_B \\
E_{Cb} & = & \dfrac{E_B - E_Y}{2*(1-K_B)} \\
E_{Cr} & = & \dfrac{E_R - E_Y}{2*(1-K_R)} \\
\end{eqnarray*}

\paragraph{YCoCg coding}
$\ $\newline
In the case of YCoCg coding, integer $I_R$, $I_G$, $I_B$ should be directly computed from
the decoded $Y$, $C1$ ($C_O$) and $C2$ ($C_G$) values by
\begin{eqnarray*}
Y & -= & \SLumaOffset \\
Co=C1 & -= & \SChromaOffset \\
Cg=C2 & -= & \SChromaOffset \\
t & = & Y-(Cg\gg1) \\
I_G & = & t+Cg \\
I_B & = & t-(Co\gg1) \\
I_R & = & I_B+Co
\end{eqnarray*}
The integer values are converted to unit-scale $E_R$, $E_G$, $E_B$ by dividing by 
$2^\LumaDepth$ and clipping to $[0,1]$.
If the inverse transform has been correctly
applied prior to coding and lossless coding employed, then clipping will
be unnecessary, and reversing the above operations will reproduce $Y$, 
$C_O$ and $C_G$ losslessly from $I_R$, $I_G$ and $I_R$ yielding a transparent
 RGB to RGB coding system:
\begin{eqnarray*}
Co & = & I_R-I_B \\
t & = & I_B+(I_R-I_B)\gg1 \approx (I_R+I_B)/2\\
Cg & = & I_G-t = \approx I_G-(I_R+I_B)/2\\
Y & = & t+(Cg\gg1) \approx I_G/2-(I_R+I_B)/4+(I_R+I_B)/2=I_R/4+I_G/2+I_B/4
\end{eqnarray*}

Note that these matrix operations imply that the chroma data requires an
 additional bit, due to the subtractions used to create chroma components. 
So for 8-bit RGB ($I_R$, $I_G$, $I_B$) values, $Y$ will be 8 bits and $C_O$ and
$C_G$ will be 9 bits. 


\subsection{Transfer characteristics}
\subsubsection{TV transfer characteristic}

ITU-R BT.601-6 defines the 625-line and 525-line standard definition systems 
with an assumed receiver display gamma value of 2.8. SMPTE 170M defines the NTSC
 SDTV system with an assumed receiver display gamma value of 2.2.

High Definition systems for both 50Hz and 60Hz based systems use an encoding
 gamma value of 0.45 with a linear portion at the low end of the scale to avoid
 the need for infinite gain at the receiver. This gamma value is defined by
ITU-R BT.709.

\subsubsection{Extended Colour Gamut}

ITU-R BT 1361 (Worldwide Unified Colorimetry of Future TV Systems) defines a
 color system with an extended colour gamut. Refer to ITU-R BT 1361 (1998) 
for details.

ISO/IEC 61966-2 (Extended RGB Color Space) defines another colour system with
 an extended color gamut. Refer to IEC 61966-2-2:2003 for details.

In both cases, it should be noted that use of the full range of $Y, C1, C2$
 values can create negative R, G or B values. The original color gamut equations
 were designed around the CRT (cathode ray tube) device. Some flat panel
displays are capable of displaying a wider color gamut resulting in the desire 
to extend the color gamut to maximize the impact of these displays.

\paragraph{Linear}
$\ $\newline
A linear transfer characteristic has $f(x)=x$ i.e. $E_X=X$. 

\subsection{Frame rate}
The ratio of the frame rate values $\SFrameRateNumer$ and $\SFrameRateDenom$
 encodes the intended rate at which frames should be
displayed subsequent to decoding. If $\SSourceSampling$ is 1 (interlaced
 sampling),  then fields are displayed at double the frame rate, in the order specified by the $\STopFieldFirst$ flag.

\subsection{Aspect ratios and clean area}

\subsubsection{Pixel aspect ratio}

The pixel aspect ratio value of an image is the ratio of the intended spacing of
 horizontal samples (pixels) to the spacing of vertical samples (picture lines)
 on the display device. Pixel aspect ratios are fundamental properties of
sampled images because they determine the displayed shape of objects in the
 whole image. Failure to use the correct value of pixel aspect ratio will result
 in distorted images where circles will be displayed as ellipses.

Most HDTV standards and computer image formats are defined to have pixel aspect
 ratios that are exactly 1:1.

For a number NH of pixels per unit length and NV pixels per unit height, this
 ratio is 1/NH : 1/NV or NV : NH. For a video standard of WxH pixels displayed 
at 4:3 picture aspect ratio, NH=W/4 and NV=H/3.

\paragraph{Using non-square pixel aspect ratios}
\newline$ $
The defined pixel aspect ratios are designed to give image aspect ratios for
 standard definition television operating with a standard 4:3 picture aspect
 ratio.

For 525-line video, defining a 704 x 480 picture with a 4:3 aspect ratio results
 in a H:V pixel aspect ratio of 10:11 (i.e. 480/3 : 704/4 ).

For 625-line video defining a 704 x 576 picture with a 4:3 aspect ratio results
 in a H:V pixel aspect ratio of 12:11 (i.e. 576/3 : 704/4 ).

If the intended image aspect ratio is 16:9, then the H:V pixel aspect ratios
 change accordingly to 40:33 for 525-line video and 16:11 for 625-line video.

The values specified above are widely, but not unanimously, agreed to be the
 correct values. Differences of viewpoint arise from how much of the available
 horizontal picture size of 720 Y pixels is intended for display.

You are strongly advised to use one of the default pixel aspect ratios. However,
 if you know what you are doing and don’t like the default values the codec
 allows you to define your own ratio. You should be aware that many display
devices could ignore your decision and may default to using different and
 unsuitable values.

\subsubsection{Clean area}

The clean area is intended to define an area within which picture information is
 subjectively uncontaminated by all edge distortions and possible unintended
 picture content such as microphones appearing at the top of the picture. It
could be appropriate to display the clean area rather than the whole picture,
 which can contain edge distortions or unintended content.

The top-left corner of the clean area has coordinates
\[(\SLeftOffset,\STopOffset)\]
counting from the top-left corner of the picture data, and
dimensions $\SCleanWidth$ by $\SCleanHeight$.

Note that these dimensions refer to pixels within a picture, not a frame,
so a change from interlaced to progressive picture coding will
necessitate a change of clean area if a custom clean area is used.

The clean area and the pixel aspect ratio together determine the
aspect ratio of the displayed image which is the ratio of the width of the
 intended
display area to the height of the intended display area:
\[\dfrac{\SCleanWidth*\SAspectRatioNumer}{\SCleanHeight*\SAspectRatioDenom}\]

Given two separate sequences, with identical image aspect ratio, if the
top left corner and bottom right corners of their clean apertures are
coincident when displayed, then the images as a whole should be exactly
coincident. This is regardless of the actual pixel dimensions of the
images or their clean areas. This allows sequences to be combined
together appropriately if they are appropriately scaled.

\end{informative*}
