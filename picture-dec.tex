%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% - This chapter defines the overall process  - %
% - for decoding a picture                    - % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{picturedec}

\subsection{Overall picture decoding process}
\label{overallpicturedec}

\subsubsection{Picture data initialisation}
\label{picdataconventions}

Picture data from the current picture being decoded is stored in the $\CurrentPicture$ state
variable, which is a structure with indices $pic\_num$, $Y$, $C1$ and $C2$ representing
luma and chroma data (typically Y, Cb and Cr, although other formats are supported too -- see
Appendix \ref{vidsys}).


The $init\_picture\_data()$ initialises the current picture data so that:
\begin{itemize}
\item $\CurrentPicture[pic\_num]=\PictureNumber$
\item $\CurrentPicture[Y]$ is a 2-dimensional array of width $\LumaWidth$ and height $\LumaHeight$, 
all values $\CurrentPicture[Y][y][x]$ set to 0
\item $\CurrentPicture[C1]$ and $\CurrentPicture[C2]$ are 2-dimensional arrays of width $\ChromaWidth$ and height $\ChromaHeight$, 
all values $\CurrentPicture[C1][y][x]$ and $\CurrentPicture[C2][y][x]$ set to 0
\end{itemize}

\subsubsection{Decoding process}
\label{picturedecprocess}

The process for decoding a picture within a Dirac sequence can commence 
when: 
\begin{itemize}
\item a sequence header has been located, and parsed, and the default parameters set, and
\item a picture data unit has been located and parsed, overriding default parameters, and
\item all reference pictures for the current picture have been decoded
\end{itemize}

Decoding a picture with picture number 
$n=\PictureNumber$ in a Dirac sequence consists of:

\begin{pseudo}{picture\_decode}{}
\bsIF{is\_ref(()}
    \bsCODE{ref\_buffer\_remove()}{\ref{refbuffer}}
\bsEND
\bsCODE{init\_picture\_data()}{\ref{picdataconventions}}
\bsIF{\ZeroResidual==\false}
    \bsCODE{\CurrentPicture[Y]=idwt(\YTransform)}{\ref{idwt}}
    \bsCODE{\CurrentPicture[C1]=idwt(\COneTransform)}{\ref{idwt}}
    \bsCODE{\CurrentPicture[C2]=idwt(\CTwoTransform)}{\ref{idwt}}
\bsEND
\bsIF{is\_inter()}
    \bsCODE{ref1=get\_ref(\RefOneNum)}
    \bsIF{num\_refs()==2}{\ref{parseinfo}}
        \bsCODE{ref2=get\_ref(\RefTwoNum)}
    \bsEND
    \bsCODE{motion\_compensate(ref1[Y], ref2[Y],  \CurrentPicture[Y], c)}{\ref{motioncompensate}}
    \bsCODE{motion\_compensate(ref1[C1], ref2[C1],  \CurrentPicture[C1], c)}{\ref{motioncompensate}}
    \bsCODE{motion\_compensate(ref1[C2], ref2[C2],  \CurrentPicture[C2], c)}{\ref{motioncompensate}}
\bsEND
\bsCODE{clip\_picture()}{\ref{pictureclip}}
\bsIF{is\_ref()}
    \bsCODE{ref\_buffer\_add()}{\ref{refbuffer}}
\bsEND
\bsCODE{offset\_output\_picture(\CurrentPicture)}{\ref{videooutput}}
\bsRET{\CurrentPicture}
\end{pseudo}

\begin{informative}
When randomly accessing a sequence, a picture may not be decodeable because reference pictures
may not be available in the buffer. In this case the current picture may be discarded, although some
decoders may be designed to produce an output. 

Picture numbers within the stream may not be in numerical order, and subsequent reordering may be
required: the size of the decoded picture buffer required to perform any such reordering is specified
as part of the application profile and level (Appendix \ref{profilelevel}).
\end{informative}

\subsection{Reference picture buffer management}
\label{refbuffer}

This section specifies how the Dirac stream data shall be used to manage the reference 
picture buffer $\RefBuffer$. The reference picture buffer has a maximum size of
$\RefBufferSize$ elements, as set in the applicable level (Appendix \ref{profilelevel}).

The $ref\_picture\_remove()$ process shall be defined as
follows:

\begin{pseudo}{ref\_picture\_remove}{}
\bsCODE{n=\RetiredPicture}
\bsFOR{k=0}{\RefBufferSize-1}
   \bsIF{\RefBuffer[k][pic\_number]==n}
        \bsFOR{j=k}{\RefBufferSize-2}
            \bsCODE{\RefBuffer[j]=\RefBuffer[j+1]}
        \bsEND
        \bsCODE{\RefBufferSize -= 1}
    \bsEND
\bsEND
\end{pseudo}

The $get\_ref(n)$ function shall returns the reference picture in the buffer with 
picture number $n$.  If there is no such picture it shall return an all-zero picture.

The $ref\_picture\_add()$ process for adding pictures to the reference picture
buffer shall proceed according to the following rules:

{\bf Case 1.} If the reference picture buffer is not full i.e. has fewer than $\MaxRefBufferSize$ elements,
then add $\CurrentPicture$ to the end of the buffer. 

{\bf Case 2.} If the reference picture is full i.e. it has $\MaxRefBufferSize$ elements, then remove the
first (i.e. oldest) element of the buffer, $\RefBuffer[0]$, set
\[\RefBuffer[i] = \RefBuffer[i+1] \]
for $i=0$ to $\RefBufferSize-2$, and set the last element $\RefBuffer[\RefBufferSize-1]$ equal to
a copy of $\CurrentPicture$.



\subsection{Inverse discrete wavelet transform}
\input{idwt}

\subsection{Motion compensation}
\input{mc}

\subsection{Clipping}
\label{pictureclip}

Picture data must be clipped prior to being output or being
used as a reference:

\begin{pseudo}{clip\_picture}{}
\bsFOREACH{c}{Y,C1,C2}
    \bsCODE{clip\_component(\CurrentPicture[c])}
\bsEND
\end{pseudo}


\begin{pseudo}{clip\_component}{comp\_data,c}
\bsIF{c==Y}
    \bsCODE{bit\_depth=\LumaDepth}
\bsELSE
    \bsCODE{bit\_depth=\ChromaDepth}
\bsEND
\bsFOR{y=0}{\height(comp\_data)-1}
    \bsFOR{x=0}{\width(comp\_data)-1}
        \bsCODE{data = \clip(comp\_data[y][x], -2^{bit\_depth-1}, 2^{bit\_depth-1}-1)}
     \bsEND
\bsEND
\end{pseudo}

\begin{informative}
Note that clipping is incorporated into motion compensation, so that strictly speaking additional
clipping is only required for intra pictures.
\end{informative}


\subsection{Clipping}
\label{pictureclip}

Picture data must be clipped prior to being output or being
used as a reference:

\begin{pseudo}{clip\_picture}{}
\bsFOREACH{c}{Y,C1,C2}
    \bsCODE{clip\_component(\CurrentPicture[c])}
\bsEND
\end{pseudo}


\begin{pseudo}{clip\_component}{comp\_data,c}
\bsIF{c==Y}
    \bsCODE{bit\_depth=\LumaDepth}
\bsELSE
    \bsCODE{bit\_depth=\ChromaDepth}
\bsEND
\bsFOR{y=0}{\height(comp\_data)-1}
    \bsFOR{x=0}{\width(comp\_data)-1}
        \bsCODE{data = \clip(comp\_data[y][x], -2^{bit\_depth-1}, 2^{bit\_depth-1}-1)}
     \bsEND
\bsEND
\end{pseudo}

\begin{informative}
Note that clipping is incorporated into motion compensation, so that strictly speaking additional
clipping is only required for intra pictures.
\end{informative}

\subsection{Video output ranges}
\label{videooutput}

Video output data ranges are deemed to be non-negative, so that the offset and excursion values 
may be applied by subsequent processing. Since decoded video data is bipolar, it must be 
suitably offset before output:

\begin{pseudo}{offset\_output\_data}{picture\_data}
\bsFOREACH{c}{Y, C1, C2}
    \bsIF{c==Y}
        \bsCODE{bit\_depth=\LumaDepth}
    \bsELSE
        \bsCODE{bit\_depth=\ChromaDepth}
    \bsEND
    \bsCODE{comp=picture\_data[c]}
    \bsFOR{y=0}{\height{comp}-1}
        \bsFOR{x=0}{\width{comp}-1}
            \bsCODE{comp[y][x]+=2^{bit\_depth-1}}
        \bsEND
    \bsEND
\bsEND
\end{pseudo}