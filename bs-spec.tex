%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% - This chapter defines the bytestream structure - %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{streamstructure}

This section specifies the Dirac stream and stream parsing operations,
excepting the unpacking of wavelet coefficients and motion data,
which are deferred to Sections \ref{wltunpacking} and \ref{motiondec}.
The decoding operations for extracting decoded pictures from unpacked
data are specified in Section \ref{picturedec}.

A Dirac stream has two variant syntaxes: a core syntax used for conventional
coding applications and a low-delay syntax used for applications where decoding 
(and encoding) delay is required to be less than a picture. These different
syntaxes apply primarily to the unpacking of wavelet coefficients, and
do not affect stream parsing as specified in this section,
except in terms of some alternative transform metadata 
(Section \ref{transformparameters}). 

The stream parsing specification is augmented by the parse diagrams
in Appending \ref{parsediagrams}, which summarise in graphical form
the struture of the stream.

\subsection{Introduction}

A stream is a concatenation of Dirac sequences.
a sequence is a concatenation of Access Units, comprised of Access Unit
headers and a number of picture data units, together with data headers (``Parse Info")
allowing for efficient navigation of the sequence.

The essential difference between a stream and a sequence is that
a sequence corresponds to a single video sequence, meaning a stream
of images of constant video parameters (picture dimensions, aspect ratio,
frame rate and so on as defined in Sections \ref{sequenceparameters} and \ref{sourceparameters}).
Any change in video parameters necessitates that a sequence be terminated and a
new sequence started.

Default decoding parameters are computed based on the Access Unit header data.
AU header data is required to be constant throughout
a sequence (Section \ref{auheader}): however the decoding parameters used for
decoding pictures are {\em not} necessarily constant since they may be overridden within
the picture data. 

As a result, the parsing and decoding model used in this
specification maintains two sets of state variables: the sequence or default state variable
$\SeqStateName$, holding the defaults to be used
throughout a sequence, and the state variable $\StateName$ holding
the values to be used for decoding the current picture, which may override the defaults 
for many variables. The picture
state variable is re-intialised from the default settings before each picture is decoded.


\begin{informative}
The requirement that default decoding parameters are overridden 
for each picture -- rather than, for example, changing
defaults for all subsequent pictures -- potentially causes a little more overhead. However it
greatly enhances random access: once the Access Unit header has been read, {\em any} picture
within the Access Unit can be successfully parsed independently, and decoding may even be possible
from a variety of points within the Access Unit. Since the AU data is constant throughout the sequence, 
reading the AU header once allows any picture in the sequence to be parsed.
\end{informative}

\subsection{Stream}
\label{stream}

A stream is a concatenation of Dirac sequences. The process for parsing a stream 
is to parse all sequences it contains. A Dirac sequence shall be decoded as a separate entity.

\subsubsection{Sequence}

The data contained in a Dirac Sequence corresponds to a single video sequence with
constant video parameters as defined in Sections \ref{sequenceparameters} and \ref{sourceparameters}. A sequence
is preceded by a Parse Info header which indicates the beginning of the sequence
with a parse code. A Dirac sequence can be excised from a Dirac stream and decoded entirely
independently.

\begin{pseudo}{video\_sequence}{}
\bsCODE{\RefBuffer=\emptyset}
\bsCODE{\DecodedBuffer=\emptyset}
\bsCODE{parse\_info()}{\ref{parseinfo}}
\bsWHILE {is\_access\_unit()}{\ref{parseinfo}}
    \bsCODE{access\_unit()}{\ref{accessunit}}
\bsEND
\end{pseudo}

\subsection{Parse Info header}
\label{parseinfo}

This section specifies the operation of the $parse\_info()$ process for parsing
Parse Info header data. This header is byte-aligned. It occurs:
\begin{itemize}
\item at the beginning of a sequence
\item at the end of a sequence
\item before an Access Unit header
\item before each set of picture data
\item before each unit of padding or auxiliary data
\end{itemize}

It consists of a whole number of bytes and hence succeeding data elements
are also byte aligned by default.

It is used to navigate through the stream (Section \ref{picturedec}).
The values of Parse Info parameters determine the type and format of the
subsequent data structures, in particular indicating whether a picture is
Intra or Inter coded, and if Inter how many references it has.

\begin{pseudo}{parse\_info}{}
\bsCODE{byte\_align()}
\bsCODE{\ParseInfoPrefix=read\_uint\_lit(4)}
\bsCODE{\ParseCode=read\_byte()}
\bsCODE{\NextParseOffset=read\_uint\_lit(4)}
\bsCODE{\PrevParseOffset=read\_uint\_lit(4)}
\end{pseudo}

The Parse Info parameters shall satisfy the following constraints:

\begin{itemize}
\item $\ParseInfoPrefix$ shall be set to be 0x42 0x42 0x43 0x44, which is ASCII for BBCD.
\item $\ParseCode$ shall be one of the supported values set out in Table \ref{parsecodes}
\item $\NextParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the next Parse Info header, if there is one. If there
is no subsequent Parse Info header, it shall be be 0
\item $\PrevParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the previous Parse Info header, if there is one. If there
is no subsequent Parse Info header, it shall be be 0
\end{itemize}

Parse codes are divided into three sets. The first set of parse codes is generic. The second set 
relates to the core Dirac syntax, used for conventional coding applications. The third set of parse codes relate to the low-delay
syntax, used for professional applications. These are suitable
for applications where the required delay is less than a picture -- perhaps much less.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|l|c|}
\hline
\multicolumn{4}{|c|}{\bf Generic} \\
\hline
0x00 & 0000 0000 & Access Unit header &--\\
\hline
0x10 & 0001 0000 & End of Sequence & -- \\
\hline
0x20 & 0010 0000 & Auxiliary data & -- \\
\hline
0x30 & 0011 0000 & Padding data & -- \\
\hline
\multicolumn{4}{|c|}{\bf Core syntax} \\
\hline
\ParseCode &  {\bf Bits} & {\bf Description} & \begin{tabular}{c} {\bf Number of}\\ {\bf Reference}\\{\bf Pictures}\end{tabular}\\
\hline
0x0C & 0000 1100 & Intra Reference Picture (arithmetic coding) & 0\\
\hline
0x08 & 0000 1000 & Intra Non Reference Picture (arithmetic coding) & 0\\
\hline
0x4C & 0100 1100 & Intra Reference Picture (no arithmetic coding) & 0\\
\hline
0x48 & 0100 1000 & Intra Non Reference Picture (no arithmetic coding) & 0\\
\hline
0x0D & 0000 1101 & Inter Reference Picture (arithmetic coding) & 1\\
\hline
0x4D & 0100 1101 & Inter Reference Picture (no arithmetic coding) & 1\\
\hline
0x0E & 0000 1110 & Inter Reference Picture (arithmetic coding) & 2\\
\hline
0x4E & 0100 1110 & Inter Reference Picture (no arithmetic coding) & 2\\
\hline
0x09 & 0000 1001 & Inter Non Reference Picture (arithmetic coding)& 1\\
\hline
0x49 & 0100 1001 & Inter Non Reference Picture (no arithmetic coding) & 1\\
\hline
0x0A & 0000 1010 & Inter Non Reference Picture (arithmetic coding) & 2\\
\hline
0x4A & 0100 1010 & Inter Non Reference Picture (no arithmetic coding)& 2\\
\hline
\multicolumn{4}{|c|}{\bf Low-delay syntax} \\
\hline
\ParseCode &  {\bf Bits} & {\bf Description} & \begin{tabular}{c} {\bf Number of}\\ {\bf Reference}\\{\bf Pictures}\end{tabular}\\
\hline
0x8C & 1000 1100 & Intra Picture & --\\
\hline
0x88 & 1000 1000 & Intra Non Reference Picture & 0\\
\hline
\end{tabular}
\caption{Parse codes}\label{parsecodes}
\end{table}

A number of functions are defined based on the parse code value, considered
as a bit-field, which shall be used to direct subsequent decoding operations. All are
boolean, except for $num\_refs()$ which returns an integer:

\begin{pseudo}{is\_AU}{}
\bsRET{\ParseCode==\text{0x00}}
\end{pseudo}

\begin{pseudo}{is\_picture}{}
\bsRET{((\ParseCode \&\text{0x08})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{is\_end\_of\_sequence}{}
\bsRET{\ParseCode==\text{0x10}}
\end{pseudo}

\begin{pseudo}{is\_reference}{}
\bsRET{((\ParseCode \&\text{0x04})==\text{0x04})}
\end{pseudo}

\begin{pseudo}{is\_non\_reference}{}
\bsRET{((\ParseCode \&\text{0x04})==\text{0x00})}
\end{pseudo}

\begin{pseudo}{using\_ac}{}
\bsRET{((\ParseCode \&\text{0x40})==\text{0x40})}
\end{pseudo}

\begin{pseudo}{num\_refs}{}
\bsRET{(\ParseCode \&\text{0x03})}
\end{pseudo}

\begin{pseudo}{is\_intra}{}
\bsRET{(num\_refs()==0)}
\end{pseudo}

\begin{pseudo}{is\_inter}{}
\bsRET{(num\_refs()>0)}
\end{pseudo}

\begin{pseudo}{is\_low\_delay}{}
\bsRET{(\ParseCode \&\text{0x80})}
\end{pseudo}

\begin{informative}
Next Parse Offset and Previous Parse Offset are added to the byte stream to simplify parsing.
Next Parse Offset represents the offset in bytes from the start of the current Parse Info to the
start of the next Parse Info. So counting forward Next Parse Offset bytes from the first byte
(0x42=“B”) of the current Parse Info should yield a byte of value 0x42=“B” corresponding to
the start of the next Parse Info. The Previous Parse Offset is the number of bytes backwards
to the start of the previous Parse Info header. The Previous Parse Offset of the current Parse Info
therefore equals the Next Parse Offset of the previous Parse Info.

The 4 byte Parse Info Prefix is present to allow an application to find a point from which to
start decoding. That is, the function of Parse Prefix Header is to synchronise the decoder with
the byte stream. Parsing of the stream can start from any Access Unit Header,
and successful decoding  once the reference buffer has converged (see Section \ref{picturedec}). 

The decoder first needs to
find a Parse Info structure. It should then check the Parse Code in the Parse Info. If the
following parse unit is an Access Unit Header then the decoder can start decoding. If the
it is a Picture then the decoder should skip forward by Next Parse Offset bytes (from
the start of the Parse Info Prefix) to the next Parse Info. The decoder would continue skipping
forward until it locates an Access Unit Header. Note that the decoder does not need to parse
any intervening data in order to navigate through the stream to find an Access Unit Header. The
Previous Parse Offset is provided to allow searching backwards through the byte stream.

Any particular instance of the Parse Info Prefix in the byte stream may not, necessarily,
indicate the start of a Parse Info structure. This is because other parts of the byte stream may,
by chance, introduce these bytes into the byte stream. In particular, the use of arithmetic coding in Dirac
means that it is impossible to directly avoid accidentally introducing the Parse Info Prefix.
When encoding a bytestream it is not necessary to avoid accidentally introducing Parse Info
Prefix sequences. They are present to allow synchronisation of the bytes stream with the
decoder and this can be ensured, even in the presence of spurious Parse Info Prefixes, as
follows. When the decoder finds a Parse Info Prefix it should skip forward by Next Parse
Offset (or back by Previous Parse Offset) and check whether the next three bytes are a Parse
Info Prefix. If so the decoder can be reasonably certain that it has found a genuine Parse Info
Prefix. If it does not find another Parse Info Prefix it was probably unlucky enough to have
found a spurious Parse Info Prefix. In this case it should search for the next Prefix and repeat
the test.

The probability of a spurious Parse Info Prefix is low: 1 in $2^{32}$ since the prefix is 4 bytes
long. This is the probability of finding two Parse Info Prefix sequences separated by Next
Parse Offset. The test outlined in the previous paragraph is, therefore, more than adequate in practice.
For the paranoid the test may of course be extended, for example by testing that the Next Parse Offset
of one parse unit is equal to the Previous Parse Offset of the next parse unit.

The test for two appropriately separated Parse Info Prefixes is, anyway, prudent in any
channel subject to bit errors even in the absence of spurious Prefixes.
\end{informative}

\subsection{Auxiliary data and padding data}
Auxiliary data and padding data parse units consist of a parse info header, 
decoded by the $parse\_info()$ function defined in the previous section, 
followed by zero or more bytes of unspecified data. These
parse units may be interposed between any two other legitimate parse units in the stream, and
may safely be skipped by a compliant decoder. As for any other parse units, the Next Parse
Offset and Previous Parse Offset values must correctly encode the offset in bytes to the 
start of the next parse unit and previous parse unit respectively.

For the purposes of subsequent parts of this specification, the potential presence of auxiliary 
and padding data is ignored. 

Note that the most appropriate location for most forms of auxiliary data (subtitles, closed signing,
audio, other metadata) is almost certainly within a wrapping format/transport stream, and auxiliary
data units within the Dirac stream should be used with circumspection, and certainly not for any
data that might be displayed or otherwise directly consumed by end-users.

Padding data should not be used for any form of auxiliary data service or content, and should be
used by an encoder to insert additional data to assist in complying with constant or constrained bit rate 
requirements.

\subsection{Access Units}
\label{accessunit}

This section specifies the operation of the $access\_unit()$ process for parsing an Access Unit.
Access Units provide points at which the stream may be randomly accessed.
Specifically, a stream may be successfully parsed from any Access Unit Header (Section \ref{auheader})
without reference to prior data, and successfully decoded once the reference picture buffer has
converged (Section \ref{picturedec}). 

The access unit parsing process returns a set containing metadata, derived from the access unit
header, describing the encoded video
formats, which shall be used by decoding and display processes for presenting decoded video
(Section \ref{picturedec}).

The Access Unit parsing process is given by:

\begin{pseudo}{access\_unit}{}
\bsCODE{video\_params=access\_unit\_header()}{\ref{auheader}}
\bsCODE{parse\_info()}{\ref{parseinfo}}
\bsWHILE{is\_picture()==\true}{\ref{parseinfo}}
    \bsCODE{picture\_parse()}{\ref{picture}}
    \bsCODE{parse\_info()}{\ref{parseinfo}}
\bsEND
\bsRET{video\_params}
\end{pseudo}

Each Access Unit begins with the Access Unit header. Picture data may be read from that point until
the next Access Unit or until the end of the sequence/stream. Data is read into the default parameter
set by parsing the Access Unit header (Section \ref{auheader}). 

\subsection{Access Unit header}
\label{auheader}

This section specifies the structure of the Access Unit header. The Access Unit header is byte aligned
by default (see Section \ref{parseinfo} -- the pseudocode below contains a superfluous byte alignment for clarity).

Parsing this header consists in reading the Access Unit parameters and initialising 
the default decoder parameters $\SeqStateName$ as a result of these. Access Unit parameters
remain constant throughout a sequence, so in theory the AU header may be skipped after being read
once.

The AU header is parsed as follows:

\begin{pseudo}{access\_unit\_header}{}
\bsCODE{byte\_align()}
\bsCODE{parse\_parameters()}{\ref{parseparameters}}
\bsITEM{video\_format}{uint}{\ref{videoformat}}
\bsCODE{video\_params=source\_parameters()}{\ref{sourceparameters}}
\bsCODE{coding\_mode=interlaced\_coding(video\_format)}{\ref{interlacedcoding}}
\bsCODE{coding\_parameters(video\_params,coding\_mode)}{\ref{codingparameters}}
\bsRET{video\_params}
\end{pseudo}

\begin{informative}
Note that video parameters indicate whether the video sequence is interlaced or progressive.
In particular a change from interlaced to progressive video, or vice-versa, necessitates that
the Dirac sequence be terminated and a new sequence begun. The coding mode indicates whether
the pictures within a Dirac sequence are fields or frames. Note that progressive video may
still be encoded as fields, to provide backward compatibility with pseudo-progressive frame (PSF)
video transmission, although this application -- along with the use of PSF itself -- is deprecated.

The video parameters are not used by the Dirac decoder. Video parameter values should
be made available using appropriate interfaces and standards to any downstream video
processing device or display, but their use and interpretation by other devices is not specified in this standard. 
Neverthless, Appendix \ref{vidsys} specifies the video systems model that should be used for the interpretation
of video parameters.
\end{informative}


%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Access unit parse parameters}
\label{parseparameters}

This section specifes the structure of the Access Unit Parse Parameters, which is as follows:

\begin{pseudo}{parse\_parameters}{}
\bsITEM{\SVersionMajor}{uint}{}
\bsITEM{\SVersionMinor}{uint}{}
\bsITEM{\SProfile}{uint}{}
\bsITEM{\SLevel}{uint}{}
\end{pseudo}

Access Unit Parse parameter data shall remain constant
(byte-for-byte identical) for all instances of the Access Unit header within a Dirac sequence.

\subsubsection{Version number}

The version number of the Dirac syntax specification (this document) shall be used by the 
decoder to determine whether it can decode the sequence. It falls into two integer 
parts, the major and minor version, written as $M.m$, where $M=\SVersionMajor$ and
$m=\SVersionMinor$.
 
The major version defines the version of the syntax with which the stream 
complies. A decoder complies with a major version number if it can parse all bit 
streams that comply with that version number. Such a compliant decoder must be able 
to parse all previous versions too. Decoders that comply with a major version of the 
specification may not be able to parse the bit stream corresponding to a later 
specification. 

Depending on the profile and level defined a decoder compliant with a given major 
version number may still not be able to decode a bitstream. 

All minor versions of the specification should be functionally compatible with earlier 
minor versions with the same major version number. Later minor versions may 
contain corrections, clarifications, and disambiguations; they must not contain new 
features.

\subsubsection{Profiles and levels}

A profile determines a toolset that is sufficient to decode a sequence. A level determines
decoder resources (picture and data buffers; computational resources) sufficient
to decode a sequence, including the sizes $\RefBufferSize$ and $\DPBSize$ of 
the reference picture and decoded picture buffers. 
Applicable values of profile and level and the variables they set are specified in Appendix
\ref{profilelevel}.

\begin{comment}
The profile determines, amongst other things, the value of the boolean functions $using\_ac()$ and $using\_mc()$.
If $using\_ac()==\false$ then arithmetic coding is not used for entropy coding of coefficients.
If $ using\_mc()==\false$ then all pictures in the sequence shall be Intra pictures.

Main profile has value 0, and $using\_ac()$ and $using\_mc()$ are both set to $\true$. This does
not mean that an application under Main profile is required to use Inter pictures, but it is
required to use arithmetic coding.
\end{comment}

\subsection{Video format}
\label{videoformat}

Video Format shall be an index to Table \ref{table:videoformats}. For each entry in the table, parameters are defined in Appendix \ref{videoformatdefaults}, indicating default video parameters corresponding the video source and parameters required to decode pictures. These default parameters may be overridden by subsequent metadata present in the stream as defined in subsequent sections.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
Video format index	& Video format description \\
\hline
0	& Custom Format\\
\hline
1	&	QSIF\\
\hline
2	&	QCIF\\
\hline
3	&	SIF\\
\hline
4	&	CIF\\
\hline
5	&	4SIF\\
\hline
6	&	4CIF\\
\hline
7	&	SD 525 (525 Line 60 Field/s Standard Definition)\\
\hline
8	&	SD 625 (625 Line 50 Field/s Standard Definition)\\
\hline
9	&	HD 720P60 (720 Line 60 Frame/s High Definition)\\
\hline
10 &	HD 720P60 (720 Line 50 Frame/s High Definition)\\
\hline
11 &	HD 1080I60 (1080 Line 60 Field/s High Definition)\\
\hline
12	&	HD 1080I50 (1080 Line 50 Field/s High Definition)\\
\hline
13	&	HD 1080P60 (1080 Line 60 Frame/s High Definition)\\
\hline
14	&	HD 1080P50 (1080 Line 50 Frame/s High Definition)\\
\hline
15	&	2K Cinema\\
\hline
16	&	4K Cinema\\
\hline
\end{tabular}
\caption{Video formats}
\label{table:videoformats}
\end{table}

\subsection{Access unit source parameters}
\label{sourceparameters}

The Source Parameters are intended indicate the format of the video that was originally encoded.
 They provide metadata that indicates how the decoded video should be displayed. The Frame Size,
Sampling Format, Scanning Format and the Signal Range are required to decode the video. 
Display and downstream processing falls outside the scope of this specification, hence 
the interpretation of the other parameters (not required to decode the video) is not normatively defined, with the exception of frame rate (Section \ref{framerate}). The frame rate imposes requirements 
  on compliant decoders for a given level and profile (Appendix \ref{profilelevel}).

The Source Parameters shall comprise Frame Size, Sampling Format, Scan Format, Frame Rate, Aspect Ratio, Clean Area, Signal Range and Color Specification.
Source Parameter data shall remain constant throughout a VC-2 sequence. 

Default values for the source parameters shall be derived from the Video Format, as defined in
 Appendix \ref{videoformatdefaults}. These default values shall be the source parameters unless they are overridden with alternative values encoded as part of the Source Parameters part of the stream. Each parameter shall be associated with a Boolean variable that determines whether the parameter shall be set to the default parameter in  or shall be over-ridden. If the Boolean value is True, the stream syntax shall either:
\begin{itemize}
\item	define a value for each parameter or
\item	define the value of an index parameter that shall be used to access a defined look-up table.
\end{itemize}
If the Boolean value is False, the parameter value shall retain its default value.

Parsing the AU source parameters is as follows:

\begin{pseudo}{source\_parameters}{video\_format\_index}
\bsCODE{video\_params = set\_source\_defaults(video\_format\_index)}{\ref{setsourcedefaults}}
\bsCODE{\SVideoFormat = video\_format\_index}	
\bsCODE{frame\_size(video\_params)}{\ref{framedimensions}}
\bsCODE{chroma\_sampling\_format(video\_params)}{\ref{chromaformat}}
\bsCODE{scan\_format(video\_params)}{\ref{scanformat}}
\bsCODE{frame\_rate(video\_params)}{\ref{framerate}}
\bsCODE{aspect\_ratio(video\_params)}{\ref{aspectratio}}
\bsCODE{clean\_area(video\_params)}{\ref{cleanarea}}
\bsCODE{signal\_range(video\_params)}{\ref{signalrange}}
\bsCODE{colour\_spec(video\_params)}{\ref{colourspec}}
\bsRET{video\_params}
\end{pseudo}


\subsubsection{Setting source defaults}
\label{setsourcedefaults}

The function that sets the default values of the source video parameters 
shall take the video format index as an argument. That is, the signature of this function is: $set\_source\_defaults(video\_format\_index)$ where $video\_format\_index$ is an unsigned integer. The function returns a map of source video parameters.

The source video parameters shall be set, based on the video format index, as defined in 
Appendix \ref{videoformatdefaults}. The parameters set by this function shall be: Frame Size, 
Sampling Format (4:4:4, 4:2:2 or 4:2:0), Scan Format (Progressive or Interlace), Frame Rate, Aspect Ratio, Clean Area, Signal Range, Color Specification. The tokens used to access the map returned by the function shall be as defined in the subsequent sections that specify how to override the default video source parameters.

Note: as an example, if $video\_format\_index  == 4$, CIF defaults are set, with picture size equal to 252x288, 4:2:0 chroma format, amongst other parameters. A frame width of 360 pixels may be encoded by overriding the CIF format default value of 352. 

\subsubsection{Frame dimensions}
\label{framedimensions}

If a flag is set, the image dimensions specified by the video format defaults may
be overridden:

\begin{pseudo}{frame\_size}{video\_params}
\bsITEM{custom\_dimensions\_flag}{bool}{}
\bsIF{custom\_dimensions\_flag==\true}
    \bsITEM{video\_params[frame\_width]}{uint}{}
    \bsITEM{video\_params[frame\_height]}{uint}{}
\bsEND
\end{pseudo}

\subsubsection{Chroma samplingformats}
\label{chromaformat}

If a flag is set, the chroma format specified by the video format defaults is overridden.

\begin{pseudo}{chroma\_format}{video\_params}
\bsITEM{chroma\_format\_flag}{bool}{}
\bsIF{chroma\_format\_flag==\true}
     \bsITEM{video\_params[chroma\_format\_index]}{uint}{}
\bsEND
\end{pseudo}

The supported chroma sampling formats are specified in Table \ref{tab:chromaformats}:

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\SChromaFormatIndex & {\bf Chroma format} \\
\hline
0 & 4:4:4 \\
\hline
1 & 4:2:2 \\
\hline
2 & 4:2:0 \\
\hline
\end{tabular}
\caption{Supported chroma formats}\label{tab:chromaformats}
\end{table}

The chroma sampling format shall be used to determine the width and height of the 
chroma components of the coded video as described in Section \ref{} below.

\subsubsection{Scan format}
\label{scanformat}

Scan Format parameters are concerned with interlace. If $\SInterlaced=\true$, then the
video should be displayed as interlaced video. The process for parsing the Scan Format parameters
is as follows:

\begin{pseudo}{scan\_format}{video\_params}
\bsITEM{scan\_format\_flag}{bool}{}
\bsIF{scan\_format\_flag==\true}
    \bsITEM{video\_params[interlaced}{bool}{}
    \bsIF{video\_params[interlaced]==\true}
        \bsITEM{field\_dominance\_flag}{bool}{}
        \bsIF{field\_dominance\_flag==\true}
            \bsITEM{video\_params[top\_field\_first]}{bool}{}
        \bsEND
    \bsEND
\bsEND
\end{pseudo}

If the scan format flag is set to $\true$, the scan format parameters defined by 
the default values shall be overridden by the new values.

If the source video is interlaced, then $video\_params[interlaced]$ shall be true, 
else $video\_params[interlaced]$ shall be False.

If the source video is interlaced then $video_params[top\_field\_first])$ shall be $\true$ 
if the top line of the frame is in the earlier field, else $video\_params[top\_field\_first])$
 shall be $\false$.

These flags are independent of whether the video is coded as fields or frames.

\subsubsection{Frame rate}
\label{framerate}

The process for parsing Frame Rate parameters is as follows:

\begin{pseudo}{frame\_rate}{video\_params}
\bsITEM{frame\_rate\_flag}{bool}{}
\bsIF{frame\_rate\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{video\_params[frame\_rate\_numer]}{uint}{}
        \bsITEM{video\_params[frame\_rate\_denom]}{uint}{}
    \bsELSE
        \bsCODE{preset\_frame\_rate(video\_params,index)}
     \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 8.

For $index>0$, $preset\_frame\_rate(index)$ sets frame rate values as specified in Table \ref{table:frameratevalues}
(Appendix \ref{sourceparamspresets}).

The true frame rate is $\dfrac{\SFrameRateNumerator}{\SFrameRateDenominator}$.

Note that what is encoded is frame rate, not picture rate. If the video is coded
as fields, then picture rate is twice the encoded frame rate. Supported frame rates in a given profile
and level are specified in Appendix \ref{profilelevel}.

\subsubsection{Aspect ratio}
\label{aspectratio}

The process for extracting aspect ratio parameters is as follows:

\begin{pseudo}{aspect\_ratio}{video\_params}
\bsITEM{aspect\_ratio\_flag}{bool}{}
\bsIF{apect\_ratio\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{video\_params[aspect\_ratio\_numer]}{uint}{}
        \bsITEM{video\_params[aspect\_ratio\_denom]}{uint}{}
    \bsELSE
        \bsCODE{preset\_aspect\_ratio(index)}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

For $index>0$, $preset\_aspect\_ratio(index)$ sets aspect ratio values as specified in Table \ref{table:aspectratiovalues}
(Appendix \ref{sourceparamspresets}).

The true aspect ratio is $\dfrac{\SAspectRatioNumerator}{\SAspectRatioDenominator}$. 

It is a pixel aspect ratio and relates to frame dimensions and not field dimensions.

\subsubsection{Clean area}
\label{cleanarea}

The process for extracting the clean area parameters is as follows:

\begin{pseudo}{clean\_area}{video\_params}
\bsITEM{clean\_area\_flag}{bool}{}
\bsIF{clean\_area\_flag==\true}
    \bsITEM{video\_params[clean\_width]}{uint}{}
    \bsITEM{video\_params[clean\_height]}{uint}{}
    \bsITEM{video\_params[left\_offset]}{uint}{}
    \bsITEM{video\_params[top\_offset]}{uint}{}
\bsEND
\end{pseudo}

The clean area determines the part of the picture that should be displayed. The
following restrictions shall apply:

\begin{itemize}
\item $clean\_width+left\_offset\leq video\_params[frame\_width]$
\item $clean\_height+top\_offset\leq video\_params[frame\_height]$
\end{itemize}

\subsubsection{Signal range}
\label{signalrange}

The Signal Range parameters indicate how the signal range of the picture component data, decoded by the Dirac decoder, should be adjusted prior to the color matrixing operations (described in Appendix \ref{signalranges}). It shall also be used to determine the clipping levels applied to the decoded video (Section \ref{pictureclip}).

Note that picture component data processed by the Dirac decoder is bipolar, and
is adjusted to positive ranges when pictures are output.

The process for extracting the signal range parameters is as follows:

\begin{pseudo}{signal\_range}{}
\bsITEM{signal\_range\_flag}{bool}{}
\bsIF{signal\_range\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{video\_params[luma\_offset]}{uint}{}
        \bsITEM{video\_params[luma\_excursion]}{uint}{}
        \bsITEM{video\_params[chroma\_offset]}{uint}{}
        \bsITEM{video\_params[chroma\_excursion]}{uint}{}
    \bsELSE
        \bsCODE{preset\_signal\_ranges(video\_params,index)}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

$preset\_signal\_ranges(video\_paramsindex)$ sets signal range values as specified in Tables 
\ref{table:lumasignalrangevalues} and
\ref{table:chromasignalrangevalues} (Appendix \ref{sourceparamspresets}).

\subsubsection{Colour specification}
\label{colourspec}

This section specifies the $colour\_spec()$ parsing process. The colour
specification consists of primaries, matrix and transfer function. Defaults
are available for all three collectively and individually. The process is:

\begin{pseudo}{colour\_spec}{video\_params}
\bsITEM{colour\_spec\_flag}{bool}{}
\bsIF{colour\_spec\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsCODE{colour\_primaries(video\_params)}{\ref{colourprimaries}}
        \bsCODE{colour\_matrix(video\_params)}{\ref{colourmatrix}}
        \bsCODE{transfer\_function(video\_params)}{\ref{transferfunction}}
    \bsELSE
        \bsCODE{preset\_colour\_specs(video\_params,index)}
    \bsEND
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 4.

$preset\_colour\_spec(index)$ shall set the colour primaries, matrix and transfer function as specified 
in Table \ref{table:colourspecvalues} (Appendix \ref{sourceparamspresets}). If the index is 0, these values may be overridden as defined in the succeeding sections. 

\paragraph{Colour primaries}
\label{colourprimaries}
$\ $\newline The $colour\_primaries(video\_params)$ process is as follows:

\begin{pseudo}{colour\_primaries}{video\_params}
\bsITEM{colour\_primaries\_flag}{bool}{}
\bsIF{colour\_primaries\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_primaries(video\_params,index)}
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 3. $preset\_colour\_primaries(video\_params,index)$ shall set the colour primaries as specified
in Table \ref{table:primariesvalues} (Appendix \ref{sourceparamspresets}).

\paragraph{Colour matrix}
\label{colourmatrix}
$\ $\newline
The $colour\_matrix()$ process is as follows:

\begin{pseudo}{colour\_matrix}{}
\bsITEM{colour\_matrix\_flag}{bool}{}
\bsIF{colour\_matrix\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_matrices(index)}
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 2. $preset\_colour\_matrices(video\_params,index)$ shall set the colour matrix as specified
in Table \ref{table:matrixvalues} (Appendix \ref{sourceparamspresets}).

\paragraph{Transfer function}
\label{transferfunction}
$\ $\newline
The $transfer\_function()$ process is as follows:

\begin{pseudo}{transfer\_function}{}
\bsITEM{transfer\_function\_flag}{bool}{}
\bsIF{transfer\_function\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_transfer\_functions(index)}
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 3. $preset\_transfer\_functions(index)$ sets the transfer function as specified
in Table \ref{table:transfervalues} (Appendix \ref{sourceparamspresets}).

\subsection{Interlaced coding}
\label{interlacedcoding}

The Interlaced Coding part of the Access Unit Header shall determine whether source video is coded as frames or fields.

Interlaced coding shall determine the interpretation of coded pictures in the stream. If video is coded as interlaced then coded pictures represent fields, else coded pictures represent frames. 

Interlaced video is initially set as coded as fields (interlaced coding), and progressive video is initially set as coded as frames (progressive coding).

The $interlace\_coding$ parsing process shall be as defined by the following table: 

\begin{pseudo}{interlaced\_coding}{video\_params}
\bsCODE{coding\_mode=video\_params[interlaced]}{\ref{defaultcodingmode}}	
\bsITEM{scan\_coding\_flag}{bool}
\bsIF{scan\_coding\_flag == \true}	
  \bsCODE{coding\_mode=!coding\_mode}
\bsEND
\bsRET{coding\_mode}
\end{pseudo}

If video is coded as fields then the earliest field in each frame shall have an even picture number (Section \ref{}). That is the LSB of the frame number, expressed as a binary number, indicates field parity.

With interlaced coding each frame shall be split into two fields as indicated by the Scan Format (Section \ref{scanformat}).

An effect of interlace coding shall be to determine the vertical dimensions of coded pictures. Hence, once the interlace coding mode is known, the picture dimensions, which shall be stored as part of the global state variable, shall be set (Section \ref{}).

\begin{informative}
There are may be circumstances in which it is appropriate to interlaced source video as if it were progressive frames. This might be appropriate if there were limited motion in the video, in which case coding as if it were progressive frames would yield fewer coded bits. Sometimes progressively scanned video is conveyed as if it were interlaced, which is know as "film mode" or progressive segmented frames (psf). For a progressive video source, formatted as psf, it is appropriate to code it as progressive frames even though it is signaled as being interlaced.
\end{informative}

\subsection{Setting coding parameters}
\label{codingparameters}

The Coding Parameters process shall initialize the dimensions of the coded picture (frame or field) and the video depth (the maximum number of bits in a decoded video sample), which are needed to decode pictures. 

Picture dimensions shall remain constant throughout a sequence and shall be initialized as elements of the decoder state. 
Initialization of the coding parameters is as defined in the table below:

\begin{pseudo}{coding\_parameters}{video\_format, video\_params, interlaced\_coding}
\bsCODE{picture\_dimensions(video\_params, interlaced\_coding)}{\ref{picturedimensions}}
\bsCODE{video\_depth(video\_params)}
\bsCODE{format\_coding\_defaults(video\_format)}{\ref{formatcodingdefaults}}
\end{pseudo}

\subsubsection{Picture dimensions}
The $picture\_dimensions$ process, which determines the size of coded pictures, shall be defined follows:

\begin{pseudo}{picture\_dimensions}{video\_params, interlaced\_coding}
\bsCODE{\SLumaWidth = video\_params[frame\_width]}
\bsCODE{\SLumaHeight = video\_params[frame\_height]}
\bsCODE{\SChromaWidth = \SLumaWidth}
\bsCODE{\SChromaHeight = \SLumaHeight}
\bsCODE{chroma\_format\_index = video\_params[chroma\_format\_index]}
\bsIF{chroma\_format\_index == 1}
  \bsCODE{\SChromaWidth //= 2}
\bsELSEIF{chroma\_format\_index == 2}
  \bsCODE{\SChromaWidth //= 2}
  \bsCODE{\SChromaHeight //= 2}
\bsEND
\bsIF{interlace\_coding==\true}
  \bsCODE{\SLumaHeight //=2}
  \bsCODE{\SChromaHeight //=2}
\bsEND
\end{pseudo}

The parameter $frame\_height$ in the video parameters refers to the height of a frame. The parameter $luma\_height$ in the state variables refers to the height of a picture.  A picture may be either a frame or a field depending on whether it is being coded in an interlaced or progressive mode.

Frame heights shall be constrained such that the chroma height of pictures is equal to or an exact sub-multiple of the frame height. Thus for 4:4:4 and 4:2:2 chroma formats the frame height must be a multiple of 2 if interlaced coding is used. Similarly for 4:2:0 chroma format the frame height must always be a multiple of 2 and a multiple of 4 if interlaced coding is used. 
 
\subsubsection{Video depth}
The $video\_depth()$ process, which determines the maximum number of bits required to represent a sample of the decoded video, shall be defined as follows:

\begin{pseudo}{video\_depth}{video\_params}
\bsCODE{\SLumaDepth =\left\lceil \log_2(video\_params[luma\_excursion])\right\rceil}
\bsCODE{\SChromaDepth =\left\lceil \log_2(video\_params[chroma\_excursion])\right\rceil}
\end{pseudo}

Note that for some video formats (specifically YCgCo) the luma and chroma depths may be different.

\subsubsection{Format coding defaults}
\label{formatcodingdefaults}
[TBC]

\section{Dirac picture syntax specification}

This section specifies the structure of picture elements within a Dirac stream.

\subsection{Picture parsing}
\label{picture}
\label{pictureparse}

This Section specifies the operation of the $picture\_parse()$ process. The process for
decoding and outputting pictures is specified in Section \ref{picturedec}.

Picture data may be successfully parsed after parsing any Access Unit header
within the same Dirac sequence. Picture data encapsulates data for each of three
components -- one luma component (labelled $Y$) and two chroma components (labelled
$C1$ and $C2$)) -- and, optionally, motion vector data.

The parsing process is:

\begin{pseudo}{picture\_parse}{}
\bsCODE{init\_decode\_params()}{\ref{initdecodeparams}}
\bsCODE{byte\_align()}
\bsCODE{picture\_header()}{\ref{pictureheader}}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsCODE{byte\_align()}
    \bsCODE{picture\_prediction()}{\ref{pictureprediction}}
\bsEND
\bsCODE{byte\_align()}
\bsCODE{wavelet\_transform()}{\ref{wavelettransform}}
\end{pseudo}

\subsubsection{Initialising decoding parameters}
\label{initdecodeparams}

The default parameters are used to initialise the decoder state prior to 
decoding each picture:

\begin{pseudo}{init\_decode\_params}{}
\bsFOREACH{var}{\args(\SeqStateName)}
    \bsCODE{\StateName[var]=\SeqStateName[var]}
\bsEND
\end{pseudo}

State variables and default state variables are listed in the index.

\subsubsection{Picture header}
\label{pictureheader}

The picture header follows a Parse Info header with a picture parse code. It is byte aligned
by default (see Section \ref{parseinfo} -- the pseudocode below contains a superfluous byte
alignment for clarity). The process for parsing the picture header is as follows:

\begin{pseudo}{picture\_header}{}
\bsCODE{\PictureNumber=read\_byte\_lit(4)}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsCODE{reference\_picture\_numbers()}
\bsEND
\bsIF{is\_low\_delay()==\false}
    \bsCODE{retired\_picture\_list()}
\bsEND
\end{pseudo}

Picture numbers are not required to be unique within a sequence.
\begin{comment}
, since there are
only a finite number of them, and at some point the picture numbers will wrap round $2^{32}$.
However, a stream is required to be so constructed that:

\begin{itemize}
\item the decoded picture buffer mandated in the relevant profile and level shall be sufficient
to reorder the output picture numbers into a continous stream of integers $ \hdots, n, n+1, n+2, \hdots$
modulo $2^{32}$
\item decoding from any AU header 
\end{itemize}
\end{comment}

Reference picture numbers are encoded differentially with respect to the
picture number:

\begin{pseudo}{reference\_picture\_numbers}{}
\bsCODE{\RefOneNum=(\PictureNumber+read\_sint())\%2^{32}}
\bsIF{num\_refs() == 2}{\ref{parseinfo}}
    \bsCODE{\RefTwoNum=(\PictureNumber+read\_sint())\%2^{32}}
\bsEND
\end{pseudo}


The retired picture list is a list of pictures to be removed from the reference picture
buffer after the current picture is decoded. The rules for the use of the retired
picture list are specified in Section \ref{refbuffer}.
The list of retired picture numbers is also encoded differentially with respect to the
picture number:

\begin{pseudo}{retired\_picture\_list}{}
\bsITEM{num\_retired\_pictures}{uint}{}
\bsFOR{i = 0}{num\_retired\_pictures - 1}
    \bsCODE{\RetiredPictureList[i]=(\PictureNumber+read\_sint())\% 2^{32}}
\bsEND
\end{pseudo}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Picture prediction data}
\label{pictureprediction}

This section specifies the $picture\_prediction()$ process for parsing picture prediction data.
The process consists of two parts: extracting picture prediction parameters and
decoding and extracting motion vector fields for motion compensation, as follows:

\begin{pseudo}{picture\_prediction}{}
\bsCODE{picture\_prediction\_parameters()}{\ref{picpredparams}}
\bsCODE{byte\_align()}
\bsCODE{block\_data()}{\ref{motiondec}}
\end{pseudo}

The decoding and generation of block motion vector fields is specified in Section \ref{motiondec}. 
The remainder of this section is concerned
with the overall structure of the picture prediction data and the process for parsing and setting picture
prediction parameters, including global motion parameters.

The two elements of the picture prediction process correspond to two elements of the Dirac stream,
the picture prediction parameters and the block motion data. Global motion parameters
are used to construct a global motion vector field, and block motion data is used to provide
motion vectors block-by-block. Both elements may not be present, depending upon flags
signalled within the stream.

\subsubsection{Picture prediction parameters}
\label{picpredparams}

Picture prediction parameters consist of metadata required for successful parsing of the
motion data and for performing motion compensation. It includes data indicating whether
and how global motion is used, the size of blocks, and the weightings used for reference
pictures in motion compensation (Section \ref{motioncompensate}).

\begin{pseudo}{picture\_prediction\_parameters}{}
\bsCODE{block\_parameters()}{\ref{blockparameters}}
\bsCODE{motion\_vector\_precision()}{\ref{mvprecision}}
\bsCODE{global\_motion()}{\ref{globalmotion}}
\bsCODE{picture\_prediction\_mode()}{\ref{picpredmode}}
\bsCODE{reference\_picture\_weights()}{\ref{refpicweights}}
\end{pseudo}

\subsubsection{Block parameters}
\label{blockparameters}

This Section specifies the operation of the $block\_parameters()$ process for
setting the block parameters, consisting of the state variables
$\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$
defining luma blocks, and $\ChromaXBlen$, $\ChromaYBlen$, $\ChromaXBsep$,
and $\ChromaYBsep$ defining chroma blocks. 

Before this process is invoked, default block parameters are set by the video
format encoded in the Access Unit header (Section \ref{auheader}). These may
be temporarily overridden for the current picture if a flag is set, either by
a preset or by explicit signalling:

\begin{pseudo}{block\_parameters}{}
\bsITEM{block\_params\_flag}{bool}{}
\bsIF{block\_params\_flag}
    \bsITEM{index}{uint}
    \bsIF{index == 0}
        \bsITEM{\LumaXBLen}{uint}{}
        \bsITEM{\LumaYBLen}{uint}{}
        \bsITEM{\LumaXBSep}{uint}{}
        \bsITEM{\LumaYBSep}{uint}{}
    \bsELSE
       \bsCODE{preset\_block\_params(index)}
    \bsEND
\bsEND
\bsCODE{chroma\_block\_params()}{\ref{chromablockparams}}
\end{pseudo}

$index$ shall fall in the range 0 to 4. $preset\_block\_params(index)$ sets the transfer function as specified
in Table \ref{blockparamsvalues} (note that chroma block parameter values are computed from luma values
in Section \ref{chromablockparams}).

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
             & \multicolumn{4}{|c|}{{\bf Block parameters}}\\
\hline
$index$  & \LumaXBlen & \LumaYBlen & \LumaXBsep & \LumaYBsep \\
\hline
1 & 8 & 8 & 4 & 4 \\
\hline
2 & 12 & 12 & 8 & 8\\
\hline
3 & 16 & 16 & 12 & 12\\
\hline
4 & 24 & 24 & 16 & 16\\
\hline
\end{tabular}
\caption{Luma block parameter presets}\label{blockparamsvalues}
\end{table}

Block parameters shall satisfy the following constraints:

\begin{enumerate}
\item $\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$ shall all be positive
multiples of 4
\item $\LumaXBlen\geq\LumaXBsep$ and $\LumaYBlen\geq\LumaYBsep$
\item $\LumaXBlen\leq 2*\LumaXBsep$ and $\LumaYBlen\leq 2*\LumaYBsep$
\item $\LumaXBlen-\LumaXBsep$ and $\LumaYBlen-\LumaYBsep$ shall be
powers of 2 (i.e. 0 or $2^k$, $k\geq 2$ by 1.)
\end{enumerate}

\begin{comment}
These block constraints are now implemented in the software and non-overlapped blocks are supported.
\end{comment}

\begin{informative}
Note that these requirements do not preclude length from equalling separation, i.e.
motion compensation blocks are not overlapped. 
\begin{comment}
[NB: software currently crashes in this case!]
\end{comment}
\end{informative}

\subsubsection{Setting chroma block parameters}
\label{chromablockparams}

This section specifies the operation of the $chroma\_block\_params()$ process, which
determines chroma block dimensions from luma block dimensions. Chroma block parameters
are equal to the corresponding luma block parameters scaled according to the chroma
vertical and horizontal subsampling ratios. In this way chroma blocks and luma blocks are
co-located in the video picture.

\begin{pseudo}{chroma\_block\_params}{}
\bsCODE{\ChromaXBlen=\LumaXBlen//chroma\_h\_ratio()}
\bsCODE{\ChromaYBlen=\LumaYBlen//chroma\_v\_ratio()}
\bsCODE{\ChromaXBsep=\LumaXBsep//chroma\_h\_ratio()}
\bsCODE{\ChromaYBsep=\LumaYBsep//chroma\_v\_ratio()}
\end{pseudo}

\subsubsection{Motion vector precision}
\label{mvprecision}

This section specifies the $motion\_vector\_precision()$ process for setting
the precision (number of sub-pixel accuracy bits) used for motion compensation.

\begin{pseudo}{motion\_vector\_precision}{}
\bsITEM{motion\_vector\_precision\_flag}{bool}
\bsIF{motion\_vector\_precision\_flag==\true}
    \bsITEM{\MotionVectorPrecision}{uint}
\bsEND
\end{pseudo}

$\MotionVectorPrecision$ shall lie in the range 0 (pixel-accurate) to 3 (1/8th-pixel accurate).

\subsubsection{Global motion}
\label{globalmotion}

Global motion parameters are encoded if a flag is set. Up to two sets are encoded,
depending upon the number of references:

\begin{pseudo}{global\_motion}{}
\bsITEM{\PictureUsingGlobal}{bool}{}
\bsIF{\PictureUsingGlobal==\true}
    \bsCODE{global\_motion\_parameters(\GlobalParams[1])}
    \bsIF{num\_refs() == 2}
        \bsCODE{global\_motion\_parameters(\GlobalParams[2])}
    \bsEND
\bsEND
\end{pseudo}

\begin{comment}
[NB: there is now no $global\_motion\_only$ flag, since we will in practice always have to
signal block modes]
\end{comment}

Global motion parameters $\GlobalParams$ consist of three elements: 

\begin{itemize}
\item an integer pan/tilt vector 
\begin{equation*}
{\bf b}=\left(
\begin{array}{c} b_0 \\ 
b_1
\end{array}\right)
\end{equation*}
\item an integer matrix element 
\begin{equation*}
{\bf A}=\left( 
\begin{array}{cc}
 A_{0,0} & A_{0,1} \\
 A_{1,0} & A_{1,1} 
\end{array}\right)
\end{equation*}
capturing zoom, rotation and shear, together with a scaling exponent
\item an integer perspective element 
\begin{equation*}
{\bf c}=\left(
\begin{array}{c} c_0 \\ 
c_1
\end{array}
\right)
\end{equation*}
 capturing the effect of non-orthogonal projection onto the image plane, together 
with a scaling exponent
\end{itemize}

Their interpretation and the process for generating a global motion vector field is specified in Section \ref{globalmv}. 
These elements are parsed in turn:

\begin{pseudo}{global\_motion\_parameters}{gparams}
\bsCODE{pan\_tilt(gparams)}
\bsCODE{zoom\_rotate\_shear(gparams)}
\bsCODE{perspective(gparams)}
\end{pseudo}

The $pan\_tilt()$ process  extracts horizontal and vertical translation elements:

\begin{pseudo}{pan\_tilt}{gparams}
\bsCODE{gparams.{\bf b}={\mathbf{0}} }
\bsITEM{nonzero\_pan\_tilt\_flag}{bool}{}
\bsIF{nonzero\_pan\_tilt\_flag==\true}
    \bsITEM{gparams.{\bf b}_0}{sint}{}
    \bsITEM{gparams.{\bf b}_1}{sint}{}
\bsEND
\end{pseudo}

The $zoom\_rotate\_shear()$ process extracts a linear matrix element:

\begin{pseudo}{zoom\_rotation\_shear}{gparams}
\bsITEM{nontrivial\_zrs\_flag}{bool}{}
\bsIF{nontrivial\_zrs\_flag==\true}
    \bsITEM{gparams[ZRS\_exp]}{uint}{}
    \bsITEM{gparams.{\bf A}_{0,0}}{sint}{}
    \bsITEM{gparams.{\bf A}_{0,1}}{sint}{}
    \bsITEM{gparams.{\bf A}_{1,0}}{sint}{}
    \bsITEM{gparams.{\bf A}_{1,1}}{sint}{}
\bsELSE
    \bsCODE{gparams[ZRS\_exp]=0}
    \bsCODE{gparams.{\bf A}=\left(\begin{array}{cc} 1 & 0 \\ 0 & 1 \end{array}\right)}
\bsEND
\end{pseudo}

The $perspective()$ process extracts horizontal and vertical perspective
elements:

\begin{pseudo}{perspective}{gparams}
\bsITEM{nonzero\_perspective\_flag}{bool}{}
\bsIF{nonzero\_perspective\_flag==\true}
    \bsITEM{gparams[perspective\_exp]}{uint}{}
    \bsITEM{gparams.{\bf c}_0}{sint}{}
    \bsITEM{gparams.{\bf c}_1}{sint}{}
\bsELSE
    \bsCODE{gparams[perspective\_exp]=0}
    \bsCODE{gparams.{\bf c}={\mathbf{0}} }
\bsEND
\end{pseudo}

\subsubsection{Picture prediction mode}
\label{picpredmode}

The picture prediction mode encodes alternative methods of motion compensation.

\begin{pseudo}{picture\_prediction\_mode}{}
\bsITEM{pic\_pred\_mode\_flag}{bool}
\bsIF{pic\_pred\_mode\_flag==\true}
    \bsITEM{\PicturePredictionModeIndex}{uint}
\bsELSE
    \bsCODE{\PicturePredictionModeIndex=0}
\end{pseudo}

$\PicturePredictionModeIndex$ shall be 0.
\begin{comment}
[Express this better. Do we want this is a video format default? Maybe.]
\end{comment}

\subsubsection{Reference picture weight values}
\label{refpicweights}

Alternative reference picture weight values may be defined to override the
video format defaults:

\begin{pseudo}{reference\_picture\_weights}{}
\bsITEM{non\_default\_weights\_flag}{bool}
\bsIF{non\_default\_weights\_flag==\true}
    \bsITEM{\RefsWeightPrecision}{uint}
    \bsITEM{\RefOneWeight}{sint}
    \bsIF{\textit{num\_refs} == 2}
        \bsITEM{\RefTwoWeight}{sint}
    \bsEND
\bsEND
\end{pseudo}

For bi-directional prediction modes, reference 1 data will be weighted by 

$\dfrac{\RefOneWeight}{2^\RefsWeightPrecision}$

and reference 2 data by

$\dfrac{\RefTwoWeight}{2^\RefsWeightPrecision}$ 

(see Section \ref{pixelpredict}). 

\begin{informative}
Note that the picture weights are signed integers and may be negative. In
addition, they may not sum to $2^\RefsWeightPrecision$, to accomodate fade
prediction.
\end{informative}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wavelet transform data}
\label{wavelettransform}
The $wavelet\_transform()$ function parses wavelet transform meta-data (wavelet 
depth, filter type etc) and unpacks wavelet coefficients.

Decoded wavelet transform coefficient data is stored in the state
variables $\YTransform$, $\COneTransform$ and $\CTwoTransform$ for subsequent
processing using the inverse wavelet transform (Section \ref{idwt}).

\begin{pseudo}{wavelet\_transform}{}
\bsCODE{\ZeroResidual = \false}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsITEM{\ZeroResidual}{bool}
\bsEND
\bsIF{\ZeroResidual == \false}
    \bsCODE{transform\_parameters()}{\ref{transformparameters}}
    \bsCODE{byte\_align()}
    \bsCODE{transform\_data()}{\ref{wltunpacking}}
\bsEND
\end{pseudo}

If $\ZeroResidual=\true$ then all component pixels will be set to zero prior to
motion compensation (Section \ref{picturedec}).

Wavelet coefficients have been encoded using entropy coding, and their
decoding is specified in Section \ref{transformdec}. The remainder of this
section specifies the decoding of transform parameters.

\subsubsection{Wavelet transform parameters}
\label{transformparameters}

The wavelet transform parameters encode the filter to be used, the depth of filtering
and  (if low-delay syntax is not being used) how subbands are spatially partitioned:

\begin{pseudo}{transform\_parameters}{state}
\bsCODE{wavelet\_filter()}{\ref{wltfilter}}
\bsCODE{wavelet\_depth()}{\ref{wltdepth}}
\bsIF{is\_low\_delay()==\false}
    \bsCODE{spatial\_partition()}{\ref{spatialpartition}}
\bsELSE
    \bsCODE{slice\_parameters()}{\ref{sliceparams}}
    \bsCODE{quant\_matrix()}{\ref{quantmatrix}}
\bsEND
\end{pseudo}

\paragraph{Wavelet filters}
\label{wltfilter}
$\ $\newline
A variety of preset wavelet filters are available, encoded as a 
values of $\WaveletIndex$, which is an index into
Table \ref{wltfilterpresets}. Default wavelet filters
are the Deslauriers-Debuc (9,7) filter for intra pictures
and the LeGall (5,3) filter for inter pictures. If a flag is
set, other presets may be used. Their interpretation and lifting 
implementations are specified in Section \ref{wltfilters}. 

\begin{pseudo}{wavelet\_filter}{}
\bsITEM{\WaveletIndex}{uint}
\end{pseudo}

$\WaveletIndex$ shall lie in the range 0 to 6. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\WaveletIndex & {\bf Filter} \\
\hline
0 & Deslauriers-Debuc (9,7) \\
\hline
1 & LeGall (5,3) \\
\hline
2 & Deslauriers-Debuc (13,7) \\
\hline
3 & Haar with no shift \\
\hline
4 & Haar with single shift per level\\
\hline
5 & Fidelity filter \\
\hline
6 & Daubechies (9,7) integer approximation \\
\hline
\end{tabular}
\caption{Wavelet filter presets}\label{wltfilterpresets}
\end{table}

\begin{informative}
For consistency, the filter nomenclature $(m, n)$ refers to the length of the analysis low-pass
and high-pass filters in the conventional prefiltering (i.e. before subsampling) 
model of wavelet filtering. They do not reflect the length of lifting filters, which
operate in the subsampled domain: see Section \ref{wltfilters}. Deslauriers-Debuc
filters are normally referred to in terms of the number of vanishing moments of their
synthesis filters, so the (9,7) and (13,7) filters may be referred to in the literature
as (2,2) and (4,2) filters respectively.
\end{informative}

\subsubsection{Wavelet depth}
\label{wltdepth}

The wavelet depth determines the number of times the vertical and horizontal
wavelet filters may be applied. The $wavelet\_depth()$ parsing process is as
follows:

\begin{pseudo}{wavelet\_depth}{}
\bsITEM{\WaveletDepth}{uint}
\end{pseudo}

Allowable $\WaveletDepth$ values are determined by the level and profile 
(Appendix \ref{profilelevel}). The wavelet depth determines the number of 
subbands and the the dimensions of the subband data array (Section \ref{wltinit}).

\subsubsection{Spatial partition of wavelet data (core syntax)}
\label{spatialpartition}

Each subband may be partitioned into a number of code blocks. The number of codeblocks
to be used for subbands at level $level$ is encoded in $\Codeblocks[level][v]$ and
$\Codeblocks[level][h]$ respectively. 

\begin{pseudo}{spatial\_partition}{}
\bsCODE{\CodeblockMode=0}
\bsITEM{spatial\_partition\_flag}{bool}
\bsIF{spatial\_partition\_flag==\false}
    \bsFOR{level=0}{\WaveletDepth}
        \bsCODE{\Codeblocks[level][h]=1}
        \bsCODE{\Codeblocks[level][v]=1}
    \bsEND
\bsELSE
    \bsFOR{level=0}{\WaveletDepth}
        \bsITEM{\Codeblocks[level][h]}{uint}
        \bsITEM{\Codeblocks[level][v]}{uint}
    \bsEND
    \bsITEM{\CodeblockMode}{uint}
\bsEND
\end{pseudo}

$\CodeblockMode$ shall lie in the range 0 to 1, whose meanings are as shown in Table \ref{codeblockmodes}. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
 $\CodeblockMode$ & {\bf Description} \\
\hline
0 & Single Quantiser \\
\hline
1 & Multiple Quantiser \\
\hline
\end{tabular}
\caption{Codeblock modes}\label{codeblockmodes}
\end{table}

\subsubsection{Slice parameters and dimensions (low delay syntax)}
\label{sliceparams}

This section specifies the $slice\_parameters()$ process for parsing the width, height and bit allocation of 
the slices. This process is invoked if $is\_low\_delay()==\true$.There are no default slice parameters -- these parameters are always explicitly encoded as follows:

\begin{pseudo}{slice\_parameters}{}
\bsITEM{width\_exp}{uint}
\bsCODE{\SliceWidth=2^{width\_exp}}
\bsITEM{height\_exp}{uint}
\bsCODE{\SliceHeight=2^{height\_exp}}
\bsITEM{\SliceBytesNum}{uint}
\bsITEM{\SliceBytesDenom}{uint}
\end{pseudo}

The ratio
\[b=\dfrac{\SliceBytesNum}{\SliceBytesDenom}\]
is the mean number of bytes per slice. The actual slice allocation is either $\lfloor b \rfloor$
or $\lceil b \rceil$ depending on the slice index (Section \ref{slicebytes}).

If $is\_low\_delay()==\true$, the following constraints are placed upon the slice dimensions 
and the wavelet depth:
 
\begin{itemize}
\item $\SliceWidth$ and $\SliceHeight$ shall both be divisible by $2^\WaveletDepth$
\begin{comment}
\item If $is\_inter()==\true$, $\SliceWidth$ shall be divisible by $4*\LumaXBsep$ and $\SliceHeight$ shall be divisible by $4*\LumaYBsep$
\end{comment}
\item Chroma and luma subbands must contain corresponding levels of padding, i.e. for all orientations $orient$ and levels $l$,
\begin{eqnarray*}
\width(\YTransform[l][orient]) & = & chroma\_h\_ratio()*\width(\COneTransform[l][orient]) \\
& = & chroma\_h\_ratio()*\width(\CTwoTransform[l][orient]) \\
\height(\YTransform[l][orient]) & = & chroma\_v\_ratio()*\height(\COneTransform[l][orient]) \\
& = & chroma\_v\_ratio()*\height(\CTwoTransform[l][orient]) \\
\end{eqnarray*}
\end{itemize}

These restrictions ensure that both wavelet coefficients and (if present) motion data superblocks may be partitioned
correctly by the slices. For example, the last condition restricts the transform depth to be at most 3 on $720\times 576$ 4:2:2 video
since a depth of 4 would lead to padding for chroma coefficients but not for luma, as $2^4=16$ divides 720 but not 360.

\subsubsection{Quantisation matrices (low-delay syntax)}
\label{quantmatrix}

This section specifies the operation of the $quant\_matrix()$ process for setting the $\QuantMatrix$ parameters.

\begin{pseudo}{quant\_matrix}{}
\bsITEM{non\_default\_quant\_matrix}{bool}
\bsIF{non\_default\_quant\_matrix==\true}
    \bsITEM{\QuantMatrix[0][\LL]}{uint}
    \bsFOR{level=1}{\WaveletDepth}
        \bsITEM{\QuantMatrix[level][\HL]}{uint}
        \bsITEM{\QuantMatrix[level][\LH]}{uint}
        \bsITEM{\QuantMatrix[level][\HH]}{uint}
    \bsEND
\bsELSE
    \bsCODE{set\_quant\_matrix()}
\bsEND
\end{pseudo}

The function $set\_quant\_matrix()$ sets default quantisation matrices for $\WaveletDepth\leq4$ and certain values of $\WaveletIndex$, as per Table \ref{presetqmatrices}. For values not represented in this table, $non\_default\_quant\_matrix$ shall be $\True$ (custom quantisation matrix). 
 
\begin{informative}
Default quantisation matrices are ``unweighted'', and intended only to compensate for the differential power gain of the high-pass and low-pass filters. Perceptual weighting may be applied by designing a custom matrix as described in Appendix \ref{custommatrices}.
\end{informative} 
