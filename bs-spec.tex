%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% - This chapter defines the bytestream structure - %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{streamstructure}

This section specifies the overall structure of Dirac streams. 
Subsequent sections define the processes for 
parsing pictures, and Section \ref{picturedec} specifies how pictures 
are decoded.

\subsection{Pseudocode}
The parsing process is normatively defined using pseudocode and/or mathematical formulae.
 The definitions of stream syntax operations and pseudocode shall be as defined in 
section \ref{spec-conventions}. 

The Dirac stream syntax uses a state model to express the stream in a way that can 
be parsed and used for decoding operations. The parsing and decoding operations are 
specified in terms of modifying the decoder state according to the data extracted 
from the Dirac stream. The state of the decoder is stored in the global variable $\StateName$.
 This is a map (Section \ref{datatypes}) and individual elements are accessed by 
means of named labels, e.g. $\StateName[\text{VAR\_NAME}]$. 
The state variables comprise the parameters that shall be used in parsing and decoding a picture. 
The variable $\StateName$ is a global variable and shall be accessible to all decoder functions and processes. 
All other variables shall be local to the function or process in which they are defined.

Decoder state variables (that is elements of state) may not directly correspond 
to parts of the stream, but may be calculated from them taking into account the 
decoder state as a whole. For example, a state variable value may be differentially 
encoded with respect to another value, with the difference, not the variable itself, 
encoded in the stream. Some parameters are encoded in the stream as indices
 to tables of values. The indices are coded as variable length integers. 
This allows the tables to be extended to contain new entries, in future versions 
of this specification, without changing the syntax.


\subsection{Stream}
\label{stream}

A stream is a concatenation of Dirac sequences. The process for parsing a stream 
is to parse all sequences it contains. A Dirac sequence shall be decoded as a separate entity.

\subsection{Sequence}

The data contained in a Dirac sequence corresponds to a single video sequence with
constant video parameters as defined in Sections \ref{sourceparameters}. A sequence
 A Dirac sequence can be excised from a Dirac stream and decoded entirely
independently.

A Dirac sequence shall comprise an alternating sequence of parse info headers and 
data units. The first data unit shall be a sequence header, and further sequence 
headers may be inserted at any data unit point in the sequence . 
The process for parsing a Dirac sequence shall be as defined below:

\begin{pseudo}{parse\_sequence}{}
\bsCODE{\StateName=\{\}}
\bsCODE{\RefBuffer=\{\}}
%\bsCODE{\DecodedBuffer=\{\}}
\bsCODE{parse\_info()}{\ref{parseinfoheader}}
\bsCODE{\VideoParams=sequence\_header()}{\ref{sequenceheader}}
\bsCODE{parse\_info()}{\ref{parseinfoheader}}
\bsWHILE {is\_end\_of\_sequence()==\false}{\ref{parsecodevalues}}
    \bsIF{is\_seq\_header()==\true}{\ref{parsecodevalues}}
        \bsCODE{\VideoParams=sequence\_header()}{\ref{sequenceheader}}
    \bsELSEIF{is\_picture()}{\ref{parsecodevalues}}
        \bsCODE{picture\_parse()}{\ref{pictureparse}}
    \bsELSEIF{is\_auxiliary\_data()}{\ref{parsecodevalues}}
        \bsCODE{auxiliary\_data()}{\ref{auxdata}}
    \bsELSEIF{is\_padding()}{\ref{parsecodevalues}}
        \bsCODE{padding()}{\ref{paddingdata}}
    \bsEND
    \bsCODE{parse\_info()}{\ref{parseinfoheader}}
\bsEND
\end{pseudo}

Each Dirac sequence shall start and end with a parse info header. 

\subsection{Parse Info headers}

Parse info headers shall contain a 32 bit code so that the decoder can 
be synchronized with the stream. They are defined in section \ref{parseinfoheader}.
The parse info headers support navigating through the stream without the 
need to decode any data units. Each parse info header contains pointers 
to the location of the next and previous parse info headers within the stream. 
The stream may thus be thought of as a doubly linked list of data units.
Each parse info headers contains a code that identifies the type of data held 
in the following data unit. This is the only information contained within
the parse info headers that is needed to decode the sequence.

\subsection{Data units}

Data units may be one of:
\begin{itemize}
\item a sequence header, 
\item a picture, 
\item auxiliary data 
\item padding data. 
\end{itemize}

A sequence header shall contain metadata describing the coded sequence 
and metadata needed to decode the stream. The sequence header is defined 
in Section \ref{sequenceheader}. The first data unit in a sequence shall be a 
sequence header. To support reverse-parsing applications, the last data unit in 
a sequence should also be a sequence header.

Each sequence shall contain at least one picture and at least one sequence header.
The first picture after each sequence header (if there is one) shall be an intra picture.

If a sequence contains more than one sequence header, the data 
in each sequence header shall be the same (byte-for-byte identical) within the sequence.

Each picture, whether a frame or field, may be coded with a dependency 
on prior pictures in the stream (reference pictures).

A picture data unit shall contain sufficient data to decode a single picture 
(frame or field of video), subject to having parsed a sequence header within 
the sequence and decoded any reference pictures.

Pictures within a sequence shall either all be fields or all be frames. 
Where pictures are fields, a sequence shall contain an even number of pictures, 
comprising a whole number of frames.

Auxiliary data and padding data do not contribute to the decoding 
process and so may be discarded. 


Auxiliary and padding data units comprise undefined data for the purposes
 of this standard. These data units (together with the correct preceding 
parse info header) may be interposed at any point in the stream, but 
may safely be skipped by a compliant decoder. For the purposes of 
subsequent parts of this standard, the potential presence of auxiliary 
and padding data shall be ignored.

Padding data units shall not be used for any form of auxiliary data 
service or content. They may be used by an encoder, where required, 
to insert additional data to assist in complying with constant or constrained bit rate requirements.

\subsubsection{Auxiliary data}\label{auxdata}

The $auxiliary\_data()$ process for reading auxiliary data shall be as follows:

\begin{pseudo}{auxiliary\_data}{}
\bsCODE{byte\_align()}
\bsFOR{i=1}{\NextParseOffset-13}
    \bsCODE{read\_byte}
\bsEND
\end{pseudo}

\subsubsection{Padding data}\label{paddingdata}

The $padding()$ process for reading padding data shall be as follows:

\begin{pseudo}{padding}{}
\bsCODE{byte\_align()}
\bsFOR{i=1}{\NextParseOffset-13}
    \bsCODE{read\_byte}
\bsEND
\end{pseudo}

\subsection{Parse info header syntax}
\label{parseinfoheader}

The parse info header provides information identifying the subsequent data unit
type and length codes determining the number of bytes from the current parse
info header to the next and previous parse info headers.

The parse info header shall be byte-aligned. It shall occur:
\begin{itemize}
\item at the beginning of a sequence
\item at the end of a sequence
\item before each data unit
\end{itemize}

The parse info header shall consist of 13 whole bytes. Thus subsequent data elements
shall be byte aligned.

The value of the parse code, which is a component of the parse info header,
shall be used to determine the type and format of the subsequent data unit.

The $parse\_info()$ process for reading parse info headers shall be as follows:

\begin{pseudo}{parse\_info}{}
\bsCODE{byte\_align()}
\bsCODE{\ParseInfoPrefix=read\_uint\_lit(4)}
\bsCODE{\ParseCode=read\_byte()}
\bsCODE{\NextParseOffset=read\_uint\_lit(4)}
\bsCODE{\PrevParseOffset=read\_uint\_lit(4)}
\end{pseudo}

The Parse Info parameters shall satisfy the following constraints:

\begin{itemize}
\item $\ParseInfoPrefix$ shall be set to be 0x42 0x42 0x43 0x44, which is the character string ``BBCD'' as expressed by ISO/IEC 646.
\item $\ParseCode$ shall be one of the supported values set out 
in Table \ref{table:parsecodes}
\item $\NextParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the next Parse Info header, 
if there is one. If there
is no subsequent Parse Info header, it shall be be zero.
\item $\PrevParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the previous Parse Info header, 
if there is one. If there is no subsequent Parse Info header, it shall be be zero.
\end{itemize}

Consequently, the previous parse offset value of the current parse info header 
shall equal the next parse offset value of the previous parse info header, 
if there is one.

\begin{informative}
\begin{enumerate}
\item The parse info prefix, next parse offset and previous parse offset
values are provided to support navigation and are not required to decode
the sequence. See section \ref{nonsequential}.
\item The parse offset values will normally be non-zero. However at the beginning
and end of a stream there is no preceding or following parse info header respectively.
In these circumstances the value of the offset is zero: these are the only
places where zero values can occur.
\end{enumerate}
\end{informative}

\subsubsection{Parse code values}
\label{parsecodevalues}

Parse code values shall be divided into three sets: generic, 
core syntax and low delay
syntax.

The value of parse codes allowed within the Dirac syntax shall 
be as shown in Table \ref{table:parsecodes}

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|l|c|}
\hline
\rowcolor[gray]{0.75}
\ParseCode &  {\bf Bits} & {\bf Description} & \begin{tabular}{c} {\bf Number of}\\ {\bf Reference}\\{\bf Pictures}\end{tabular}\\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Generic}\\
\hline
0x00 & 0000 0000 & Sequence header &--\\
\hline
0x10 & 0001 0000 & End of Sequence & -- \\
\hline
0x20 & 0010 0000 & Auxiliary data & -- \\
\hline
0x30 & 0011 0000 & Padding data & -- \\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Core syntax}\\
\hline
0x0C & 0000 1100 & Intra Reference Picture (arithmetic coding) & 0\\
\hline
0x08 & 0000 1000 & Intra Non Reference Picture (arithmetic coding) & 0\\
\hline
0x4C & 0100 1100 & Intra Reference Picture (no arithmetic coding) & 0\\
\hline
0x48 & 0100 1000 & Intra Non Reference Picture (no arithmetic coding) & 0\\
\hline
0x0D & 0000 1101 & Inter Reference Picture (arithmetic coding) & 1\\
%\hline
%0x4D & 0100 1101 & Inter Reference Picture (no arithmetic coding) & 1\\
\hline
0x0E & 0000 1110 & Inter Reference Picture (arithmetic coding) & 2\\
%\hline
%0x4E & 0100 1110 & Inter Reference Picture (no arithmetic coding) & 2\\
\hline
0x09 & 0000 1001 & Inter Non Reference Picture (arithmetic coding)& 1\\
%\hline
%0x49 & 0100 1001 & Inter Non Reference Picture (no arithmetic coding) & 1\\
\hline
0x0A & 0000 1010 & Inter Non Reference Picture (arithmetic coding) & 2\\
%\hline
%0x4A & 0100 1010 & Inter Non Reference Picture (no arithmetic coding)& 2\\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Low-delay syntax}\\
\hline
0xCC & 1100 1100 & Intra Reference Picture & 0\\
\hline
0xC8 & 1100 1000 & Intra Non Reference Picture & 0\\
\hline
\end{tabular}
\caption{Parse codes}\label{table:parsecodes}
\end{table}

Future versions of this specification may introduce new parse codes. In order that 
decoders complying with this version of the specification may decode future 
versions of the coded stream, the decoder shall discard data units that immediately 
follow parse info blocks containing unknown parse codes. 

The parse codes shall be associated with a group of functions, listed below, which shall determine the type of subsequent data and the parsing and decoding processes which 
shall be used. All functions shall return a
boolean, except for $num\_refs()$ which shall returns an integer:

\begin{pseudo}{is\_seq\_header}{}
\bsRET{\ParseCode==\text{0x00}}
\end{pseudo}

\begin{pseudo}{is\_end\_of\_sequence}{}
\bsRET{\ParseCode==\text{0x10}}
\end{pseudo}

\begin{pseudo}{is\_auxiliary\_data}{}
\bsRET{(\ParseCode \& \text{0xF8})==\text{0x20}}
\end{pseudo}

\begin{pseudo}{is\_padding}{}
\bsRET{\ParseCode==\text{0x30}}
\end{pseudo}

\begin{pseudo}{is\_picture}{}
\bsRET{((\ParseCode \&\text{0x08})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{is\_low\_delay}{}
\bsRET{((\ParseCode \&\text{0x88})==\text{0x88})}
\end{pseudo}

\begin{pseudo}{is\_core\_syntax}{}
\bsRET{((\ParseCode \&\text{0x88})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{using\_ac}{}
\bsRET{((\ParseCode \&\text{0x48})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{is\_reference}{}
\bsRET{((\ParseCode \&\text{0x0C})==\text{0x0C})}
\end{pseudo}

\begin{pseudo}{is\_non\_reference}{}
\bsRET{((\ParseCode \&\text{0x0C})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{num\_refs}{}
\bsRET{(\ParseCode \&\text{0x03})}
\end{pseudo}

\begin{pseudo}{is\_intra}{}
\bsRET{is\_picture() \text{ and } (num\_refs()==0)}
\end{pseudo}

\begin{pseudo}{is\_inter}{}
\bsRET{is\_picture() \text{ and }(num\_refs()>0)}
\end{pseudo}

\begin{informative*}
\subsubsection{Parse code value rationale (Informative)}

The rationale for the parse code values in Table \ref{table:parsecodes} is as follows:
\begin{itemize}
\item The MS bit (bit 7) is used to indicate the picture syntax (core or low delay syntax) 
and only applies to pictures. Core syntax codes whole frames rather than slices. Low delay syntax codes slices not frames. 
\item The second MS bit (bit 6) is used to indicate whether arithmetic coding is used and
only applies to pictures. Core syntax may optionally use arithmetic coding. Low delay
syntax does not use arithmetic coding. The permutation of the two bits which
might indicate low delay syntax with arithmetic coding is reserved. Only arithmetic coding is supported on
Inter pictures.
\item The next three MS bits (bits 5, 4 and 3) indicate the type of data unit following the parse info unit. Bit 3 indicates whether it is a picture or non-picture data unit. Bits 5 and 4 indicate the 4 other parse codes.
\item The three LS bits (bits 2, 1 and 0) indicate picture types. Bit 2 indicates whether a picture
is a reference picture or not. Bits 0 and 1 indicate the number of references a picture has
for motion compensation purposes: if these are both 0, the picture is an Intra picture.
\end{itemize}

\end{informative*}

\clearpage
\section{Sequence header}
\label{sequenceheader}

This section defines the structure of the sequence header syntax. 
The sequence header shall be byte aligned. 
Parsing this header consists of reading the sequence parameters 
(parse parameters, base video format, source parameters and 
picture coding mode) and initializing the decoder parameters. The decoder 
parameters are initialized in the $set\_coding\_parameters()$ process (Section 
\ref{codingparameters}).

The sequence header shall remain byte identical throughout a sequence.

The process for parsing the sequence header shall be as follows:

\begin{pseudo}{sequence\_header}{}
\bsCODE{byte\_align()}
\bsCODE{parse\_parameters()}{\ref{parseparameters}}
\bsITEM{base\_video\_format}{uint}{\ref{videoformat}}
\bsCODE{\VideoParams=source\_parameters(base\_video\_format)}{\ref{sourceparameters}}
\bsITEM{picture\_coding\_mode}{uint}{\ref{picturecodingmode}}
\bsCODE{set\_coding\_parameters(\VideoParams,picture\_coding\_mode)}{\ref{codingparameters}}
\bsRET{\VideoParams}
\end{pseudo}

Parse parameters contain information a decoder may use to determine whether 
it is able to parse or decode the stream. Parse parameters are not used to decode the stream.

The base video format is a numerical index denoting a default set of parameters 
that describe the video source. For many common video formats the predefined 
values indicated by the base video format and defined in Annex \ref{videoformatdefaults}, will be sufficient 
without the need for further metadata to be present in the stream. However, to provide 
flexibility, source parameters may override the parameters indicated 
by the base video format (with the exception of the top field first flag).

Source parameters are parameters that describe the source video, not all of 
which are required to decode the stream. The source parameters are needed by 
applications that use the decoded video and so should be made available to them.

The picture coding mode indicates whether the video has been coded as a sequence 
of frames or fields.

Once the base video format, source parameters and picture coding mode have 
been read from the stream the information they contain may be decoded to 
provide the parameters used for decoding pictures. It is the purpose of the 
$set\_coding\_parameters()$ process to initialize these parameters.

\begin{informative}
Note that video parameters indicate whether the video sequence is interlaced or progressive.
In particular a change from interlaced to progressive video, or vice-versa, necessitates that
the Dirac sequence be terminated and a new sequence begun. The coding mode indicates whether
the pictures within a Dirac sequence are fields or frames. Note that progressive video may
still be encoded as fields, to provide backward compatibility with pseudo-progressive frame (PSF)
video transmission.

The video parameters are not used by the Dirac decoder. Video parameter values should
be made available using appropriate interfaces and standards to any downstream video
processing device or display, but their use and interpretation by other devices is not specified in this standard. 
Neverthless, Annex \ref{vidsys} specifies the video systems model that should be used for the interpretation
of video parameters.
\end{informative}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parse parameters}
\label{parseparameters}

This section specifes the structure of the parse parameters, which is as follows:

\begin{pseudo}{parse\_parameters}{}
\bsITEM{\VersionMajor}{uint}{}
\bsITEM{\VersionMinor}{uint}{}
\bsITEM{\Profile}{uint}{}
\bsITEM{\Level}{uint}{}
\end{pseudo}

Parse parameter data shall be constant (byte-for-byte identical) for all instances 
of the sequence header within a Dirac sequence. For stream interchange, parse
paramter data should also be constant across all sequences within a stream.

\subsubsection{Version number}

The major version number shall define the version of the syntax with 
which the stream complies. A decoder complies with a major version 
number if it can parse all bit streams that comply with 
that version number. Decoders that comply with a major version of 
the specification may not be able to parse the bit stream corresponding 
to a later specification.

Depending on the profile and level defined, a decoder compliant 
with a given major version number may still not be able to decode 
fully all parts of a stream.

All minor versions of the specification shall be functionally compatible 
with earlier minor versions with the same major version number. Later minor 
versions may contain corrections, clarifications, and removal of ambiguities. 
Later minor version numbers shall not contain new features or new 
normative provisions.

Functional compatibility shall imply that a decode with the same major version
number but a later minor version number than that contained in a stream, shall
be capable of decoding the stream and producing pictures substantially equivalent
to that of a decoder with the same version numbers as the stream.

The major version number of a stream compliant with this version 
of the Dirac specification shall be \MajorVersion.

The minor version number of a stream compliant with this version 
of the Dirac specification shall be \MinorVersion.


\subsubsection{Profiles and levels}

A profile shall define the toolset that is sufficient to decode a sequence. 

A level shall determine decoder resources (picture and data buffers; computational resources) sufficient
to decode a sequence, including the sizes $\RefBufferSize$ and $\DPBSize$ of 
the reference picture and decoded picture buffers. 

Applicable values of profile and level and the variables they set are specified in Annex
\ref{profilelevel}.

\subsection{Base video format}
\label{videoformat}

The value of $base\_video\_format$ decoded in parsing the sequence header shall be 
an index into table \ref{table:videoformats}. For each entry in the table 
parameters are defined, in annex \ref{videoformatdefaults}, indicating base
video parameters corresponding to one of a set of predefined formats. 

The selection of a base format represents an initial approximation to the video
format which can then be refined to capture all the video format characteristics
accurately by overriding parameters as necessary. In particular, the predefined
video formats listed in table \ref{table:videoformats} do not represent all the 
video formats supported by Dirac; any video format parameters may in principle be
defined and supported by Dirac sequence.

These base parameters may be modified by subsequent metadata present in the stream, 
with the exception of the top field first parameter which shall only be set 
by the base video format (see Section \ref{scanformat}).

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}Video format index	& Video format description \\
\hline
0	& Custom Format\\
\hline
1	&	QSIF525\\
\hline
2	&	QCIF\\
\hline
3	&	SIF525\\
\hline
4	&	CIF\\
\hline
5	&	4SIF525\\
\hline
6	&	4CIF\\
\hline
7	&	SD 480I-60 (525 Line 59.94 Field/s Standard Definition)\\
\hline
8	&	SD 576I-50 (625 Line 50 Field/s Standard Definition)\\
\hline
9	&	HD 720P-60 (720 Line 59.94 Frame/s High Definition)\\
\hline
10 &	HD 720P-50 (720 Line 50 Frame/s High Definition)\\
\hline
11 &	HD 1080I-60 (1080 Line 60 Field/s High Definition)\\
\hline
12	&	HD 1080I-50 (1080 Line 50 Field/s High Definition)\\
\hline
13	&	HD 1080P-60 (1080 Line 59.94 Frame/s High Definition)\\
\hline
14	&	HD 1080P50 (1080 Line 50 Frame/s High Definition)\\
\hline
15	&	DC 2K-24 (2K D-Cinema, 24fps)\\
\hline
16	&	DC 4K-24 (4K D-Cinema, 24fps)\\
\hline
17	&	UHDTV 4K-60 (2160-line 59.94 Frame/s UHDTV)\\
\hline
18	&	UHDTV 4K-50 (2160-line 50 Frame/s UHDTV)\\
\hline
19	&	UHDTV 8K-60 (4320-line 59.94 Frame/s UHDTV)\\
\hline
20	&	UHDTV 8K-50 (4320-line 50 Frame/s UHDTV)\\
\hline
\end{tabular}
\caption{Dirac predefined video formats}
\label{table:videoformats}
\end{table}

\begin{informative}
\begin{enumerate}
\item The custom format is intended for use when no other suitable base video 
format is available from the table. Video format defaults will still be set as 
per annex \ref{videoformatdefaults}, but these are token values which are expected 
to be almost wholly overridden by the subsequent source parameters. 
\item The base video format ought to be as close as possible to the desired video
format, especially in terms of picture dimensions and frame rate.
\item True 60Hz formats can be encoded by overriding the frame rate parameters
(section \ref{framerate}).
 \end{enumerate}
\end{informative}

\subsection{Source parameters}
\label{sourceparameters}

The source parameters are intended to indicate the format of the video that was 
originally encoded. They provide metadata that indicates how the decoded video
should be displayed. 

The source parameters shall comprise frame size, chroma sampling format, 
scan format, frame rate, pixel aspect ratio, clean area, signal range 
and colour specification. The frame size, chroma sampling  format, 
scanning format and the signal range are required to decode the video. Display 
and downstream processing falls outside the scope of this specification, 
hence the interpretation of the other parameters (not required to decode 
the video) is not normatively defined, with the exception of frame rate 
(section \ref{framerate}). The frame rate may impose requirements on
 compliant decoders for a given level and profile (Annex \ref{profilelevel}).

Source parameter data shall remain constant throughout a Dirac sequence. 

Default values for the source parameters shall be derived from the video 
format, as defined in annex \ref{videoformatdefaults}. These default 
values shall be the source parameters unless they are overridden 
with alternative values encoded 
as part of the Source Parameters part of the stream. 

The $source\_parameters()$ process shall return a structure defining 
the video source parameters. It shall be defined as follows:

\begin{pseudo}{source\_parameters}{base\_video\_format}
\bsCODE{\VideoParams = set\_source\_defaults(base\_video\_format)}{\ref{setsourcedefaults}}
\bsCODE{frame\_size(\VideoParams)}{\ref{framedimensions}}
\bsCODE{chroma\_sampling\_format(\VideoParams)}{\ref{chromaformat}}
\bsCODE{scan\_format(\VideoParams)}{\ref{scanformat}}
\bsCODE{frame\_rate(\VideoParams)}{\ref{framerate}}
\bsCODE{pixel\_aspect\_ratio(\VideoParams)}{\ref{aspectratio}}
\bsCODE{clean\_area(\VideoParams)}{\ref{cleanarea}}
\bsCODE{signal\_range(\VideoParams)}{\ref{signalrange}}
\bsCODE{colour\_spec(\VideoParams)}{\ref{colourspec}}
\bsRET{\VideoParams}
\end{pseudo}

\subsubsection{Setting source defaults}
\label{setsourcedefaults}

The function that sets the default values of the source video parameters 
shall take the video format index as an argument. That is, the signature of this 
function is: $set\_source\_defaults(base\_video\_format)$ where 
$base\_video\_format$ is an unsigned integer. The function returns a map 
of source video parameters.

The source video parameters shall be set, based on the video format index, 
as defined in annex \ref{videoformatdefaults}. The parameters set by this 
function shall be: frame size, sampling format (4:4:4, 4:2:2 or 4:2:0), 
scan format (progressive or interlace), frame rate, pixel aspect ratio, 
clean area, signal range, colour specification. The labels used to access the 
map returned by the function shall be as defined in the
subsequent sections that specify how to override the base video source 
parameters.

\subsubsection{Frame size}
\label{framedimensions}

The frame size decoding process shall be as follows:

\begin{pseudo}{frame\_size}{\VideoParams}
\bsITEM{custom\_dimensions\_flag}{bool}{}
\bsIF{custom\_dimensions\_flag==\true}
    \bsITEM{\SFrameWidth}{uint}{}
    \bsITEM{\SFrameHeight}{uint}{}
\bsEND
\end{pseudo}

Thus is $custom\_dimensions\_flag$ is $\true$, the frame size determined by the
base video format shall be overridden.

The frame width shall correspond to the width of the coded video, in pixels, that
is coded in the stream. The frame height shall correspond to the number of lines
per frame in the coded video, irrespective of whether the coded video is
progressively scanned or is interlaced.

\subsubsection{Chroma sampling format}
\label{chromaformat}

The chroma sampling format decoding process shall be as follows:

\begin{pseudo}{chroma\_sampling\_format}{\VideoParams}
\bsITEM{custom\_chroma\_format\_flag}{bool}{}
\bsIF{custom\_chroma\_format\_flag==\true}
     \bsITEM{\SChromaFormatIndex}{uint}{}
\bsEND
\end{pseudo}

Thus if $custom\_chroma\_format\_flag$ is $\true$ then the base video format
value is overridden.

The decoded value of $\SChromaFormatIndex$ shall lie in the range 0 to 2 with
values as defined in table \ref{tab:chromaformats}:

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}\SChromaFormatIndex & {\bf Chroma format} \\
\hline
0 & 4:4:4 \\
\hline
1 & 4:2:2 \\
\hline
2 & 4:2:0 \\
\hline
\end{tabular}
\caption{Supported chroma sampling formats}\label{tab:chromaformats}
\end{table}

The chroma sampling format shall be used to determine the width and height of the 
chroma components of the coded video as described in Section \ref{picturedimensions} below.

\subsubsection{Scan format}
\label{scanformat}

The scan format parameter shall indicate whether the source video 
represents progressive frames or interlaced fields.

The scan format decoding process shall be defined as follows:

\begin{pseudo}{scan\_format}{\VideoParams}
\bsITEM{custom\_scan\_format\_flag}{bool}{}
\bsIF{custom\_scan\_format\_flag==\true}
    \bsITEM{\SSourceSampling}{uint}{}
\bsEND
\end{pseudo}

If the custom scan format flag is set to $\true$, the source sampling 
parameter defined by the base video format values shall be overridden by new values.

If $\SSourceSampling$ is set to 0, then the source video shall be progressively 
sampled. If it is 1, then the source video shall be interlaced. Values greater than 1 shall be reserved.

If the source video is interlaced, then $\STopFieldFirst$ shall be $\true$ 
if the top line of the frame is in the earlier field, else $\STopFieldFirst$
 shall be $\false$. This shall be set only by the base video format and 
 cannot be overridden in the source parameters.

Both interlaced and progressive video may be coded as fields or frames.

\subsubsection{Frame rate}
\label{framerate}

The frame rate value (in frames per second) shall be 
$\SFrameRateNumer$ divided by $\SFrameRateDenom$

The process for decoding the frame rate parameters shall be as follows:

\begin{pseudo}{frame\_rate}{\VideoParams}
\bsITEM{custom\_frame\_rate\_flag}{bool}{}
\bsIF{custom\_frame\_rate\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SFrameRateNumer}{uint}{}
        \bsITEM{\SFrameRateDenom}{uint}{}
    \bsELSE
        \bsCODE{preset\_frame\_rate(\VideoParams,index)}
     \bsEND
\bsEND
\end{pseudo}

If $custom\_frame\_rate\_flag$ is set to $\true$ the frame rate parameters set
by the base video format shall be overridden by new values.

The decoded value of $index$ shall fall in the range 0 to 10.

If $index$ is 0, then the frame rate numerator and denominator shall be
individually defined by unsigned integer values.

For values greater than $0$, the process $preset\_frame\_rate(\VideoParams,index)$ 
shall set frame rate elements of $\VideoParams$ according to table \ref{table:frameratevalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Numerator & Denominator \\
\hline
1 & 24000 & 1001 \\
\hline
2 & 24 & 1 \\
\hline
3 & 25 & 1 \\
\hline
4 & 30000 & 1001 \\
\hline
5 & 30 & 1 \\
\hline
6 & 50 & 1 \\
\hline
7 & 60000 & 1001 \\
\hline
8 & 60 & 1 \\
\hline
9 & 15000 & 1001 \\
\hline
10 & 25 & 2 \\
\hline
\end{tabular}
\caption{Available preset frame rate values}\label{table:frameratevalues}
\end{table}

\begin{informative}
Note that what is encoded is frame rate, not picture rate. If the video is coded
as fields, then picture rate is twice the encoded frame rate.
\end{informative}

\subsubsection{Pixel aspect ratio}
\label{aspectratio}

The pixel aspect ratio shall be defined as the ratio of the parameters:
		\[\SAspectRatioNumer : \SAspectRatioDenom\]

The process for decoding the pixel aspect ratio parameters shall be defined as follows:

\begin{pseudo}{pixel\_aspect\_ratio}{\VideoParams}
\bsITEM{custom\_pixel\_aspect\_ratio\_flag}{bool}{}
\bsIF{custom\_pixel\_aspect\_ratio\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SAspectRatioNumer}{uint}{}
        \bsITEM{\SAspectRatioDenom}{uint}{}
    \bsELSE
        \bsCODE{preset\_pixel\_aspect\_ratio(\VideoParams,index)}
    \bsEND
\bsEND
\end{pseudo}

If $custom\_pixel\_aspect\_ratio\_flag$ is set to $\true$, the pixel aspect ratio 
defined by the default values shall be overridden by the new values defined by the 
index value. 

The decoded value of $index$ shall fall in the range 0 to 6.

If the value of $index$ is 0, then the pixel aspect ratio numerator and denominator 
shall be individually defined by unsigned integer values.

If $index>0$, the process $preset\_pixel\_aspect\_ratio(\VideoParams, index)$ 
shall set the pixel aspect ratio according to table \ref{table:aspectratiovalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Numerator & Denominator \\
\hline
1 (Square Pixels) & 1 & 1 \\
\hline
2 (525-line systems) & 10 & 11 \\
\hline
3 (625-line systems) & 12 & 11 \\
\hline
4 (16:9 525-line systems) & 40 & 33 \\
\hline
5 (16:9 625-line systems) & 16 & 11 \\
\hline
6 (reduced horizontal resolution) & 4 & 3 \\
\hline
\end{tabular}
\caption{Available preset pixel aspect ratio values}\label{table:aspectratiovalues}
\end{table}

\begin{informative}
 \\
\begin{enumerate}
\item The pixel aspect ratio value defines the intended ratio of the pixel 
sampling such that the viewed picture has no geometric distortion. The pixel aspect
 ratio of an image is the ratio of the spacing of horizontal samples 
(pixels) to the spacing of vertical samples (picture lines) on the display device. 
Pixel aspect ratios (PARs) are fundamental properties of sampled images because
 they determine the displayed shape of objects in the image. Failure to use the right
 PAR will result in distorted images, for example circles will be displayed as 
ellipses etc.   
\item The pixel apect ratios shown in table \ref{table:aspectratiovalues} assume
a 704x480 active picture for 525-line systems and a 704x576 active picture for 
625-line systems.
\item Some video processing tools require an image aspect ratio. This can be 
derived from the pixel aspect ratio by multiplying the ratio of horizontal to vertical 
pixels by the pixel aspect ratio. So, for example, for a 704 x 480 line picture, with 
a pixel aspect ratio of 10:11 the image aspect ratio is (704 x 10)/(480 x 11) which is
 exactly 4:3.
\end{enumerate}
\end{informative}

\subsubsection{Clean area}
\label{cleanarea}

The process for decoding the clean area parameters shall be as follows:

\begin{pseudo}{clean\_area}{\VideoParams}
\bsITEM{custom\_clean\_area\_flag}{bool}{}
\bsIF{custom\_clean\_area\_flag==\true}
    \bsITEM{\SCleanWidth}{uint}{}
    \bsITEM{\SCleanHeight}{uint}{}
    \bsITEM{\SLeftOffset}{uint}{}
    \bsITEM{\STopOffset}{uint}{}
\bsEND
\end{pseudo}

The following restrictions shall apply:

\begin{itemize}
\item $\SCleanWidth+\SLeftOffset
\leq \SFrameWidth$
\item $\SCleanHeight+\STopOffset
\leq \SFrameHeight$
\end{itemize}

\begin{informative}
The meaning and use of clean area are application defined: it might correspond
to that picture which is to be displayed, or define a ``container'' within
a picture of larger size.
\end{informative}

\subsubsection{Signal range}
\label{signalrange}

The signal range parameters indicate how the signal range of the picture 
component data, decoded by the Dirac decoder, should be adjusted prior to 
the colour matrixing operations (described in informative Annex \ref{signalranges}). 

The signal range parameters shall also be used to determine the luma depth 
and chroma depth parameters (Section \ref{videodepth}) and the resulting 
clipping levels applied to the decoded video (Section \ref{pictureclip}).

The process for decoding the signal range parameters is as follows:

\begin{pseudo}{signal\_range}{\VideoParams}
\bsITEM{custom\_signal\_range\_flag}{bool}{}
\bsIF{custom\_signal\_range\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SLumaOffset}{uint}{}
        \bsITEM{\SLumaExcursion}{uint}{}
        \bsITEM{\SChromaOffset}{uint}{}
        \bsITEM{\SChromaExcursion}{uint}{}
    \bsELSE
        \bsCODE{preset\_signal\_ranges(\VideoParams,index)}
    \bsEND
\bsEND
\end{pseudo}

If $custom\_signal\_range\_flag$ is set to $\true$ then the base video format
signal range parameters shall be overridden by new values.

The decoded value of $index$ shall fall in the range 0 to 4.

If $index>0$ the process $preset\_signal\_ranges(\VideoParams,index)$ 
shall set the signal range elements of $\VideoParams$ according to table 
\ref{table:signalrangevalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Luma offset & Luma excursion & Chroma offset & Chroma excursion\\
\hline
1 (8 Bit Full Range) & 0 & 255 & 128 & 255\\
\hline
2 (8 Bit Video) & 16 & 219 & 128 & 224\\
\hline
3 (10 Bit Video) & 64 & 876 & 512 &  896\\
\hline
4 (12 Bit Video) & 256 & 3504 & 2048 & 3584\\
\hline
\end{tabular}
\caption{Available signal range presets}\label{table:signalrangevalues}
\end{table}

\begin{informative}
Decoded video is represented within the decoder specification as bi-polar 
signals. An offset is added when video is output so that it is represented by unsigned 
integer values.
\end{informative}

\subsubsection{Color specification}
\label{colourspec}

The colour specification shall consist of three component parts:
\begin{itemize}
\item Color primaries
\item Color matrix 
\item Transfer function
\end{itemize}

Defaults are available for all three parts collectively and individually.

The process for decoding the colour specification parameters shall be follows: 

\begin{pseudo}{colour\_spec}{\VideoParams}
\bsITEM{custom\_colour\_spec\_flag}{bool}{}
\bsIF{custom\_colour\_spec\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_specs(\VideoParams,index)}
    \bsIF{index == 0}
        \bsCODE{colour\_primaries(\VideoParams)}{\ref{colourprimaries}}
        \bsCODE{colour\_matrix(\VideoParams)}{\ref{colourmatrix}}
        \bsCODE{transfer\_function(\VideoParams)}{\ref{transferfunction}}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 4.

$preset\_colour\_spec(index)$ shall set the colour primaries, matrix and transfer function elements of $\VideoParams$ as specified 
in Table \ref{table:colourspecvalues}. If the value of $index$ is 0, these values may be overridden as defined in the succeeding sections. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & {\bf Description}& {\bf Primaries} & {\bf Matrix}& {\bf Transfer function}\\
\hline
0 & Custom & HDTV & HDTV & TV gamma \\ 
\hline
1 & SDTV 525 & SDTV 525 & SDTV & TV gamma \\
\hline
2 & SDTV 625 & SDTV 625 & SDTV & TV gamma \\
\hline
3 & HDTV & HDTV & HDTV & TV gamma \\
\hline
4 & D-Cinema & HDTV & HDTV & DCinema gamma\\
\hline
\end{tabular}
\caption{Color specification presets}\label{table:colourspecvalues}
\end{table}

\paragraph{Color primaries}
\label{colourprimaries}
$\ $\newline
The colour primaries decoding process shall be defined as follows:

\begin{pseudo}{colour\_primaries}{\VideoParams}
\bsITEM{custom\_colour\_primaries\_flag}{bool}{}
\bsIF{custom\_colour\_primaries\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_primaries(\VideoParams,index)}
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

 $preset\_colour\_primaries(\VideoParams,index)$ shall set the colour primaries 
element of $\VideoParams$ as specified
in Table \ref{table:primariesvalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ &  {\bf Description} & {\bf Specification} & {\bf Comment}      \\
\hline
0       &  HDTV & ITU-R BT.709 & Also Computer, Web, sRGB \\ 
\hline
1       &  SDTV 525 & SMPTE 170M & 525 primaries          \\
\hline
2       &  SDTV 625 & EBU Tech 3213-E & 625 primaries  \\
\hline
3       &  D-Cinema & SMPTE 428.1 & CIE XYZ              \\
\hline
\end{tabular}
\caption{Color primaries presets}\label{table:primariesvalues}
\end{table}

\paragraph{Color matrix}
\label{colourmatrix}
$\ $\newline
The colour matrix decoding process shall be defined as follows:

\begin{pseudo}{colour\_matrix}{}
\bsITEM{colour\_matrix\_flag}{bool}{}
\bsIF{colour\_matrix\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_matrices(index)}
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 2. 

The $preset\_colour\_matrices(\VideoParams,index)$ process shall set the colour 
matrix element in $\VideoParams$ as specified
in Table \ref{table:matrixvalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ &  {\bf Description} & {\bf Specification} & {\bf Color matrix} & {\bf Comment}\\
\hline
0 & HDTV & ITU-R BT.709 & $K_R=0.2126$, $K_B=0.0722$ & Also computer and web\\ 
\hline
1 & SDTV & ITU-R BT.601 & $K_R=0.299$, $K_B=0.114$ & \\
\hline
2 & Reversible & ITU-T H.264 & YCgCo & \\
\hline
\end{tabular}
\caption{Color matrix presets}\label{table:matrixvalues}
\end{table}

\paragraph{Transfer function}
\label{transferfunction}
$\ $\newline
The transfer function decoding process shall be defined as follows:

\begin{pseudo}{transfer\_function}{\VideoParams}
\bsITEM{custom\_transfer\_function\_flag}{bool}{}
\bsIF{custom\_transfer\_function\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_transfer\_function(\VideoParams,index)}
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 3. The $preset\_transfer\_function(\VideoParams,index)$ process shall set the transfer function
element of $\VideoParams$ as specified
in Table \ref{table:transfervalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & {\bf Description} & {\bf Specification}\\
\hline
0 & TV gamm & ITU-R BT.1361\\ 
\hline
1 & Extended Gamut & ITU-R BT.1361 1998 Annex 1\\
\hline
2 & Linear & Linear\\
\hline
3 & DCI Gamma & SMPTE 428.1\\
\hline
\end{tabular}
\caption{Transfer function presets}\label{table:transfervalues}
\end{table}

\subsection{Picture coding mode}
\label{picturecodingmode}

The picture coding mode value in the sequence header shall determine 
whether source video is coded as frames or fields. 

If the picture coding mode value is $1$ then pictures shall correspond to fields. 
If it is $0$ then pictures shall correspond to frames. Other picture coding mode 
values shall be reserved for future extensions.

If video is coded as fields then the earliest field in each frame shall have 
an even picture number (Section \ref{pictureheader}). That is the LSB of the 
picture number, expressed as a binary number, indicates field parity.

With field coding each frame shall be split into two fields as indicated 
by the scan format (Section \ref{scanformat}).

An effect of field coding shall be to halve the vertical dimensions of 
coded pictures. Hence, once the picture coding mode is known, the 
picture dimensions, which shall be stored as part of the global 
state variable, shall be set (Section \ref{picturedimensions}).

\begin{informative}
It is possible to code progressive video as fields. In this case, 
the assignment of frame lines to fields will be determined by the 
value of the top field first parameter in the base video format 
(annex \ref{videoformatdefaults}). Note that, according to 
section \ref{scanformat}, this base format default cannot be overridden 
for progressive video, as to do so would be artificial.

Sometimes progressive source video is conveyed as if it were interlaced
(for example using interlaced SDI modes), and could be signaled as such.
This is known as progressive segmented frames (PSF). A Dirac encoder could
detect PSF, and signal video as progressive, yet still code the video as 
fields in order to introduce no additional buffering delay in the signal
chain. Or it could take the signaled video format at face value.
\end{informative}

\subsection{Initializing coding parameters}
\label{codingparameters}

The $set\_coding\_parameters()$ process shall initialize the dimensions of the coded picture (frame or field), and the video depth (the maximum number of bits in a decoded video sample), which are needed to decode pictures. 

Picture dimensions and video depth shall remain constant throughout a Dirac sequence. 

Initialization of the coding parameters shall be as defined in the table below:

\begin{pseudo}{set\_coding\_parameters}{\VideoParams, picture\_coding\_mode}
\bsCODE{picture\_dimensions(\VideoParams, picture\_coding\_mode)}{\ref{picturedimensions}}
\bsCODE{video\_depth(\VideoParams)}{\ref{videodepth}}
\end{pseudo}

\subsubsection{Picture dimensions}
\label{picturedimensions}
The picture dimensions process, which determines the size of coded pictures, shall be defined as follows:

\begin{pseudo}{picture\_dimensions}{\VideoParams, picture\_coding\_mode}
\bsCODE{\LumaWidth = \SFrameWidth}
\bsCODE{\LumaHeight = \SFrameHeight}
\bsCODE{\ChromaWidth = \LumaWidth}
\bsCODE{\ChromaHeight = \LumaHeight}
\bsCODE{chroma\_format\_index = \SChromaFormatIndex]}
\bsIF{chroma\_format\_index == 1}
  \bsCODE{\ChromaWidth //= 2}
\bsELSEIF{chroma\_format\_index == 2}
  \bsCODE{\ChromaWidth //= 2}
  \bsCODE{\ChromaHeight //= 2}
\bsEND
\bsIF{picture\_coding\_mode==1}
  \bsCODE{\LumaHeight //=2}
  \bsCODE{\ChromaHeight //=2}
\bsEND
\end{pseudo}

The parameter $\SFrameHeight$  refers to the height of a frame. The parameter $\LumaHeight$ refers to the height of a picture.  A picture may be either a frame or a field depending on whether it is being coded in an interlaced or progressive mode.

Frame height shall be an integer multiple of picture chroma height.

For convenience, the following utility functions shall be defined:

\begin{pseudo}{chroma\_h\_ratio}{}
\bsRET{\LumaWidth//\ChromaWidth}
\end{pseudo}
 
\begin{pseudo}{chroma\_v\_ratio}{}
\bsRET{\LumaHeight//\ChromaHeight}
\end{pseudo}

\subsubsection{Video depth}
\label{videodepth}
The $video\_depth()$ process, which determines the maximum number of bits required to represent a sample of the decoded video, shall be defined as follows:

\begin{pseudo}{video\_depth}{\VideoParams}
\bsCODE{\LumaDepth =\intlog2(\SLumaExcursion+1)}
\bsCODE{\ChromaDepth =\intlog2(\SChromaExcursion+1)}
\end{pseudo}

Note that for YCoCg format the luma and chroma depths are different.

\section{Picture syntax}
\label{picturesyntax}
This section specifies the structure of Dirac picture data units.

\subsection{Picture parsing}
\label{picture}
\label{pictureparse}

This section specifies the operation of the $picture\_parse()$ process. The process for
decoding and outputting pictures is specified in Section \ref{picturedec}.

Picture data may be successfully parsed after parsing a sequence header within the 
same  Dirac sequence. The picture parsing process shall be defined as follows:

\begin{pseudo}{picture\_parse}{}
\bsCODE{byte\_align()}
\bsCODE{picture\_header()}{\ref{pictureheader}}
\bsIF{is\_inter()}{\ref{parsecodevalues}}
    \bsCODE{byte\_align()}
    \bsCODE{picture\_prediction()}{\ref{pictureprediction}}
\bsEND
\bsCODE{byte\_align()}
\bsCODE{wavelet\_transform()}{\ref{wavelettransform}}
\end{pseudo}

\subsubsection{Picture header}
\label{pictureheader}

The picture header shall immediately follow a parse info header with a picture parse 
code (section \ref{parseinfoheader}). The picture header parsing process shall be defined as follows:

\begin{pseudo}{picture\_header}{}
\bsCODE{\PictureNumber=read\_uint\_lit(4)}
\bsIF{is\_inter()}{\ref{parsecodevalues}}
    \bsCODE{\RefOneNum=(\PictureNumber+read\_sint())\%2^{32}}
    \bsIF{num\_refs() == 2}{\ref{parsecodevalues}}
        \bsCODE{\RefTwoNum=(\PictureNumber+read\_sint())\%2^{32}}
    \bsEND\bsEND
\bsIF{is\_reference()}{\ref{parsecodevalues}}
    \bsCODE{\RetiredPicture=(\PictureNumber+read\_sint())\% 2^{32}}
\bsEND
\end{pseudo}

Picture numbers shall be unique within a sequence and the set of all picture numbers
within a sequence shall form a contiguous block of numbers.

Reference picture numbers shall encoded differentially with respect to the
picture number.

The pictures corresponding to the reference picture numbers of a given picture
shall occur before the given picture in the sequence.

The retired picture shall be a picture which shall be removed from 
the reference picture buffer before the current picture is decoded
(Section \ref{overallpicturedec}). The rules for the 
use of the reference picture buffer shall be as defined in Section \ref{refbuffer}.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Picture prediction data}
\label{pictureprediction}

This section defines the picture prediction process that shall be used for decoding 
picture prediction parameters and motion vector fields for motion compensation.

The picture prediction process shall be defined as follows:

\begin{pseudo}{picture\_prediction}{}
\bsCODE{picture\_prediction\_parameters()}{\ref{picpredparams}}
\bsCODE{byte\_align()}
\bsCODE{block\_motion\_data()}{\ref{motiondec}}
\end{pseudo}

The decoding and generation of block motion vector fields shall be as defined in Section \ref{motiondec}. 

\subsubsection{Picture prediction parameters}
\label{picpredparams}

Picture prediction parameters consist of metadata required for successful parsing of the
motion data and for performing motion compensation (Section \ref{motioncompensate}).

The picture prediction parameters shall be defined as follows:

\begin{pseudo}{picture\_prediction\_parameters}{}
\bsCODE{block\_parameters()}{\ref{blockparameters}}
\bsCODE{motion\_vector\_precision()}{\ref{mvprecision}}
\bsCODE{global\_motion()}{\ref{globalmotion}}
\bsCODE{picture\_prediction\_mode()}{\ref{picpredmode}}
\bsCODE{reference\_picture\_weights()}{\ref{refpicweights}}
\end{pseudo}

\subsubsection{Block parameters}
\label{blockparameters}

This section specifies the operation of the process for
setting motion compensation block parameters, which shall consist of the state variables
$\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$
defining luma blocks, and $\ChromaXBlen$, $\ChromaYBlen$, $\ChromaXBsep$,
and $\ChromaYBsep$ defining chroma blocks. 

\begin{pseudo}{block\_parameters}{}
\bsITEM{index}{uint}
\bsIF{index == 0}
    \bsITEM{\LumaXBLen}{uint}{}
    \bsITEM{\LumaYBLen}{uint}{}
    \bsITEM{\LumaXBSep}{uint}{}
    \bsITEM{\LumaYBSep}{uint}{}
\bsELSE
       \bsCODE{preset\_block\_params(index)}
\bsEND
\bsCODE{chroma\_block\_params()}{\ref{chromablockparams}}
\bsCODE{motion\_data\_dimensions()}{\ref{motiondatadimensions}}
\end{pseudo}

$index$ shall lie in the range 0 to 4. 

The $preset\_block\_params(index)$ shall set the block parameters as specified
in Table \ref{blockparamsvalues}.

Chroma block parameter values shall be determined from luma values
as defined in Section \ref{chromablockparams}).

The dimensions of motion data arrays (numbers of blocks and superblocks) shall
be as defined in Section \ref{motiondatadimensions}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$  & \LumaXBlen & \LumaYBlen & \LumaXBsep & \LumaYBsep \\
\hline
1 & 8 & 8 & 4 & 4 \\
\hline
2 & 12 & 12 & 8 & 8\\
\hline
3 & 16 & 16 & 12 & 12\\
\hline
4 & 24 & 24 & 16 & 16\\
\hline
\end{tabular}
\caption{Luma block parameter presets}\label{blockparamsvalues}
\end{table}

Block parameters shall satisfy the following constraints:

\begin{enumerate}
\item $\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$ shall all be positive
multiples of 4
\item $\LumaXBlen\geq\LumaXBsep$ and $\LumaYBlen\geq\LumaYBsep$
\item $\LumaXBlen\leq 2*\LumaXBsep$ and $\LumaYBlen\leq 2*\LumaYBsep$
\end{enumerate}

\begin{informative}
Note that these requirements do not preclude length from equalling separation, i.e.
motion compensation blocks that are not overlapped. 
\end{informative}

\subsubsection{Setting chroma block parameters}
\label{chromablockparams}

This section defines how chroma block parameters shall be derived from luma block dimensions. 

Chroma block parameters shall be equal to the corresponding luma block parameters scaled according to the chroma vertical and horizontal subsampling ratios. In this way chroma blocks and luma blocks are co-located in the video picture.

\begin{pseudo}{chroma\_block\_params}{}
\bsCODE{\ChromaXBlen=\LumaXBlen//chroma\_h\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaYBlen=\LumaYBlen//chroma\_v\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaXBsep=\LumaXBsep//chroma\_h\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaYBsep=\LumaYBsep//chroma\_v\_ratio()}{\ref{picturedimensions}}
\end{pseudo}

\subsubsection{Numbers of blocks and superblocks}
\label{motiondatadimensions}

The number of blocks and superblocks horizontally and vertically shall be set
as follows:

\begin{pseudo}{motion\_data\_dimensions}{}
\bsCODE{\SuperblocksX = \LumaWidth+4*\LumaXBsep-1}
\bsCODE{\SuperblocksX//= 4*\LumaXBsep}
\bsCODE{\SuperblocksY = \LumaHeight+4*\LumaYBsep-1}
\bsCODE{\SuperblocksY//= 4*\LumaYBsep} 
\bsCODE{\BlocksX = 4*\SuperblocksX}
\bsCODE{\BlocksY = 4*\SuperblocksY}
\end{pseudo} 

These values shall determine the size of motion data arrays as per Section
\ref{motioninit}. 

\begin{informative}
The number of superblocks is set so that the dimensions of the picture are
entirely covered by superblocks at a separation of $4*\LumaXBsep$ horizontally
and $4*\LumaYBsep$ vertically.
\end{informative}

\subsubsection{Motion vector precision}
\label{mvprecision}

The motion vector precision process shall be as follows:

\begin{pseudo}{motion\_vector\_precision}{}
\bsITEM{\MotionVectorPrecision}{uint}
\end{pseudo}

$\MotionVectorPrecision$ shall lie in the range 0 (pixel-accurate) to 3 (1/8th-pixel accurate).

\subsubsection{Global motion}
\label{globalmotion}

Global motion parameters shall be encoded if the $\PictureUsingGlobal$ flag is set
to $\true$. Up to two sets shall be encoded,
depending upon the number of references.

The global motion process shall be as follows:

\begin{pseudo}{global\_motion}{}
\bsITEM{\PictureUsingGlobal}{bool}{}
\bsIF{\PictureUsingGlobal==\true}
    \bsCODE{global\_motion\_parameters(\GlobalParams[1])}
    \bsIF{num\_refs() == 2}
        \bsCODE{global\_motion\_parameters(\GlobalParams[2])}
    \bsEND
\bsEND
\end{pseudo}

Each of the global motion parameters shall consist of three elements: 

\begin{itemize}
\item an integer pan/tilt vector $\GlobalParams[n][\PanTilt]$
\item an integer 2x2 matrix element $\GlobalParams[n][\ZRS]$
capturing zoom, rotation and shear, together with a scaling exponent 
$\GlobalParams[n][\ZRSexponent]$
\item an integer perspective vector $\GlobalParams[n][pespective]$
capturing the effect of non-orthogonal projection onto the image plane, together 
with a scaling exponent $\GlobalParams[n][pespective\_exp]$
\end{itemize}

Their interpretation and the process for generating a global motion vector field 
shall be as defined in Section \ref{globalmv}. 

The global motion parameters process shall be defined as follows:

\begin{pseudo}{global\_motion\_parameters}{gparams}
\bsCODE{pan\_tilt(gparams)}
\bsCODE{zoom\_rotate\_shear(gparams)}
\bsCODE{perspective(gparams)}
\end{pseudo}

The $pan\_tilt()$ process shall extracts horizontal and vertical translation elements
and shall be defined as follows:

\begin{pseudo}{pan\_tilt}{gparams}
\bsCODE{gparams[\PanTilt]={\mathbf{0}} }
\bsITEM{nonzero\_pan\_tilt\_flag}{bool}{}
\bsIF{nonzero\_pan\_tilt\_flag==\true}
    \bsITEM{gparams[\PanTilt][0]}{sint}{}
    \bsITEM{gparams[\PanTilt][1]}{sint}{}
\bsEND
\end{pseudo}

The $zoom\_rotate\_shear()$ process shall extract a linear matrix element and shall be
as defined as follows:

\begin{pseudo}{zoom\_rotation\_shear}{gparams}
\bsITEM{nontrivial\_zrs\_flag}{bool}{}
\bsIF{nontrivial\_zrs\_flag==\true}
    \bsITEM{gparams[\ZRSexponent]}{uint}{}
    \bsITEM{gparams[\ZRS][0][0]}{sint}{}
    \bsITEM{gparams[\ZRS][0][1]}{sint}{}
    \bsITEM{gparams[\ZRS][1][0]}{sint}{}
    \bsITEM{gparams[\ZRS][1][1]}{sint}{}
\bsELSE
    \bsCODE{gparams[\ZRSexponent]=0}
    \bsCODE{gparams[\ZRS][0][0]=1}
    \bsCODE{gparams[\ZRS][0][1]=0}
    \bsCODE{gparams[\ZRS][1][0]=0}
    \bsCODE{gparams[\ZRS][1][1]=1}
\bsEND
\end{pseudo}

The $perspective()$ process shall extract horizontal and vertical perspective
elements and shall be defined as follows:

\begin{pseudo}{perspective}{gparams}
\bsITEM{nonzero\_perspective\_flag}{bool}{}
\bsIF{nonzero\_perspective\_flag==\true}
    \bsITEM{gparams[\PerspectiveExponent]}{uint}{}
    \bsITEM{gparams[\Perspective][0]}{sint}{}
    \bsITEM{gparams[\Perspective][1]}{sint}{}
\bsELSE
    \bsCODE{gparams[\PerspectiveExponent]=0}
    \bsCODE{gparams[\Perspective]={\mathbf{0}} }
\bsEND
\end{pseudo}

\subsubsection{Picture prediction mode}
\label{picpredmode}

The picture prediction mode encodes alternative methods of motion compensation
and is present to support future extensions of this specification.

It shall be defined as follows:

\begin{pseudo}{picture\_prediction\_mode}{}
\bsITEM{\PicturePredictionModeIndex}{uint}
\end{pseudo}

In this specification, $\PicturePredictionModeIndex$ shall be 0.

\subsubsection{Reference picture weight values}
\label{refpicweights}

Reference picture weight values shall be determined as follows:

\begin{pseudo}{reference\_picture\_weights}{}
\bsCODE{\RefsWeightPrecision=1}
\bsCODE{\RefOneWeight=1}
\bsCODE{\RefTwoWeight=1}
\bsITEM{custom\_weights\_flag}{bool}
\bsIF{custom\_weights\_flag==\true}
    \bsITEM{\RefsWeightPrecision}{uint}
    \bsITEM{\RefOneWeight}{sint}
    \bsIF{num\_refs() == 2}
        \bsITEM{\RefTwoWeight}{sint}
    \bsEND
\bsEND
\end{pseudo}

\begin{informative}
For bi-directional prediction modes, reference 1 data will be weighted by 

$\dfrac{\RefOneWeight}{2^\RefsWeightPrecision}$

and reference 2 data by

$\dfrac{\RefTwoWeight}{2^\RefsWeightPrecision}$ 

(see Section \ref{blockmc}).

The picture weights are signed integers and may be negative. In
addition, they may not sum to $2^\RefsWeightPrecision$, to accomodate fade
prediction.
\end{informative}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wavelet transform data}
\label{wavelettransform}

The wavelet transform syntax shall provide metadata determining the wavelet transform
 parameters (including filter type, transform depth, and codeblock or slice structures) together with the transformed wavelet coefficients. 

The wavelet transform process for parsing transform metadata and coefficients shall be defined as follows:

\begin{pseudo}{wavelet\_transform}{}
\bsCODE{\ZeroResidual = \false}
\bsIF{is\_inter()}{\ref{parsecodevalues}}
    \bsITEM{\ZeroResidual}{bool}
\bsEND
\bsIF{\ZeroResidual == \false}
    \bsCODE{transform\_parameters()}{\ref{transformparameters}}
    \bsCODE{byte\_align()}
    \bsCODE{transform\_data()}{\ref{wltunpacking}}
\bsEND
\end{pseudo}

Parsing (unpacking) the wavelet transform data shall be as defined in Section \ref{wltunpacking}. 

Decoding the transformed wavelet transform data to produce decoded pictures shall be
 as defined in Section \ref{picturedec}.

If $\ZeroResidual=\true$ then all component pixels shall be 
set to zero (Section \ref{overallpicturedec}).

\subsubsection{Transform parameters}
\label{transformparameters}

The wavelet transform parameters shall define the metadata required to configure the inverse wavelet transform for both the low delay and core syntax. 

The $transform\_parameters()$ process shall be defined as follows:

\begin{pseudo}{transform\_parameters}{}
\bsITEM{\WaveletIndex}{uint}{\ref{wltfilter}}
\bsITEM{\TransformDepth}{uint}{\ref{wltdepth}}
\bsIF{is\_low\_delay()==\false}
    \bsCODE{codeblock\_parameters()}{\ref{codeblockparams}}
\bsELSE
    \bsCODE{slice\_parameters()}{\ref{sliceparams}}
    \bsCODE{quant\_matrix()}{\ref{quantmatrix}}
\bsEND
\end{pseudo}

\paragraph{Wavelet filters}
\label{wltfilter}
$\ $\newline

The wavelet filter parameter shall define the wavelet filter used by the Dirac stream. T
The value of $\WaveletIndex$ shall lie in the range 0 to 6 with values as 
defined in Table \ref{wltfilterpresets}: 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}\WaveletIndex & {\bf Filter} \\
\hline
0 & Deslauriers-Dubuc (9,7) \\
\hline
1 & LeGall (5,3) \\
\hline
2 & Deslauriers-Dubuc (13,7) \\
\hline
3 & Haar with no shift \\
\hline
4 & Haar with single shift per level\\
\hline
5 & Fidelity filter \\
\hline
6 & Daubechies (9,7) integer approximation \\
\hline
\end{tabular}
\caption{Wavelet filter presets}\label{wltfilterpresets}
\end{table}


The implementation of the chosen wavelet filter shall be as defined 
 in Section \ref{wltfilters}. 


\begin{informative}
For consistency, the filter nomenclature $(m, n)$ refers to the length of the analysis low-pass
and high-pass filters in the conventional prefiltering (i.e. before subsampling) 
model of wavelet filtering. They do not reflect the length of lifting filters, which
operate in the subsampled domain: see Section \ref{wltfilters}. Deslauriers-Dubuc
filters are normally referred to in terms of the number of vanishing moments of their
synthesis filters, so the (9,7) and (13,7) filters may be referred to in the literature
as (2,2) and (4,2) filters respectively.
\end{informative}

\subsubsection{Transform depth}
\label{wltdepth}

The transform depth parameter shall determine the number of stages in the wavelet transform.that the vertical and horizontal wavelet filters are applied. 

Note: The transform depth determines the number of 
subbands and the the dimensions of the subband data array (Section \ref{wltinit}).

\subsubsection{Codeblock parameters (core syntax only)}
\label{spatialpartition}
\label{codeblockparams}

In the core syntax only, each subband may be partitioned into a number of code blocks. 

The process for extracting codeblock parameters shall be as follows:

\begin{pseudo}{codeblock\_parameters}{}
\bsCODE{\CodeblockMode=0}
\bsFOR{level=0}{\TransformDepth}
    \bsCODE{\CodeblocksX[level]=1}
    \bsCODE{\CodeblocksY[level]=1}
\bsEND
\bsITEM{spatial\_partition\_flag}{bool}
\bsIF{spatial\_partition\_flag==\true}
    \bsFOR{level=0}{\TransformDepth}
        \bsITEM{\CodeblocksX[level]}{uint}
        \bsITEM{\CodeblocksY[level]}{uint}
    \bsEND
    \bsITEM{\CodeblockMode}{uint}
\bsEND
\end{pseudo}

The presence of codeblocks in subbands shall be indicated by setting $spatial\_partition\_flag$ to $\true$; otherwise it shall be $\false$.

The number of codeblocks to be used for subbands at each transform depth level shall be encoded in $\CodeblocksY[level]$ and $\CodeblocksX[level]$ for vertical and horizontal axes respectively.

The codeblock mode is encoded in $\CodeblockMode$, which shall have value 0 or 1, with meanings as defined in Table \ref{codeblockmodes}. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
 \rowcolor[gray]{0.75}$\CodeblockMode$ & {\bf Description} \\
\hline
0 & Single quantiser per subband, used for all codeblocks\\
\hline
1 & Multiple Quantiser per subband, one for each codeblock \\
\hline
\end{tabular}
\caption{Codeblock modes}\label{codeblockmodes}
\end{table}

The operation of subband codeblock decoding shall be as defined in Section \ref{codeblocks}.

\subsubsection{Slice coding parameters (low delay syntax only)}
\label{sliceparams}

This slice parameters process shall be defined as follows:

\begin{pseudo}{slice\_parameters}{}
\bsITEM{\SlicesX}{uint}
\bsITEM{\SlicesY}{uint}
\bsITEM{\SliceBytesNum}{uint}
\bsITEM{\SliceBytesDenom}{uint}
\end{pseudo}

\subsubsection{Quantisation matrices (low-delay syntax)}
\label{quantmatrix}

The quantization matrix shall be used to modify the slice quantizer for each subband in
 a slice. The quantization matrix shall be encoded in the $\QuantMatrix$ decoder variable. 

The $quant\_matrix()$ process shall be defined as follows:

\begin{pseudo}{quant\_matrix}{}
\bsITEM{custom\_quant\_matrix}{bool}
\bsIF{custom\_quant\_matrix==\true}
    \bsITEM{\QuantMatrix[0][\LL]}{uint}
    \bsFOR{level=1}{\TransformDepth}
        \bsITEM{\QuantMatrix[level][\HL]}{uint}
        \bsITEM{\QuantMatrix[level][\LH]}{uint}
        \bsITEM{\QuantMatrix[level][\HH]}{uint}
    \bsEND
\bsELSE
    \bsCODE{set\_quant\_matrix()}
\bsEND
\end{pseudo}

If $\TransformDepth> 4$ then $custom\_quant\_matrix$  shall be $\true$. 

If $\TransformDepth \leq 4$, then custom quantization 
matrices may still be transmitted, 
for example to apply a different degree of perceptual weighting 
(see Annex \ref{qmatrixdesign}). 

The function $set\_quant\_matrix()$ shall set the quantization matrix 
based on the wavelet filter as per Annex \ref{defaultquantmatrices}. These are 
unweighted matrices, whose values merely compensate for the differential power 
gain of the different subband ?lters. For perceptual weighting a custom 
quantisation matrix must be used.

