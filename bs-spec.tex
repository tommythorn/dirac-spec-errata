%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% - This chapter defines the bytestream structure - %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\label{streamstructure}

This section specifies the overall structure of Dirac streams. 
Subsequent sections define the processes for 
parsing pictures, and Section \ref{picturedec} specifies how pictures 
are decoded.

\subsection{Pseudocode}
The parsing process is normatively defined using pseudocode and/or mathematical formulae.
 The definitions of stream syntax operations and pseudocode shall be as defined in 
section \ref{spec-conventions}. 

The Dirac stream syntax uses a state model to express the stream in a way that can 
be parsed and used for decoding operations. The parsing and decoding operations are 
specified in terms of modifying the decoder state according to the data extracted 
from the Dirac stream. The state of the decoder is stored in the global variable $\StateName$.
 This is a map (Section \ref{datatypes}) and individual elements are accessed by 
means of named labels, e.g. $\StateName[\text{VAR\_NAME}]$. 
The state variables comprise the parameters that shall be used in parsing and decoding a picture. 
The variable state is a global variables and shall be accessible to all decoder functions and processes. 
All other variables shall be local to the function or process in which they are defined.

Decoder state variables (that is elements of state) may not directly correspond 
to parts of the stream, but may be calculated from them taking into account the 
decoder state as a whole. For example, a state variable value may be differentially 
encoded with respect to another value, with the difference, not the variable itself, 
encoded in the stream. Some parameters are encoded in the stream as indices
 to tables of values. The indices are coded as variable length integers. 
This allows the tables to be extended to contain new entries, in future versions 
of this specification, without changing the syntax.


\subsection{Stream}
\label{stream}

A stream is a concatenation of Dirac sequences. The process for parsing a stream 
is to parse all sequences it contains. A Dirac sequence shall be decoded as a separate entity.

\subsection{Sequence}

The data contained in a Dirac sequence corresponds to a single video sequence with
constant video parameters as defined in Sections \ref{sourceparameters}. A sequence
 A Dirac sequence can be excised from a Dirac stream and decoded entirely
independently.

A Dirac sequence shall comprise an alternating sequence of parse info headers and 
data units. The first data unit shall be a sequence header, and further sequence 
headers may be inserted at any data unit point in the sequence . 
The process for parsing a Dirac sequence shall be as defined below:

\begin{pseudo}{video\_sequence}{}
\bsCODE{\RefBuffer=\{\}}
\bsCODE{\DecodedBuffer=\{\}}
\bsCODE{parse\_info()}{\ref{parseinfo}}
\bsCODE{\VideoParams=sequence\_header()}{\ref{sequenceheader}}
\bsCODE{parse\_info()}{\ref{parseinfo}}
\bsWHILE {is\_end\_of\_sequence()==\false}{\ref{parseinfo}}
    \bsIF{is\_seq\_header()==\true}{\ref{parseinfo}}
        \bsCODE{\VideoParams=sequence\_header()}{\ref{sequenceheader}}
    \bsELSEIF{is\_picture()}{\ref{parseinfo}}
        \bsCODE{picture\_parse()}{\ref{pictureparse}}
    \bsELSEIF{is\_auxiliary\_data()}{\ref{parseinfo}}
        \bsCODE{auxiliary\_data()}{\ref{auxdata}}
    \bsELSEIF{is\_padding()}{\ref{parseinfo}}
        \bsCODE{padding()}{\ref{paddingdata}}
    \bsEND
    \bsCODE{parse\_info()}{\ref{parseinfo}}
\bsEND
\end{pseudo}

Each Dirac sequence shall start and end with a parse info header. 

\subsection{Parse Info headers}

Parse info headers shall contain a 32 bit code so that the decoder can 
be synchronized with the stream. They are defined in section \ref{parseinfo}.
The parse info headers support navigating through the stream without the 
need to decode any data units. Each parse info header contains pointers 
to the location of the next and previous parse info headers within the stream. 
The stream may thus be thought of as a doubly linked list of data units.
Each parse info headers contains a code that identifies the type of data held 
in the following data unit. This is the only information contained within
the parse info headers that is needed to decode the sequence.

\subsection{Data units}

Data units may be one of:
\begin{itemize}
\item a sequence header, 
\item a picture, 
\item auxiliary data 
\item padding data. 
\end{itemize}

A sequence header shall contain metadata describing the coded sequence 
and metadata needed to decode the stream. The sequence header is defined 
in Section \ref{sequenceheader}. The first data unit in a sequence shall be a 
sequence header. To support reverse-parsing applications, the last data unit in 
a sequence should also be a sequence header.

Each sequence shall contain at least one picture and at least one sequence header.
The first picture after each sequence header (if there is one) shall be an intra picture.

If a sequence contains more than one sequence header, the data 
in each sequence header shall be the same (byte-for-byte identical) within the sequence.

Each picture, whether a frame or field, may be coded with a dependency 
on prior pictures in the stream (reference pictures).

A picture data unit shall contain sufficient data to decode a single picture 
(frame or field of video), subject to having parsed a sequence header within 
the sequence and decoded any reference pictures.

Pictures within a sequence shall either all be fields or all be frames. Where pictures 
are fields, a sequence shall contain an even number of pictures, comprising a whole number of frames.

Auxiliary data and padding data do not contribute to the decoding 
process and so may be discarded. 


Auxiliary and padding data units comprise undefined data for the purposes
 of this standard. These data units (together with the correct preceding 
parse info header) may be interposed at any point in the stream, but 
may safely be skipped by a compliant decoder. For the purposes of 
subsequent parts of this standard, the potential presence of auxiliary 
and padding data shall be ignored.

Padding data units shall not be used for any form of auxiliary data 
service or content. They may be used by an encoder, where required, 
to insert additional data to assist in complying with constant or constrained bit rate requirements.

\subsubsection{Auxiliary data}\label{auxdata}

The $auxiliary\_data()$ process for reading auxiliary data shall be as follows:

\begin{pseudo}{auxiliary\_data}{}
\bsCODE{byte\_align()}
\bsFOR{i=1}{\NextParseOffset-13}
    \bsCODE{read\_byte}
\bsEND
\end{pseudo}

\subsubsection{Padding data}\label{paddingdata}

The $padding()$ process for reading padding data shall be as follows:

\begin{pseudo}{padding}{}
\bsCODE{byte\_align()}
\bsFOR{i=1}{\NextParseOffset-13}
    \bsCODE{read\_byte}
\bsEND
\end{pseudo}

\subsection{Parse Info header syntax}
\label{parseinfo}

This section specifies the operation of the $parse\_info()$ process for parsing
parse info header data. This header shall consists of 13 bytes of data, byte-aligned 
within the sequence. Thus it shall ensure that succeeding data elements
are  byte aligned. It shall occur:
\begin{itemize}
\item at the beginning of a sequence
\item at the end of a sequence
\item before each data unit
\end{itemize}

The value of the parse code, which is a component of the parse info, shall be used to determine the type and format of the subsequent data structures, in particular indicating whether a picture is Intra or Inter coded, and if Inter how many references it has.

\begin{pseudo}{parse\_info}{}
\bsCODE{byte\_align()}
\bsCODE{\ParseInfoPrefix=read\_uint\_lit(4)}
\bsCODE{\ParseCode=read\_byte()}
\bsCODE{\NextParseOffset=read\_uint\_lit(4)}
\bsCODE{\PrevParseOffset=read\_uint\_lit(4)}
\end{pseudo}

The Parse Info parameters shall satisfy the following constraints:

\begin{itemize}
\item $\ParseInfoPrefix$ shall be set to be 0x42 0x42 0x43 0x44, which is the character string ``BBCD'' as expressed by ISO/IEC 646.
\item $\ParseCode$ shall be one of the supported values set out in Table \ref{parsecodes}
\item $\NextParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the next Parse Info header, if there is one. If there
is no subsequent Parse Info header, it shall be be zero.
\item $\PrevParseOffset$ shall be the number of bytes from the first byte of the current
Parse Info header to the first byte of the previous Parse Info header, if there is one. If there
is no subsequent Parse Info header, it shall be be zero.
\end{itemize}

Consequently, the previous parse offset value of the current parse info header shall equal the next parse offset value of the previous parse info header, if there is one.

Parse codes shall be divided into three sets: generic, core syntax and low delay
syntax.

The value of parse codes allowed within the Dirac sequence shall be as shown in Table \ref{parsecodes}

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|l|c|}
\hline
\rowcolor[gray]{0.75}
\ParseCode &  {\bf Bits} & {\bf Description} & \begin{tabular}{c} {\bf Number of}\\ {\bf Reference}\\{\bf Pictures}\end{tabular}\\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Generic}\\
\hline
0x00 & 0000 0000 & Sequence header &--\\
\hline
0x10 & 0001 0000 & End of Sequence & -- \\
\hline
0x20 & 0010 0000 & Auxiliary data & -- \\
\hline
0x30 & 0011 0000 & Padding data & -- \\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Core syntax}\\
\hline
0x0C & 0000 1100 & Intra Reference Picture (arithmetic coding) & 0\\
\hline
0x08 & 0000 1000 & Intra Non Reference Picture (arithmetic coding) & 0\\
\hline
0x4C & 0100 1100 & Intra Reference Picture (no arithmetic coding) & 0\\
\hline
0x48 & 0100 1000 & Intra Non Reference Picture (no arithmetic coding) & 0\\
\hline
0x0D & 0000 1101 & Inter Reference Picture (arithmetic coding) & 1\\
%\hline
%0x4D & 0100 1101 & Inter Reference Picture (no arithmetic coding) & 1\\
\hline
0x0E & 0000 1110 & Inter Reference Picture (arithmetic coding) & 2\\
%\hline
%0x4E & 0100 1110 & Inter Reference Picture (no arithmetic coding) & 2\\
\hline
0x09 & 0000 1001 & Inter Non Reference Picture (arithmetic coding)& 1\\
%\hline
%0x49 & 0100 1001 & Inter Non Reference Picture (no arithmetic coding) & 1\\
\hline
0x0A & 0000 1010 & Inter Non Reference Picture (arithmetic coding) & 2\\
%\hline
%0x4A & 0100 1010 & Inter Non Reference Picture (no arithmetic coding)& 2\\
\hline
\multicolumn{4}{|c|}{\cellcolor[gray]{0.85}\bf Low-delay syntax}\\
\hline
0xCC & 1100 1100 & Intra Reference Picture & 0\\
\hline
0xC8 & 1100 1000 & Intra Non Reference Picture & 0\\
\hline
\end{tabular}
\caption{Parse codes}\label{parsecodes}
\end{table}

Future versions of this specification may introduce new parse codes. In order that 
decoders complying with this version of the specification may decode future 
versions of the coded stream, the decoder shall discard data units that immediately 
follow parse info blocks containing unknown parse codes. 

The parse codes shall be associated with a group of functions, listed below, which shall determine the type of subsequent data and the parsing and decoding processes which 
shall be used. All functions shall return a
boolean, except for $num\_refs()$ which shall returns an integer:

\begin{pseudo}{is\_seq\_header}{}
\bsRET{\ParseCode==\text{0x00}}
\end{pseudo}

\begin{pseudo}{is\_end\_of\_sequence}{}
\bsRET{\ParseCode==\text{0x10}}
\end{pseudo}

\begin{pseudo}{is\_auxiliary\_data}{}
\bsRET{(\ParseCode \& \text{0xF8})==\text{0x20}}
\end{pseudo}

\begin{pseudo}{is\_padding}{}
\bsRET{(\ParseCode \& \text{0xF8})==\text{0x30}}
\end{pseudo}

\begin{pseudo}{is\_picture}{}
\bsRET{((\ParseCode \&\text{0x08})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{is\_low\_delay}{}
\bsRET{((\ParseCode \&\text{0x88})==\text{0x88})}
\end{pseudo}

\begin{pseudo}{is\_core\_syntax}{}
\bsRET{((\ParseCode \&\text{0x88})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{using\_ac}{}
\bsRET{((\ParseCode \&\text{0x48})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{is\_reference}{}
\bsRET{((\ParseCode \&\text{0x0C})==\text{0x0C})}
\end{pseudo}

\begin{pseudo}{is\_non\_reference}{}
\bsRET{((\ParseCode \&\text{0x0C})==\text{0x08})}
\end{pseudo}

\begin{pseudo}{num\_refs}{}
\bsRET{(\ParseCode \&\text{0x03})}
\end{pseudo}

\begin{pseudo}{is\_intra}{}
\bsRET{is\_picture() \text{ and } (num\_refs()==0)}
\end{pseudo}

\begin{pseudo}{is\_inter}{}
\bsRET{is\_picture() \text{ and }(num\_refs()>0)}
\end{pseudo}



\begin{informative*}
\subsubsection{Parse code value rationale (Informative)}

The rationale for the parse code values in Table \ref{parsecodes} is as follows:
\begin{itemize}
\item The MS bit (bit 7) is used to indicate the picture syntax (core or low delay syntax) 
and only applies to pictures. Core syntax codes whole frames rather than slices. Low delay syntax codes slices not frames. 
\item The second MS bit (bit 6) is used to indicate whether arithmetic coding is used and only applies to pictures. Core syntax may optionally use arithmetic coding. Low delay syntax does not use arithmetic coding. The permutation of the two bits which might indicate low delay syntax with arithmetic coding is reserved. Arithmetic coding is not supported on
Inter pictures.
\item The next three MS bits (bits 5, 4 and 3) indicate the type of data unit following the parse info unit. Bit 3 indicates whether it is a picture or non-picture data unit. Bits 5 and 4 indicate the 4 other parse codes.
\item The three LS bits (bits 2, 1 and 0) indicate picture types. Bit 2 indicates whether a picture
is a reference picture or not. Bits 0 and 1 indicate the number of references a picture has
for motion compensation purposes: if these are both 0, the picture is an Intra picture.
\end{itemize}

\end{informative*}

\section{Sequence header}
\label{sequenceheader}

This section defines the structure of the sequence header syntax. 
The sequence header shall be byte aligned. 
Parsing this header consists of reading the sequence parameters 
(parse parameters, base video format, source parameters and 
picture coding mode) and initializing the decoder parameters. The decoder 
parameters are initialized in the $coding_parameters()$ process (below).

The sequence header shall remain byte identical throughout a sequence.

The process for parsing the sequence header shall be as follows:

\begin{pseudo}{sequence\_header}{}
\bsCODE{byte\_align()}
\bsCODE{parse\_parameters()}{\ref{parseparameters}}
\bsITEM{base\_video\_format}{uint}{\ref{videoformat}}
\bsCODE{\VideoParams=source\_parameters(base\_video\_format)}{\ref{sourceparameters}}
\bsITEM{picture\_coding\_mode}{uint}{\ref{interlacedcoding}}
\bsCODE{set\_coding\_parameters(\VideoParams,picture\_coding\_mode)}{\ref{interlacecoding}}
\bsRET{\VideoParams}
\end{pseudo}

Parse parameters contain information a decoder may use to determine whether 
it is able to parse or decode the stream. Parse parameters are not used to decode the stream.

The base video format is a numerical index denoting a default set of parameters 
that describe the video source. For many common video formats the predefined 
values indicated by the base video format and defined in Appendix \ref{videoformatdefaults}, will be sufficient 
without the need for further metadata to be present in the stream. However, to provide 
flexibility, source parameters may override the parameters indicated 
by the base video format (with the exception of the top field first flag).

Source parameters are parameters that describe the source video, not all of 
which are required to decode the stream. The source parameters are needed by 
applications that use the decoded video and so should be made available to them.

Field coding indicates whether the video has been coded as a sequence of frames or fields.

Once the base video format, source parameters and frame/field coding mode have 
been read from the stream the information they contain may be decoded to 
provide the parameters used for decoding pictures. It is the purpose of the 
$coding\_parameters()$ process to initialize these parameters.

\begin{informative}
Note that video parameters indicate whether the video sequence is interlaced or progressive.
In particular a change from interlaced to progressive video, or vice-versa, necessitates that
the Dirac sequence be terminated and a new sequence begun. The coding mode indicates whether
the pictures within a Dirac sequence are fields or frames. Note that progressive video may
still be encoded as fields, to provide backward compatibility with pseudo-progressive frame (PSF)
video transmission.

The video parameters are not used by the Dirac decoder. Video parameter values should
be made available using appropriate interfaces and standards to any downstream video
processing device or display, but their use and interpretation by other devices is not specified in this standard. 
Neverthless, Appendix \ref{vidsys} specifies the video systems model that should be used for the interpretation
of video parameters.
\end{informative}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parse parameters}
\label{parseparameters}

This section specifes the structure of the parse parameters, which is as follows:

\begin{pseudo}{parse\_parameters}{}
\bsITEM{\VersionMajor}{uint}{}
\bsITEM{\VersionMinor}{uint}{}
\bsITEM{\Profile}{uint}{}
\bsITEM{\Level}{uint}{}
\end{pseudo}

Parse parameter data shall be constant
(byte-for-byte identical) for all instances of the sequence header within a Dirac sequence.

\subsubsection{Version number}

The major version number shall define the version of the syntax with which the stream complies. A decoder complies with a major version number if it can parse all bit streams that comply with that version number. Decoders that comply with a major version of the specification may not be able to parse the bit stream corresponding to a later specification.

Depending on the profile and level defined, a decoder compliant with a given major version number may still not be able to decode fully all parts of a stream.

All minor versions of the specification shall be functionally compatible with earlier minor versions with the same major version number. Later minor versions may contain corrections, clarifications, and removal of ambiguities. Later minor version numbers shall not contain new features or new normative provisions.

The major version number of a stream compliant with this version of the Dirac standard shall be 1.

The minor version number of a stream compliant with this version of the Dirac standard shall be 0.


\subsubsection{Profiles and levels}

A profile shall define the toolset that is sufficient to decode a sequence. 

A level shall determine decoder resources (picture and data buffers; computational resources) sufficient
to decode a sequence, including the sizes $\RefBufferSize$ and $\DPBSize$ of 
the reference picture and decoded picture buffers. 

Applicable values of profile and level and the variables they set are specified in Appendix
\ref{profilelevel}.

\subsection{Base video format}
\label{videoformat}

The value of $base\_video\_format$ decoded in parsing the sequence header shall be 
an index into Table \ref{table:videoformats}. For each entry in the table parameters are defined, in 
Appendix \ref{videoformatdefaults}, indicating parameters corresponding to one of a set of 
predefined formats. These base parameters may be modified by subsequent metadata present
 in the stream as defined in subsequent sections below, with the exception of the top field first
 parameter which shall only be set by the base video format (see Section \ref{scanformat}).

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}Video format index	& Video format description \\
\hline
0	& Custom Format\\
\hline
1	&	QSIF525\\
\hline
2	&	QCIF\\
\hline
3	&	SIF525\\
\hline
4	&	CIF\\
\hline
5	&	4SIF525\\
\hline
6	&	4CIF\\
\hline
7	&	SD 480I-60 (525 Line 60 Field/s Standard Definition)\\
\hline
8	&	SD 576I-50 (625 Line 50 Field/s Standard Definition)\\
\hline
9	&	HD 720P-60 (720 Line 60 Frame/s High Definition)\\
\hline
10 &	HD 720P-50 (720 Line 50 Frame/s High Definition)\\
\hline
11 &	HD 1080I-60 (1080 Line 60 Field/s High Definition)\\
\hline
12	&	HD 1080I-50 (1080 Line 50 Field/s High Definition)\\
\hline
13	&	HD 1080P-60 (1080 Line 60 Frame/s High Definition)\\
\hline
14	&	HD 1080P50 (1080 Line 50 Frame/s High Definition)\\
\hline
15	&	DC 2K-24 (2K D-Cinema, 24fps)\\
\hline
16	&	DC 4K-24 (2K D-Cinema, 24fps)\\
\hline
\end{tabular}
\caption{Dirac predefined video formats}
\label{table:videoformats}
\end{table}

Custom format is intended for use when no other suitable base video format is available from
 the table. Video format defaults will still be set as per Appendix \ref{videoformatdefaults},
 but these are token values which are expected to be almost wholly overridden by the subsequent source parameters. 

\subsection{Source parameters}
\label{sourceparameters}

The source parameters are intended to indicate the format of the video that was 
originally encoded. They provide metadata that indicates how the decoded video should be displayed. 

The source parameters shall comprise frame size, chroma sampling format, scan format, frame rate,
 pixel aspect ratio, clean area, signal range and color specification. The frame size, chroma sampling
 format, scanning format and the signal range are required to decode the video. Display and 
downstream processing falls outside the scope of this specification, hence the interpretation of the other parameters (not required to decode the video) is not normatively defined, with the exception of frame rate (Section \ref{framerate}). The frame rate imposes requirements on
 compliant decoders for a given level and profile (Appendix \ref{profilelevel}).

Source parameter data shall remain constant throughout a VC-2 sequence. 

Default values for the source parameters shall be derived from the video format, as defined in annex C. These default values shall be the source parameters unless they are overridden with alternative values encoded as part of the Source Parameters part of the stream. 

The $source\_parameters()$ process shall return a structure defining the video source parameters. It shall be defined as follows:

\begin{pseudo}{source\_parameters}{base\_video\_format}
\bsCODE{\VideoParams = set\_source\_defaults(base\_video\_format)}{\ref{setsourcedefaults}}
\bsCODE{frame\_size(\VideoParams)}{\ref{framedimensions}}
\bsCODE{chroma\_sampling\_format(\VideoParams)}{\ref{chromaformat}}
\bsCODE{scan\_format(\VideoParams)}{\ref{scanformat}}
\bsCODE{frame\_rate(\VideoParams)}{\ref{framerate}}
\bsCODE{pixel\_aspect\_ratio(\VideoParams)}{\ref{aspectratio}}
\bsCODE{clean\_area(\VideoParams)}{\ref{cleanarea}}
\bsCODE{signal\_range(\VideoParams)}{\ref{signalrange}}
\bsCODE{colour\_spec(\VideoParams)}{\ref{colourspec}}
\bsRET{\VideoParams}
\end{pseudo}

Note: Although some source parameters are not used by the Dirac decoder all source parameters should, nevertheless, be made available any downstream video processing device or display to allow the proper interpretation of the decoded video. Their use and interpretation by other devices is not specified in this standard. 

\subsubsection{Setting source defaults}
\label{setsourcedefaults}

The function that sets the default values of the source video parameters 
shall take the video format index as an argument. That is, the signature of this function is: $set\_source\_defaults(video\_format\_index)$ where $video\_format\_index$ is an unsigned integer. The function returns a map of source video parameters.

The source video parameters shall be set, based on the video format index, as defined in 
Appendix \ref{videoformatdefaults}. The parameters set by this function shall be: Frame Size, 
Sampling Format (4:4:4, 4:2:2 or 4:2:0), Scan Format (Progressive or Interlace), Frame Rate, Pixel Aspect Ratio, Clean Area, Signal Range, Color Specification. The tokens used to access the map returned by the function shall be as defined in the subsequent sections that specify how to override the default video source parameters.

Note: as an example, if $video\_format\_index  == 4$, CIF defaults are set, with picture size equal to 252x288, 4:2:0 chroma format, amongst other parameters. A frame width of 360 pixels may be encoded by overriding the CIF format default value of 352. 

\subsubsection{Frame dimensions}
\label{framedimensions}

If a flag is set, the image dimensions specified by the video format defaults may
be overridden:

\begin{pseudo}{frame\_size}{\VideoParams}
\bsITEM{custom\_dimensions\_flag}{bool}{}
\bsIF{custom\_dimensions\_flag==\true}
    \bsITEM{\SFrameWidth}{uint}{}
    \bsITEM{\SFrameHeight}{uint}{}
\bsEND
\end{pseudo}

\subsubsection{Chroma sampling formats}
\label{chromaformat}

If a flag is set, the chroma format specified by the video format defaults is overridden.

\begin{pseudo}{chroma\_sampling\_format}{\VideoParams}
\bsITEM{custom\_chroma\_format\_flag}{bool}{}
\bsIF{custom\_chroma\_format\_flag==\true}
     \bsITEM{\SChromaFormatIndex}{uint}{}
\bsEND
\end{pseudo}

The supported chroma sampling formats are specified in Table \ref{tab:chromaformats}:

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}\SChromaFormatIndex & {\bf Chroma format} \\
\hline
0 & 4:4:4 \\
\hline
1 & 4:2:2 \\
\hline
2 & 4:2:0 \\
\hline
\end{tabular}
\caption{Supported chroma sampling formats}\label{tab:chromaformats}
\end{table}

The chroma sampling format shall be used to determine the width and height of the 
chroma components of the coded video as described in Section \ref{picturedimensions} below.

\subsubsection{Scan format}
\label{scanformat}

The scan format parameter shall indicate whether the source video represents progressive 
frames or interlaced fields.

The process for parsing the scan format parameters shall be as follows:

\begin{pseudo}{scan\_format}{\VideoParams}
\bsITEM{custom\_scan\_format\_flag}{bool}{}
\bsIF{custom\_scan\_format\_flag==\true}
    \bsITEM{\SSourceSampling}{uint}{}
\bsEND
\end{pseudo}

If the custom scan format flag is set to $\true$, the source sampling parameter defined by 
the base video format values shall be overridden by the new value.

If $\SSourceSampling$ is set to 0, then the source video shall be progressively sampled. 
If it is 1, then the source video shall be interlaced. Values greater than 1 shall be reserved.

If the source video is interlaced then $\STopFieldFirst$ shall be $\true$ 
if the top line of the frame is in the earlier field, else $\STopFieldFirst$
 shall be $\false$. This shall be set only by the base video format and cannot be overridden 
in the source parameters.

Both interlaced and progressive video may be coded as fields or frames.

\subsubsection{Frame rate}
\label{framerate}

The frame rate value (in frames per second) shall be 
$\SFrameRateNumer$ divided by $\SFrameRateDenom$

The process for decoding the frame rate parameters shall be as follows:

\begin{pseudo}{frame\_rate}{\VideoParams}
\bsITEM{frame\_rate\_flag}{bool}{}
\bsIF{frame\_rate\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SFrameRateNumer}{uint}{}
        \bsITEM{\SFrameRateDenom}{uint}{}
    \bsELSE
        \bsCODE{preset\_frame\_rate(\VideoParams,index)}
     \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 10.

For $index>0$, $preset\_frame\_rate(\VideoParams,index)$ shall set frame rate
elements of $\VideoParams$ 
as specified in Table \ref{table:frameratevalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Numerator & Denominator \\
\hline
1 & 24000 & 1001 \\
\hline
2 & 24 & 1 \\
\hline
3 & 25 & 1 \\
\hline
4 & 30000 & 1001 \\
\hline
5 & 30 & 1 \\
\hline
6 & 50 & 1 \\
\hline
7 & 60000 & 1001 \\
\hline
8 & 60 & 1 \\
\hline
9 & 15000 & 1001 \\
\hline
10 & 25 & 2 \\
\hline
\end{tabular}
\caption{Available preset frame rate values}\label{table:frameratevalues}
\end{table}

Note that what is encoded is frame rate, not picture rate. If the video is coded
as fields, then picture rate is twice the encoded frame rate.

\subsubsection{Pixel aspect ratio}
\label{aspectratio}

The process for decoding the pixel aspect ratio parameters shall be defined as follows:

\begin{pseudo}{pixel\_aspect\_ratio}{\VideoParams}
\bsITEM{custom\_pixel\_aspect\_ratio\_flag}{bool}{}
\bsIF{custom\_pixel\_aspect\_ratio\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SAspectRatioNumer}{uint}{}
        \bsITEM{\SAspectRatioDenom}{uint}{}
    \bsELSE
        \bsCODE{preset\_pixel\_aspect\_ratio(\VideoParams,index)}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

For $index>0$, $preset\_pixel\_aspect\_ratio(\VideoParams, index)$ shall set the pixel aspect ratio value elements of $\VideoParams$ as specified in Table \ref{table:aspectratiovalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Numerator & Denominator \\
\hline
1 (Square Pixels) & 1 & 1 \\
\hline
2 (525-line systems) & 10 & 11 \\
\hline
3 (625-line systems) & 12 & 11 \\
\hline
4 (16:9 525-line systems) & 40 & 33 \\
\hline
5 (16:9 625-line systems) & 16 & 11 \\
\hline
6 (reduced horizontal resolution) & 4 & 3 \\
\hline
\end{tabular}
\caption{Available preset pixel aspect ratio values}\label{table:aspectratiovalues}
\end{table}

\begin{informative}
The pixel aspect ratio is defined as the ratio of the aspect ratio parameters:
		\[\SAspectRatioNumer : \SAspectRatioDenom\]
The pixel aspect ratio (PAR) value defines the intended pixel aspect ratio of the pixels such that the viewed picture has no geometric distortion. The pixel aspect ratio of an image is the PARs are fundamental properties of sampled images because they determine the displayed shape of objects in the image. Failure to use the right PAR will result in distorted images, for example circles will be displayed as ellipses etc. 
Some video processing tools require an image aspect ratio. This may be derived from the pixel aspect ratio by multiplying the ratio of horizontal to vertical pixels by the pixel aspect ratio. So, for example, for a 704 x 480 line picture, with a pixel aspect ratio of 10:11 the image aspect ratio is (704 x 10)/(480 x 11) which is exactly 4:3.
\end{informative}

\subsubsection{Clean area}
\label{cleanarea}

The process for decoding the clean area parameters shall be as follows:

\begin{pseudo}{clean\_area}{\VideoParams}
\bsITEM{custom\_clean\_area\_flag}{bool}{}
\bsIF{custom\_clean\_area\_flag==\true}
    \bsITEM{\SCleanWidth}{uint}{}
    \bsITEM{\SCleanHeight}{uint}{}
    \bsITEM{\SLeftOffset}{uint}{}
    \bsITEM{\STopOffset}{uint}{}
\bsEND
\end{pseudo}

The following restrictions shall apply:

\begin{itemize}
\item $\SCleanWidth+\SLeftOffset
\leq \SFrameWidth$
\item $\SCleanHeight+\STopOffset
\leq \SFrameHeight$
\end{itemize}

\subsubsection{Signal range}
\label{signalrange}

The signal range parameters indicate how the signal range of the picture component data, decoded by the Dirac decoder, should be adjusted prior to the color matrixing operations (described in informative Appendix \ref{signalranges}). 

The signal range parameters shall also be used to determine the luma depth and chroma depth parameters (Section \ref{videodepth}) and the resulting clipping levels applied to the decoded video (Section \ref{pictureclip}).

Note that picture component data processed by the Dirac decoder is bipolar, and
is adjusted to positive ranges when pictures are output.

The process for decoding the signal range parameters is as follows:

\begin{pseudo}{signal\_range}{\VideoParams}
\bsITEM{custom\_signal\_range\_flag}{bool}{}
\bsIF{custom\_signal\_range\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsIF{index == 0}
        \bsITEM{\SLumaOffset}{uint}{}
        \bsITEM{\SLumaExcursion}{uint}{}
        \bsITEM{\SChromaOffset}{uint}{}
        \bsITEM{\SChromaExcursion}{uint}{}
    \bsELSE
        \bsCODE{preset\_signal\_ranges(\VideoParams,index)}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

If $index>0$ the $preset\_signal\_ranges(\VideoParams,index)$ shall set the signal range elements of $\VideoParams$ as specified in Tables \ref{table:signalrangevalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & Luma offset & Luma excursion & Chroma offset & Chroma excursion\\
\hline
1 (8 Bit Full Range) & 0 & 255 & 128 & 255\\
\hline
2 (8 Bit Video) & 16 & 219 & 128 & 224\\
\hline
3 (10 Bit Video) & 64 & 876 & 512 &  896\\
\hline
4 (12 Bit Video) & 256 & 3504 & 2048 & 3584\\
\hline
\end{tabular}
\caption{Available signal range presets}\label{table:signalrangevalues}
\end{table}

Note that decoded video is represented within the decoder specification as bi-polar 
signals. An offset is added when video is output so that it is represented by unsigned 
integer values.

\subsubsection{Colour specification}
\label{colourspec}

The color specification shall consist of three component parts:
\begin{itemize}
\item Color primaries
\item Color matrix 
\item Transfer function
\end{itemize}

Defaults are available for all three parts collectively and individually.

The process for decoding the color specification parameters shall be follows: 

\begin{pseudo}{colour\_spec}{\VideoParams}
\bsITEM{custom\_colour\_spec\_flag}{bool}{}
\bsIF{custom\_colour\_spec\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_specs(\VideoParams,index)}
    \bsIF{index == 0}
        \bsCODE{colour\_primaries(\VideoParams)}{\ref{colourprimaries}}
        \bsCODE{colour\_matrix(\VideoParams)}{\ref{colourmatrix}}
        \bsCODE{transfer\_function(\VideoParams)}{\ref{transferfunction}}
    \bsEND
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 4.

$preset\_colour\_spec(index)$ shall set the colour primaries, matrix and transfer function elements of $\VideoParams$ as specified 
in Table \ref{table:colourspecvalues}. If the value of $index$ is 0, these values may be overridden as defined in the succeeding sections. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & {\bf Description}           & {\bf Primaries}       & {\bf Matrix}  & {\bf Transfer function}\\
\hline
0 & Custom & HDTV & HDTV & TV gamma \\ 
\hline
1 & SDTV 525 & SDTV 525 & SDTV & TV gamma \\
\hline
2 & SDTV 625 & SDTV 625 & SDTV & TV gamma \\
\hline
3 & HDTV & HDTV & HDTV & TV gamma \\
\hline
4 & Cinema & CIE XYZ & HDTV & DCI Gamma\\
\hline
\end{tabular}
\caption{Colour specification presets}\label{table:colourspecvalues}
\end{table}

\paragraph{Colour primaries}
\label{colourprimaries}

The color primaries decoding process shall be defined as follows:

\begin{pseudo}{colour\_primaries}{\VideoParams}
\bsITEM{custom\_colour\_primaries\_flag}{bool}{}
\bsIF{custom\_colour\_primaries\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_primaries(\VideoParams,index)}
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 3.

 $preset\_colour\_primaries(\VideoParams,index)$ shall set the colour primaries 
element of $\VideoParams$ as specified
in Table \ref{table:primariesvalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ &  {\bf Description} & {\bf Specification} & {\bf Comment}      \\
\hline
0       &  HDTV & ITU-R BT.709 & Also Computer, Web, sRGB \\ 
\hline
1       &  SDTV 525 & ITU-R BT.601 & 525 primaries          \\
\hline
2       &  SDTV 625 & ITU-R BT.601 & 625 primaries  \\
\hline
3       &  Cinema & SMPTE 428.1 & CIE XYZ              \\
\hline
\end{tabular}
\caption{Colour primaries presets}\label{table:primariesvalues}
\end{table}

\paragraph{Colour matrix}
\label{colourmatrix}
$\ $\newline
The color matrix decoding process shall be defined as follows:

\begin{pseudo}{colour\_matrix}{}
\bsITEM{colour\_matrix\_flag}{bool}{}
\bsIF{colour\_matrix\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_colour\_matrices(index)}
\bsEND
\end{pseudo}

The decoded value of $index$ shall fall in the range 0 to 2. 

The $preset\_colour\_matrices(\VideoParams,index)$ process shall set the colour 
matrix element in $\VideoParams$ as specified
in Table \ref{table:matrixvalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ &  {\bf Description} & {\bf Specification} & {\bf Colour matrix} & {\bf Comment}\\
\hline
0 & HDTV & ITU-R BT.709 & $K_R=0.2126$, $K_B=0.0722$ & Also computer and web\\ 
\hline
1 & SDTV & ITU-R BT.601 & $K_R=0.299$, $K_B=0.114$ & \\
\hline
2 & Reversible & ITU-T H.264 & YCgCo & \\
\hline
\end{tabular}
\caption{Colour matrix presets}\label{table:matrixvalues}
\end{table}

\paragraph{Transfer function}
\label{transferfunction}
$\ $\newline
The transfer function decoding process shall be defined as follows:

\begin{pseudo}{transfer\_function}{\VideoParams}
\bsITEM{custom\_transfer\_function\_flag}{bool}{}
\bsIF{custom\_transfer\_function\_flag==\true}
    \bsITEM{index}{uint}{}
    \bsCODE{preset\_transfer\_function(\VideoParams,index)}
\bsEND
\end{pseudo}

$index$ shall fall in the range 0 to 3. The $preset\_transfer\_function(\VideoParams,index)$ process shall set the transfer function
element of $\VideoParams$ as specified
in Table \ref{table:transfervalues}.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$ & {\bf Description} & {\bf Specification}\\
\hline
0 & TV gamm & ITU-R BT.1361\\ 
\hline
1 & Extended Gamut & ITU-R BT.1361 1998 Annex 1\\
\hline
2 & Linear & Linear\\
\hline
3 & DCI Gamma & SMPTE 428.1\\
\hline
\end{tabular}
\caption{Transfer function presets}\label{table:transfervalues}
\end{table}

\subsection{Picture coding mode}
\label{interlacecoding}

The picture coding mode value in the sequence header shall determine 
whether source video is coded as frames or fields. 

If the picture coding mode value is $1$ then pictures shall correspond to fields. If it is $0$ 
then pictures shall correspond to frames. Other picture coding mode values shall be
reserved for future extensions.

If video is coded as fields then the earliest field in each frame shall have an even picture number (Section \ref{pictureheader}). That is the LSB of the frame number, expressed as a binary number, indicates field parity.

With field coding each frame shall be split into two fields as indicated by the scan format (Section \ref{scanformat}).

An effect of field coding shall be to halve the vertical dimensions of coded pictures. Hence, once the frame/field coding mode is known, the picture dimensions, which shall be stored as part of the global state variable, shall be set (Section \ref{picturedimensions}).

\begin{informative}
It is possible to code progressive video as fields. In this case, the assignment of 
frame lines to fields will be determined by the value of the top field first parameter in the base 
video format (Appendix \ref{videoformatdefaults}). Note that, according to Section \ref{scanformat},
 this base format default cannot be overridden for progressive video, as to do so would be artificial.
\end{informative}

\subsection{Initializing coding parameters}
\label{codingparameters}

The $set\_coding\_parameters()$ process shall initialize the dimensions of the coded picture (frame or field), and the video depth (the maximum number of bits in a decoded video sample), which are needed to decode pictures. 

Picture dimensions and video depth shall remain constant throughout a Dirac sequence. 

Initialization of the coding parameters shall be as defined in the table below:

\begin{pseudo}{set\_coding\_parameters}{\VideoParams, picture\_coding\_mode}
\bsCODE{picture\_dimensions(\VideoParams, picture\_coding\_mode)}{\ref{picturedimensions}}
\bsCODE{video\_depth(\VideoParams)}{\ref{videodepth}}
\end{pseudo}

\subsubsection{Picture dimensions}
\label{picturedimensions}
The picture dimensions process, which determines the size of coded pictures, shall be defined as follows:

\begin{pseudo}{picture\_dimensions}{\VideoParams, picture\_coding\_mode}
\bsCODE{\LumaWidth = \SFrameWidth}
\bsCODE{\LumaHeight = \SFrameHeight}
\bsCODE{\ChromaWidth = \LumaWidth}
\bsCODE{\ChromaHeight = \LumaHeight}
\bsCODE{chroma\_format\_index = \SChromaFormatIndex]}
\bsIF{chroma\_format\_index == 1}
  \bsCODE{\ChromaWidth //= 2}
\bsELSEIF{chroma\_format\_index == 2}
  \bsCODE{\ChromaWidth //= 2}
  \bsCODE{\ChromaHeight //= 2}
\bsEND
\bsIF{picture\_coding\_mode==1}
  \bsCODE{\LumaHeight //=2}
  \bsCODE{\ChromaHeight //=2}
\bsEND
\end{pseudo}

The parameter $\SFrameHeight$  refers to the height of a frame. The parameter $\LumaHeight$ refers to the height of a picture.  A picture may be either a frame or a field depending on whether it is being coded in an interlaced or progressive mode.

Frame height shall be an integer multiple of picture chroma height.

For convenience, the following utility functions shall be defined:

\begin{pseudo}{chroma\_h\_ratio}{}
\bsRET{\LumaWidth//\ChromaWidth}
\end{pseudo}
 
\begin{pseudo}{chroma\_v\_ratio}{}
\bsRET{\LumaHeight//\ChromaHeight}
\end{pseudo}

\subsubsection{Video depth}
\label{videodepth}
The $video\_depth()$ process, which determines the maximum number of bits required to represent a sample of the decoded video, shall be defined as follows:

\begin{pseudo}{video\_depth}{\VideoParams}
\bsCODE{\LumaDepth =\intlog2(\SLumaExcursion+1)}
\bsCODE{\ChromaDepth =\intlog2(\SChromaExcursion+1)}
\end{pseudo}

Note that for YCoCg format the luma and chroma depths are different.

\section{Picture syntax}
\label{picturesyntax}
This section specifies the structure of Dirac picture data units.

\subsection{Picture parsing}
\label{picture}
\label{pictureparse}

This section specifies the operation of the $picture\_parse()$ process. The process for
decoding and outputting pictures is specified in Section \ref{picturedec}.

Picture data may be successfully parsed after parsing a sequence header within the same VC-2 sequence. The picture parsing process shall be defined as follows:

\begin{pseudo}{picture\_parse}{}
\bsCODE{byte\_align()}
\bsCODE{picture\_header()}{\ref{pictureheader}}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsCODE{byte\_align()}
    \bsCODE{picture\_prediction()}{\ref{pictureprediction}}
\bsEND
\bsCODE{byte\_align()}
\bsCODE{wavelet\_transform()}{\ref{wavelettransform}}
\end{pseudo}

\subsubsection{Picture header}
\label{pictureheader}

The picture header shall immediately follow a parse info header with a picture parse 
code (Section \ref{parseinfo}). The picture header parsing process shall be defined as follows:

\begin{pseudo}{picture\_header}{}
\bsCODE{\PictureNumber=read\_byte\_lit(4)}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsCODE{\RefOneNum=(\PictureNumber+read\_sint())\%2^{32}}
    \bsIF{num\_refs() == 2}{\ref{parseinfo}}
        \bsCODE{\RefTwoNum=(\PictureNumber+read\_sint())\%2^{32}}
    \bsEND\bsEND
\bsIF{is\_ref()}{\ref{parseinfo}}
    \bsCODE{\RetiredPicture=(\PictureNumber+read\_sint())\% 2^{32}}
\bsEND
\end{pseudo}

Picture numbers shall be unique within a sequence and the set of all picture numbers
within a sequence shall form a contiguous block of numbers.

Reference picture numbers shall encoded differentially with respect to the
picture number.

The pictures corresponding to the reference picture numbers of a given picture
shall occur before the given picture in the sequence.

The retired picture shall be a pictures which shall be removed from 
the reference picture buffer before the current picture is decoded
(Sections \ref{picturedecprocess}and \ref{refbuffer}). The rules for the 
use of the reference picture buffer shall be as defined in Section \ref{refbuffer}.

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Picture prediction data}
\label{pictureprediction}

This section defines the picture prediction process that shall be used for decoding 
picture prediction parameters and motion vector fields for motion compensation.

The picture prediction process shall be defined as follows:

\begin{pseudo}{picture\_prediction}{}
\bsCODE{picture\_prediction\_parameters()}{\ref{picpredparams}}
\bsCODE{byte\_align()}
\bsCODE{block\_data()}{\ref{motiondec}}
\end{pseudo}

The decoding and generation of block motion vector fields shall be as defined in Section \ref{motiondec}. 

\subsubsection{Picture prediction parameters}
\label{picpredparams}

Picture prediction parameters consist of metadata required for successful parsing of the
motion data and for performing motion compensation (Section \ref{motioncompensate}).

The picture prediction parameters shall be defined as follows:

\begin{pseudo}{picture\_prediction\_parameters}{}
\bsCODE{block\_parameters()}{\ref{blockparameters}}
\bsCODE{motion\_vector\_precision()}{\ref{mvprecision}}
\bsCODE{global\_motion()}{\ref{globalmotion}}
\bsCODE{picture\_prediction\_mode()}{\ref{picpredmode}}
\bsCODE{reference\_picture\_weights()}{\ref{refpicweights}}
\end{pseudo}

\subsubsection{Block parameters}
\label{blockparameters}

This section specifies the operation of the process for
setting motion compensation block parameters, which shall consist of the state variables
$\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$
defining luma blocks, and $\ChromaXBlen$, $\ChromaYBlen$, $\ChromaXBsep$,
and $\ChromaYBsep$ defining chroma blocks. 

\begin{pseudo}{block\_parameters}{}
\bsITEM{index}{uint}
\bsIF{index == 0}
    \bsITEM{\LumaXBLen}{uint}{}
    \bsITEM{\LumaYBLen}{uint}{}
    \bsITEM{\LumaXBSep}{uint}{}
    \bsITEM{\LumaYBSep}{uint}{}
\bsELSE
       \bsCODE{preset\_block\_params(index)}
\bsEND
\bsCODE{chroma\_block\_params()}{\ref{chromablockparams}}
\end{pseudo}

$index$ shall lie in the range 0 to 4. 

The $preset\_block\_params(index)$ shall set the block parameters as specified
in Table \ref{blockparamsvalues}.

Chroma block parameter values shall be determined from luma values
as defined in Section \ref{chromablockparams}).

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\rowcolor[gray]{0.75}$index$  & \LumaXBlen & \LumaYBlen & \LumaXBsep & \LumaYBsep \\
\hline
1 & 8 & 8 & 4 & 4 \\
\hline
2 & 12 & 12 & 8 & 8\\
\hline
3 & 16 & 16 & 12 & 12\\
\hline
4 & 24 & 24 & 16 & 16\\
\hline
\end{tabular}
\caption{Luma block parameter presets}\label{blockparamsvalues}
\end{table}

Block parameters shall satisfy the following constraints:

\begin{enumerate}
\item $\LumaXBlen$, $\LumaYBlen$, $\LumaXBsep$, and $\LumaYBsep$ shall all be positive
multiples of 4
\item $\LumaXBlen\geq\LumaXBsep$ and $\LumaYBlen\geq\LumaYBsep$
\item $\LumaXBlen\leq 2*\LumaXBsep$ and $\LumaYBlen\leq 2*\LumaYBsep$
\end{enumerate}

\begin{informative}
Note that these requirements do not preclude length from equalling separation, i.e.
motion compensation blocks that are not overlapped. 
\end{informative}

\subsubsection{Setting chroma block parameters}
\label{chromablockparams}

This section defines how chroma block parameters shall be derived from luma block dimensions. 

Chroma block parameters shall be equal to the corresponding luma block parameters scaled according to the chroma vertical and horizontal subsampling ratios. In this way chroma blocks and luma blocks are co-located in the video picture.

\begin{pseudo}{chroma\_block\_params}{}
\bsCODE{\ChromaXBlen=\LumaXBlen//chroma\_h\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaYBlen=\LumaYBlen//chroma\_v\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaXBsep=\LumaXBsep//chroma\_h\_ratio()}{\ref{picturedimensions}}
\bsCODE{\ChromaYBsep=\LumaYBsep//chroma\_v\_ratio()}{\ref{picturedimensions}}
\end{pseudo}

\subsubsection{Motion vector precision}
\label{mvprecision}

The motion vector precision process shall be as follows:

\begin{pseudo}{motion\_vector\_precision}{}
\bsITEM{\MotionVectorPrecision}{uint}
\end{pseudo}

$\MotionVectorPrecision$ shall lie in the range 0 (pixel-accurate) to 3 (1/8th-pixel accurate).

\subsubsection{Global motion}
\label{globalmotion}

Global motion parameters shall be encoded if the $\PictureUsingGlobal$ flag is set
to $\true$. Up to two sets shall be encoded,
depending upon the number of references.

The global motion process shall be as follows:

\begin{pseudo}{global\_motion}{}
\bsITEM{\PictureUsingGlobal}{bool}{}
\bsIF{\PictureUsingGlobal==\true}
    \bsCODE{global\_motion\_parameters(\GlobalParams[1])}
    \bsIF{num\_refs() == 2}
        \bsCODE{global\_motion\_parameters(\GlobalParams[2])}
    \bsEND
\bsEND
\end{pseudo}

Each of the global motion parameters shall consist of three elements: 

\begin{itemize}
\item an integer pan/tilt vector $\GlobalParams[n][pan\_tilt]$
\item an integer 2x2 matrix element $\GlobalParams[n][ZRS]$
capturing zoom, rotation and shear, together with a scaling exponent 
$\GlobalParams[n][ZRS\_exp]$
\item an integer perspective vector $\GlobalParams[n][pespective]$
capturing the effect of non-orthogonal projection onto the image plane, together 
with a scaling exponent $\GlobalParams[n][pespective\_exp]$
\end{itemize}

Their interpretation and the process for generating a global motion vector field 
shall be as defined in Section \ref{globalmv}. 

The global motion parameters process shall be defined as follows:

\begin{pseudo}{global\_motion\_parameters}{gparams}
\bsCODE{pan\_tilt(gparams)}
\bsCODE{zoom\_rotate\_shear(gparams)}
\bsCODE{perspective(gparams)}
\end{pseudo}

The $pan\_tilt()$ process shall extracts horizontal and vertical translation elements
and shall be defined as follows:

\begin{pseudo}{pan\_tilt}{gparams}
\bsCODE{gparams[pan\_tilt]={\mathbf{0}} }
\bsITEM{nonzero\_pan\_tilt\_flag}{bool}{}
\bsIF{nonzero\_pan\_tilt\_flag==\true}
    \bsITEM{gparams[pan\_tilt][0]}{sint}{}
    \bsITEM{gparams[pan\_tilt][1]}{sint}{}
\bsEND
\end{pseudo}

The $zoom\_rotate\_shear()$ process shall extract a linear matrix element and shall be
as defined as follows:

\begin{pseudo}{zoom\_rotation\_shear}{gparams}
\bsITEM{nontrivial\_zrs\_flag}{bool}{}
\bsIF{nontrivial\_zrs\_flag==\true}
    \bsITEM{gparams[ZRS\_exp]}{uint}{}
    \bsITEM{gparams[ZRS][0][0]}{sint}{}
    \bsITEM{gparams[ZRS][0][1]}{sint}{}
    \bsITEM{gparams[ZRS][1][0]}{sint}{}
    \bsITEM{gparams[ZRS][1][1]}{sint}{}
\bsELSE
    \bsCODE{gparams[ZRS\_exp]=0}
    \bsCODE{gparams[ZRS][0][0]=1}
    \bsCODE{gparams[ZRS][0][1]=0}
    \bsCODE{gparams[ZRS][1][0]=0}
    \bsCODE{gparams[ZRS][1][1]=1}
\bsEND
\end{pseudo}

The $perspective()$ process shall extract horizontal and vertical perspective
elements and shall be defined as follows:

\begin{pseudo}{perspective}{gparams}
\bsITEM{nonzero\_perspective\_flag}{bool}{}
\bsIF{nonzero\_perspective\_flag==\true}
    \bsITEM{gparams[perspective\_exp]}{uint}{}
    \bsITEM{gparams[perspective][0]}{sint}{}
    \bsITEM{gparams[perspective][1]}{sint}{}
\bsELSE
    \bsCODE{gparams[perspective\_exp]=0}
    \bsCODE{gparams[perspective]={\mathbf{0}} }
\bsEND
\end{pseudo}

\subsubsection{Picture prediction mode}
\label{picpredmode}

The picture prediction mode encodes alternative methods of motion compensation
and is present to support future extensions of this specification.

It shall be defined as follows:

\begin{pseudo}{picture\_prediction\_mode}{}
\bsITEM{\PicturePredictionModeIndex}{uint}
\end{pseudo}

In this specification, $\PicturePredictionModeIndex$ shall be 0.

\subsubsection{Reference picture weight values}
\label{refpicweights}

Reference picture weight values shall be determined as follows:

\begin{pseudo}{reference\_picture\_weights}{}
\bsCODE{\RefsWeightPrecision=1}
\bsCODE{\RefOneWeight=1}
\bsCODE{\RefTwoWeight=1}
\bsITEM{custom\_weights\_flag}{bool}
\bsIF{custom\_weights\_flag==\true}
    \bsITEM{\RefsWeightPrecision}{uint}
    \bsITEM{\RefOneWeight}{sint}
    \bsIF{num\_refs() == 2}
        \bsITEM{\RefTwoWeight}{sint}
    \bsEND
\bsEND
\end{pseudo}

\begin{informative}
For bi-directional prediction modes, reference 1 data will be weighted by 

$\dfrac{\RefOneWeight}{2^\RefsWeightPrecision}$

and reference 2 data by

$\dfrac{\RefTwoWeight}{2^\RefsWeightPrecision}$ 

(see Section \ref{pixelpredict}).

The picture weights are signed integers and may be negative. In
addition, they may not sum to $2^\RefsWeightPrecision$, to accomodate fade
prediction.
\end{informative}

%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wavelet transform data}
\label{wavelettransform}

The wavelet transform syntax shall provide metadata determining the wavelet transform
 parameters (including filter type, transform depth, and codeblock or slice structures) together with the transformed wavelet coefficients. 

The wavelet transform process for parsing transform metadata and coefficients shall be defined as follows:

\begin{pseudo}{wavelet\_transform}{}
\bsCODE{\ZeroResidual = \false}
\bsIF{is\_inter()}{\ref{parseinfo}}
    \bsITEM{\ZeroResidual}{bool}
\bsEND
\bsIF{\ZeroResidual == \false}
    \bsCODE{transform\_parameters()}{\ref{transformparameters}}
    \bsCODE{byte\_align()}
    \bsCODE{transform\_data()}{\ref{wltunpacking}}
\bsEND
\end{pseudo}

Parsing (unpacking) the wavelet transform data shall be as defined in Section \ref{wltunpacking}. 

Decoding the transformed wavelet transform data to produce decoded pictures shall be
 as defined in Section \ref{picturedec}.

If $\ZeroResidual=\true$ then all component pixels shall be 
set to zero (Section \ref{picturedecprocess}).

\subsubsection{Transform parameters}
\label{transformparameters}

The wavelet transform parameters shall define the metadata required to configure the inverse wavelet transform for both the low delay and core syntax. 

The $transform\_parameters()$ process shall be defined as follows:

\begin{pseudo}{transform\_parameters}{}
\bsITEM{\WaveletIndex}{uint}{\ref{wltfilter}}
\bsITEM{\TransformDepth}{uint}{\ref{wltdepth}}
\bsIF{is\_low\_delay()==\false}
    \bsCODE{codeblock\_parameters()}{\ref{codeblockparams}}
\bsELSE
    \bsCODE{slice\_parameters()}{\ref{sliceparams}}
    \bsCODE{quant\_matrix()}{\ref{quantmatrix}}
\bsEND
\end{pseudo}

\paragraph{Wavelet filters}
\label{wltfilter}
$\ $\newline

The wavelet filter parameter shall define the wavelet filter used by the Dirac stream. T
The value of $\WaveletIndex$ shall lie in the range 0 to 6 with values as 
defined in Table \ref{wltfilterpresets}: 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
\rowcolor[gray]{0.75}\WaveletIndex & {\bf Filter} \\
\hline
0 & Deslauriers-Debuc (9,7) \\
\hline
1 & LeGall (5,3) \\
\hline
2 & Deslauriers-Debuc (13,7) \\
\hline
3 & Haar with no shift \\
\hline
4 & Haar with single shift per level\\
\hline
5 & Fidelity filter \\
\hline
6 & Daubechies (9,7) integer approximation \\
\hline
\end{tabular}
\caption{Wavelet filter presets}\label{wltfilterpresets}
\end{table}


The implementation of the chosen wavelet filter shall be as defined 
 in Section \ref{wltfilters}. 


\begin{informative}
For consistency, the filter nomenclature $(m, n)$ refers to the length of the analysis low-pass
and high-pass filters in the conventional prefiltering (i.e. before subsampling) 
model of wavelet filtering. They do not reflect the length of lifting filters, which
operate in the subsampled domain: see Section \ref{wltfilters}. Deslauriers-Debuc
filters are normally referred to in terms of the number of vanishing moments of their
synthesis filters, so the (9,7) and (13,7) filters may be referred to in the literature
as (2,2) and (4,2) filters respectively.
\end{informative}

\subsubsection{Transform depth}
\label{wltdepth}

The transform depth parameter shall determine the number of stages in the wavelet transform.that the vertical and horizontal wavelet filters are applied. 

Note: The transform depth determines the number of 
subbands and the the dimensions of the subband data array (Section \ref{wltinit}).

\subsubsection{Codeblock parameters (core syntax only)}
\label{spatialpartition}

In the core syntax only, each subband may be partitioned into a number of code blocks. 

The process for extracting codeblock parameters shall be as follows:

\begin{pseudo}{codeblock\_parameters}{}
\bsCODE{\CodeblockMode=0}
\bsFOR{level=0}{\TransformDepth}
    \bsCODE{\CodeblocksX[level]=1}
    \bsCODE{\CodeblocksY[level]=1}
\bsEND
\bsITEM{spatial\_partition\_flag}{bool}
\bsIF{spatial\_partition\_flag==\true}
    \bsFOR{level=0}{\TransformDepth}
        \bsITEM{\CodeblocksX[level]}{uint}
        \bsITEM{\CodeblocksY[level]}{uint}
    \bsEND
    \bsITEM{\CodeblockMode}{uint}
\bsEND
\end{pseudo}

The presence of codeblocks in subbands shall be indicated by setting $spatial\_partition\_flag$ to $\true$; otherwise it shall be $\false$.

The number of codeblocks to be used for subbands at each transform depth level shall be encoded in $\CodeblocksY[level]$ and $\CodeblocksX[level]$ for vertical and horizontal axes respectively.

The codeblock mode is encoded in $\CodeblockMode$, which shall have value 0 or 1, with meanings as defined in Table \ref{codeblockmodes}. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|}
\hline
 \rowcolor[gray]{0.75}$\CodeblockMode$ & {\bf Description} \\
\hline
0 & Single quantiser per subband, used for all codeblocks\\
\hline
1 & Multiple Quantiser per subband, one for each codeblock \\
\hline
\end{tabular}
\caption{Codeblock modes}\label{codeblockmodes}
\end{table}

The operation of subband codeblock decoding shall be as defined in Section \ref{codeblocks}.

\subsubsection{Slice coding parameters (low delay syntax only)}
\label{sliceparams}

This slice parameters process shall be defined as follows:

\begin{pseudo}{slice\_parameters}{}
\bsITEM{\SlicesX}{uint}
\bsITEM{\SlicesY}{uint}
\bsITEM{\SliceBytesNum}{uint}
\bsITEM{\SliceBytesDenom}{uint}
\end{pseudo}

\subsubsection{Quantisation matrices (low-delay syntax)}
\label{quantmatrix}

The quantization matrix shall be used to modify the slice quantizer for each subband in
 a slice. The quantization matrix shall be encoded in the $\QuantMatrix$ decoder variable. 

The $quant\_matrix()$ process shall be defined as follows:

\begin{pseudo}{quant\_matrix}{}
\bsITEM{custom\_quant\_matrix}{bool}
\bsIF{custom\_quant\_matrix==\true}
    \bsITEM{\QuantMatrix[0][\LL]}{uint}
    \bsFOR{level=1}{\TransformDepth}
        \bsITEM{\QuantMatrix[level][\HL]}{uint}
        \bsITEM{\QuantMatrix[level][\LH]}{uint}
        \bsITEM{\QuantMatrix[level][\HH]}{uint}
    \bsEND
\bsELSE
    \bsCODE{set\_quant\_matrix()}
\bsEND
\end{pseudo}

If $\TransformDepth> 4$ then $custom\_quant\_matrix$  shall be $\true$. 

If $\TransformDepth \leq 4$, then custom quantization matrices may still be transmitted, 
for example to apply a different degree of perceptual weighting (see Appendix \ref{qmatrixdesign}). 

The function $set\_quant\_matrix()$ shall set the quantization matrix based on the wavelet ?lter as per Appendix \ref{defaultquantmatrices}. These are unweighted matrices, whose values merely compensate for the differential power gain of the different subband ?lters. For perceptual weighting a custom quantisation matrix must be used.